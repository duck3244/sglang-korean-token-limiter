#!/bin/bash
# SGLang ê¸°ë°˜ í•œêµ­ì–´ Token Limiter íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)

set -e

echo "ğŸš€ SGLang ê¸°ë°˜ í•œêµ­ì–´ Token Limiter ì„¤ì¹˜"
echo "======================================"

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

# í™˜ê²½ í™•ì¸
check_environment() {
    echo -e "${BLUE}ğŸ” í™˜ê²½ í™•ì¸ ì¤‘...${NC}"

    # Python ë²„ì „ í™•ì¸ (SGLangì€ 3.10+ í•„ìš”)
    PYTHON_VERSION=$(python --version 2>&1 | cut -d' ' -f2)
    PYTHON_MAJOR=$(echo $PYTHON_VERSION | cut -d'.' -f1)
    PYTHON_MINOR=$(echo $PYTHON_VERSION | cut -d'.' -f2)

    echo "Python ë²„ì „: $PYTHON_VERSION"

    if [ "$PYTHON_MAJOR" -lt 3 ] || ([ "$PYTHON_MAJOR" -eq 3 ] && [ "$PYTHON_MINOR" -lt 10 ]); then
        echo -e "${RED}âŒ SGLangì€ Python 3.10+ í•„ìš” (í˜„ì¬: $PYTHON_VERSION)${NC}"
        echo "ì—…ê·¸ë ˆì´ë“œ ë°©ë²•:"
        echo "  conda install python=3.10"
        echo "  ë˜ëŠ” ìµœì‹  Python ì„¤ì¹˜"
        exit 1
    fi

    echo -e "${GREEN}âœ… Python ë²„ì „ ì í•© (SGLang ì§€ì›)${NC}"

    # ê°€ìƒí™˜ê²½ í™•ì¸
    if [[ "$VIRTUAL_ENV" == "" ]] && [[ "$CONDA_DEFAULT_ENV" == "" ]]; then
        echo -e "${YELLOW}âš ï¸ ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤${NC}"
        echo "ê¶Œì¥: conda activate korean_sglang ë˜ëŠ” source venv/bin/activate"

        read -p "ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    else
        if [[ "$CONDA_DEFAULT_ENV" != "" ]]; then
            echo -e "${GREEN}âœ… Conda í™˜ê²½: $CONDA_DEFAULT_ENV${NC}"
        else
            echo -e "${GREEN}âœ… Python venv í™˜ê²½ í™œì„±í™”ë¨${NC}"
        fi
    fi

    # GPU í™•ì¸
    if command -v nvidia-smi &> /dev/null; then
        GPU_AVAILABLE=true
        echo -e "${GREEN}ğŸ® GPU ê°ì§€ë¨${NC}"
        GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)
        GPU_MEMORY=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
        echo "GPU: $GPU_NAME"
        echo "ë©”ëª¨ë¦¬: ${GPU_MEMORY}MB"

        # CUDA ë²„ì „ í™•ì¸
        if command -v nvcc &> /dev/null; then
            CUDA_VERSION=$(nvcc --version | grep "release" | sed 's/.*release \([0-9]\+\.[0-9]\+\).*/\1/')
            echo "CUDA ê°œë°œ ë„êµ¬: $CUDA_VERSION"
        else
            echo -e "${YELLOW}âš ï¸ CUDA ê°œë°œ ë„êµ¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ëŸ°íƒ€ì„ì€ ì‚¬ìš© ê°€ëŠ¥)${NC}"
        fi
    else
        GPU_AVAILABLE=false
        echo -e "${YELLOW}âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.${NC}"
    fi
}

# ê¸°ë³¸ ë„êµ¬ ì—…ê·¸ë ˆì´ë“œ
upgrade_basic_tools() {
    echo -e "\n${BLUE}ğŸ“¦ ê¸°ë³¸ ë„êµ¬ ì—…ê·¸ë ˆì´ë“œ${NC}"
    pip install --upgrade pip wheel setuptools
    echo -e "${GREEN}âœ… ê¸°ë³¸ ë„êµ¬ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ${NC}"
}

# PyTorch ì„¤ì¹˜ (SGLang í˜¸í™˜ì„± ê³ ë ¤)
install_pytorch() {
    echo -e "\n${BLUE}ğŸ”¥ PyTorch ì„¤ì¹˜ (SGLang í˜¸í™˜)${NC}"

    # ê¸°ì¡´ PyTorch í™•ì¸
    if python -c "import torch" 2>/dev/null; then
        EXISTING_TORCH=$(python -c "import torch; print(torch.__version__)" 2>/dev/null)
        echo "ê¸°ì¡´ PyTorch ë²„ì „: $EXISTING_TORCH"

        # SGLang í˜¸í™˜ì„± í™•ì¸
        if python -c "import torch; assert torch.__version__.startswith('2.1') or torch.__version__.startswith('2.2')" 2>/dev/null; then
            echo -e "${GREEN}âœ… ê¸°ì¡´ PyTorchê°€ SGLangê³¼ í˜¸í™˜ë©ë‹ˆë‹¤${NC}"

            read -p "ê¸°ì¡´ PyTorchë¥¼ ìœ ì§€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): " -n 1 -r
            echo
            if [[ ! $REPLY =~ ^[Nn]$ ]]; then
                echo "ê¸°ì¡´ PyTorchë¥¼ ìœ ì§€í•©ë‹ˆë‹¤."
                return 0
            fi
        else
            echo -e "${YELLOW}âš ï¸ ê¸°ì¡´ PyTorchê°€ SGLangê³¼ í˜¸í™˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤${NC}"
            echo "SGLang ê¶Œì¥ ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."
        fi
    fi

    if [ "$GPU_AVAILABLE" = true ]; then
        echo "CUDA ë²„ì „ PyTorch ì„¤ì¹˜ ì¤‘ (SGLang ìµœì í™”)..."
        # SGLangì´ ì§€ì›í•˜ëŠ” PyTorch ë²„ì „
        pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121
    else
        echo "CPU ë²„ì „ PyTorch ì„¤ì¹˜ ì¤‘..."
        pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu
    fi

    # ì„¤ì¹˜ í™•ì¸
    python -c "
import torch
print(f'âœ… PyTorch {torch.__version__} ì„¤ì¹˜ ì™„ë£Œ (SGLang í˜¸í™˜)')
if torch.cuda.is_available():
    print(f'ğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}')
    print(f'ğŸ® CUDA ë²„ì „: {torch.version.cuda}')
    gpu_count = torch.cuda.device_count()
    print(f'ğŸ® GPU ê°œìˆ˜: {gpu_count}')

    # GPU ë©”ëª¨ë¦¬ í™•ì¸
    for i in range(gpu_count):
        props = torch.cuda.get_device_properties(i)
        memory_gb = props.total_memory / 1024**3
        print(f'ğŸ® GPU {i}: {props.name} ({memory_gb:.1f}GB)')
else:
    print('ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤')
"
}

# SGLang ì„¤ì¹˜ (ë©”ì¸)
install_sglang() {
    echo -e "\n${PURPLE}ğŸš€ SGLang ì„¤ì¹˜ (ë©”ì¸ í”„ë ˆì„ì›Œí¬)${NC}"

    if [ "$GPU_AVAILABLE" = true ]; then
        echo "GPU ë²„ì „ SGLang ì„¤ì¹˜ ì¤‘..."

        # SGLang ì½”ì–´ íŒ¨í‚¤ì§€ ì„¤ì¹˜
        echo "SGLang ì½”ì–´ íŒ¨í‚¤ì§€..."
        pip install "sglang[all]==0.2.6"

        # ì„±ëŠ¥ ìµœì í™” íŒ¨í‚¤ì§€ë“¤
        echo "SGLang ì„±ëŠ¥ ìµœì í™” íŒ¨í‚¤ì§€..."

        # FlashAttention (ì¤‘ìš”: SGLang ì„±ëŠ¥ì— í•µì‹¬)
        pip install flashinfer==0.0.5 --no-build-isolation || echo "âš ï¸ FlashInfer ì„¤ì¹˜ ì‹¤íŒ¨ (ì„±ëŠ¥ì— ì˜í–¥)"
        pip install flash-attn==2.3.6 --no-build-isolation || echo "âš ï¸ Flash Attention ì„¤ì¹˜ ì‹¤íŒ¨ (ëŒ€ì•ˆ ì‚¬ìš©)"

        # ì¶”ê°€ ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
        pip install triton==2.1.0 || echo "âš ï¸ Triton ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)"
        pip install xformers==0.0.22.post7 || echo "âš ï¸ xformers ì„¤ì¹˜ ì‹¤íŒ¨ (ëŒ€ì•ˆ ì¡´ì¬)"

    else
        echo "CPU ë²„ì „ SGLang ì„¤ì¹˜ ì¤‘..."
        # CPU ë²„ì „ì€ ì½”ì–´ íŒ¨í‚¤ì§€ë§Œ
        pip install "sglang[all]==0.2.6"
        echo -e "${YELLOW}âš ï¸ CPU ëª¨ë“œ: ì„±ëŠ¥ ìµœì í™” íŒ¨í‚¤ì§€ ìƒëµ${NC}"
    fi

    # SGLang ì„¤ì¹˜ ê²€ì¦
    python -c "
try:
    import sglang
    print(f'âœ… SGLang {sglang.__version__} ì„¤ì¹˜ ì™„ë£Œ')

    # SGLang ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    from sglang import function, system, user, assistant, gen, select
    print('âœ… SGLang í•µì‹¬ ê¸°ëŠ¥ import ì„±ê³µ')

    # í† í°í™” í…ŒìŠ¤íŠ¸
    from sglang.lang.backend.runtime_endpoint import RuntimeEndpoint
    print('âœ… SGLang ëŸ°íƒ€ì„ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš© ê°€ëŠ¥')

    # ì¶”ê°€ ì»´í¬ë„ŒíŠ¸ í™•ì¸
    try:
        from sglang.srt.server import launch_server
        print('âœ… SGLang ì„œë²„ ëŸ°ì²˜ ì‚¬ìš© ê°€ëŠ¥')
    except ImportError as e:
        print(f'âš ï¸ SGLang ì„œë²„ ëŸ°ì²˜ ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ: {e}')

    print('ğŸš€ SGLang ì¤€ë¹„ ì™„ë£Œ!')

except ImportError as e:
    print(f'âŒ SGLang import ì‹¤íŒ¨: {e}')
    print('ë‹¤ì‹œ ì„¤ì¹˜ë¥¼ ì‹œë„í•˜ê±°ë‚˜ ì˜ì¡´ì„±ì„ í™•ì¸í•˜ì„¸ìš”.')
    exit(1)
"

    echo -e "${GREEN}âœ… SGLang ì„¤ì¹˜ ì™„ë£Œ${NC}"
}

# í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
install_korean_packages() {
    echo -e "\n${BLUE}ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜${NC}"

    # Transformers ë° í† í¬ë‚˜ì´ì € (SGLang í˜¸í™˜ ë²„ì „)
    echo "Transformers ë° í† í¬ë‚˜ì´ì €..."
    pip install transformers==4.36.0
    pip install tokenizers==0.15.0
    pip install sentencepiece==0.1.99
    pip install protobuf==4.25.1

    # í•œêµ­ì–´ ëª¨ë¸ ì§€ì› ë¼ì´ë¸ŒëŸ¬ë¦¬
    echo "í•œêµ­ì–´ ëª¨ë¸ ì§€ì›..."
    pip install accelerate==0.25.0
    pip install safetensors==0.4.1

    # ì–‘ìí™” ì§€ì› (ì„ íƒì‚¬í•­)
    if [ "$GPU_AVAILABLE" = true ]; then
        pip install bitsandbytes==0.41.3 || echo "âš ï¸ bitsandbytes ì„¤ì¹˜ ì‹¤íŒ¨ (ì–‘ìí™” ê¸°ëŠ¥ ì œí•œ)"
    fi

    # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ì„ íƒì‚¬í•­)
    echo "í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬..."
    pip install hanja==0.15.1 || echo "âš ï¸ hanja ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)"
    pip install kss==4.5.4 || echo "âš ï¸ kss ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)"

    echo -e "${GREEN}âœ… í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ${NC}"
}

# ì›¹ ì„œë²„ ë° API íŒ¨í‚¤ì§€ ì„¤ì¹˜
install_web_packages() {
    echo -e "\n${BLUE}ğŸŒ ì›¹ ì„œë²„ ë° API íŒ¨í‚¤ì§€ ì„¤ì¹˜${NC}"

    # FastAPI ë° ì›¹ ì„œë²„ (SGLang í˜¸í™˜)
    echo "FastAPI ìŠ¤íƒ..."
    pip install fastapi==0.104.1
    pip install uvicorn[standard]==0.24.0
    pip install httpx==0.25.2
    pip install pydantic==2.5.0
    pip install pydantic-settings==2.1.0

    # SGLang ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
    echo "ìŠ¤íŠ¸ë¦¬ë° ë° ì‹¤ì‹œê°„ í†µì‹ ..."
    pip install sse-starlette==1.6.5
    pip install websockets==12.0
    pip install python-multipart==0.0.6

    # ì¶”ê°€ ì›¹ ìœ í‹¸ë¦¬í‹°
    pip install jinja2==3.1.2
    pip install python-jose==3.3.0
    pip install passlib==1.7.4

    echo -e "${GREEN}âœ… ì›¹ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ${NC}"
}

# ì €ì¥ì†Œ ë° ëª¨ë‹ˆí„°ë§ íŒ¨í‚¤ì§€ ì„¤ì¹˜
install_storage_packages() {
    echo -e "\n${BLUE}ğŸ’¾ ì €ì¥ì†Œ ë° ëª¨ë‹ˆí„°ë§ íŒ¨í‚¤ì§€ ì„¤ì¹˜${NC}"

    # ë°ì´í„° ì €ì¥ì†Œ
    echo "ë°ì´í„° ì €ì¥ì†Œ..."
    pip install redis==5.0.1
    pip install aiosqlite==0.19.0

    # ì„¤ì • ê´€ë¦¬
    echo "ì„¤ì • ê´€ë¦¬..."
    pip install PyYAML==6.0.1
    pip install python-dotenv==1.0.0
    pip install click==8.1.7

    # ëª¨ë‹ˆí„°ë§ ë° ëŒ€ì‹œë³´ë“œ
    echo "ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ..."
    pip install streamlit==1.28.2
    pip install plotly==5.17.0
    pip install pandas==2.1.4
    pip install numpy==1.24.4

    # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
    echo "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§..."
    pip install psutil==5.9.6

    # GPU ëª¨ë‹ˆí„°ë§ (GPU ìˆëŠ” ê²½ìš°)
    if [ "$GPU_AVAILABLE" = true ]; then
        pip install nvidia-ml-py3==7.352.0 || echo "âš ï¸ nvidia-ml-py3 ì„¤ì¹˜ ì‹¤íŒ¨ (GPU ëª¨ë‹ˆí„°ë§ ì œí•œ)"
        pip install pynvml==11.5.0 || echo "âš ï¸ pynvml ì„¤ì¹˜ ì‹¤íŒ¨ (GPU ëª¨ë‹ˆí„°ë§ ì œí•œ)"
    fi

    # ë©”íŠ¸ë¦­ ë° ë¡œê¹…
    pip install structlog==23.2.0
    pip install rich==13.7.0

    echo -e "${GREEN}âœ… ì €ì¥ì†Œ ë° ëª¨ë‹ˆí„°ë§ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ${NC}"
}

# ê°œë°œ ë° í…ŒìŠ¤íŠ¸ ë„êµ¬ ì„¤ì¹˜
install_dev_tools() {
    echo -e "\n${BLUE}ğŸ› ï¸ ê°œë°œ ë„êµ¬ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)${NC}"

    read -p "ê°œë°œ ë„êµ¬(Jupyter, pytest ë“±)ë¥¼ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then

        # Jupyter ë° ë…¸íŠ¸ë¶ ë„êµ¬
        echo "Jupyter í™˜ê²½..."
        pip install jupyter==1.0.0
        pip install notebook==7.0.6
        pip install ipykernel==6.26.0
        pip install ipywidgets==8.1.1

        # í…ŒìŠ¤íŠ¸ ë„êµ¬
        echo "í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬..."
        pip install pytest==7.4.3
        pip install pytest-asyncio==0.21.1
        pip install httpx-ws==0.4.2
        pip install pytest-mock==3.12.0

        # ì½”ë“œ í’ˆì§ˆ ë„êµ¬
        echo "ì½”ë“œ í’ˆì§ˆ ë„êµ¬..."
        pip install black==23.11.0
        pip install flake8==6.1.0
        pip install isort==5.12.0
        pip install mypy==1.7.1

        # SGLang ê°œë°œ ë„êµ¬
        echo "SGLang ì „ìš© ê°œë°œ ë„êµ¬..."
        pip install gradio==4.8.0 || echo "âš ï¸ Gradio ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)"

        echo -e "${GREEN}âœ… ê°œë°œ ë„êµ¬ ì„¤ì¹˜ ì™„ë£Œ${NC}"
    else
        echo "ê°œë°œ ë„êµ¬ ì„¤ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
    fi
}

# í•œêµ­ì–´ ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ
download_korean_models() {
    echo -e "\n${BLUE}ğŸ‡°ğŸ‡· í•œêµ­ì–´ ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ (ì„ íƒì‚¬í•­)${NC}"

    read -p "í•œêµ­ì–´ ëª¨ë¸ì„ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then

        echo "ì‚¬ìš© ê°€ëŠ¥í•œ SGLang í˜¸í™˜ í•œêµ­ì–´ ëª¨ë¸:"
        echo "1. Qwen/Qwen2.5-3B-Instruct (ê¶Œì¥ - 3B, ë¹ ë¦„, SGLang ìµœì í™”)"
        echo "2. beomi/Llama-3-Open-Ko-8B (8B, ë†’ì€ í’ˆì§ˆ)"
        echo "3. upstage/SOLAR-10.7B-Instruct-v1.0 (11B, ìµœê³  í’ˆì§ˆ)"
        echo "4. microsoft/DialoGPT-medium (í…ŒìŠ¤íŠ¸ìš© - 350MB)"
        echo "5. ê±´ë„ˆë›°ê¸°"

        read -p "ì„ íƒí•˜ì„¸ìš” (1-5): " -n 1 -r
        echo

        case $REPLY in
            1)
                MODEL_NAME="Qwen/Qwen2.5-3B-Instruct"
                echo "ğŸš€ SGLang ìµœì í™” ëª¨ë¸ ì„ íƒ!"
                ;;
            2)
                MODEL_NAME="beomi/Llama-3-Open-Ko-8B"
                ;;
            3)
                MODEL_NAME="upstage/SOLAR-10.7B-Instruct-v1.0"
                ;;
            4)
                MODEL_NAME="microsoft/DialoGPT-medium"
                echo "âš¡ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ëª¨ë¸ ì„ íƒ"
                ;;
            *)
                echo "ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
                return 0
                ;;
        esac

        echo "SGLang í˜¸í™˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: $MODEL_NAME"

        python -c "
from transformers import AutoTokenizer, AutoConfig
import torch

model_name = '$MODEL_NAME'
print(f'ğŸ”½ SGLang í˜¸í™˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: {model_name}')

try:
    # í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ
    print('ğŸ“ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì¤‘...')
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True,
        cache_dir='./tokenizer_cache'
    )
    print(f'âœ… í† í¬ë‚˜ì´ì € ì™„ë£Œ (ì–´íœ˜ í¬ê¸°: {len(tokenizer):,})')

    # ëª¨ë¸ ì„¤ì • ë‹¤ìš´ë¡œë“œ
    print('âš™ï¸ ëª¨ë¸ ì„¤ì • ë‹¤ìš´ë¡œë“œ ì¤‘...')
    config = AutoConfig.from_pretrained(
        model_name,
        trust_remote_code=True,
        cache_dir='./tokenizer_cache'
    )
    print(f'âœ… ì„¤ì • ì™„ë£Œ (ìˆ¨ê²¨ì§„ í¬ê¸°: {getattr(config, \"hidden_size\", \"Unknown\")})')

    # SGLang í˜¸í™˜ì„± í™•ì¸
    print('ğŸ” SGLang í˜¸í™˜ì„± í™•ì¸...')

    # í† í°í™” í…ŒìŠ¤íŠ¸
    test_text = 'ì•ˆë…•í•˜ì„¸ìš”! SGLangìœ¼ë¡œ í•œêµ­ì–´ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.'
    tokens = tokenizer.encode(test_text)
    decoded = tokenizer.decode(tokens)

    print(f'âœ… í† í°í™” í…ŒìŠ¤íŠ¸ ì„±ê³µ')
    print(f'   ì›ë³¸: {test_text}')
    print(f'   í† í° ìˆ˜: {len(tokens)}')
    print(f'   ë³µì›: {decoded}')

    print(f'ğŸš€ {model_name} SGLang ì¤€ë¹„ ì™„ë£Œ!')

except Exception as e:
    print(f'âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}')
    print('SGLang ì„œë²„ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.')
"

        echo -e "${GREEN}âœ… í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ${NC}"
    else
        echo "ëª¨ë¸ì€ SGLang ì„œë²„ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤."
    fi
}

# ì„¤ì¹˜ ê²€ì¦ ë° SGLang í…ŒìŠ¤íŠ¸
verify_installation() {
    echo -e "\n${BLUE}ğŸ§ª SGLang ì„¤ì¹˜ ê²€ì¦${NC}"

    python -c "
import sys
print(f'ğŸ Python: {sys.version}')
print(f'ğŸ“ ê²½ë¡œ: {sys.executable}')

# í™˜ê²½ ì •ë³´
import os
if 'CONDA_DEFAULT_ENV' in os.environ:
    print(f'ğŸŒ Conda: {os.environ[\"CONDA_DEFAULT_ENV\"]}')
elif 'VIRTUAL_ENV' in os.environ:
    print(f'ğŸŒ venv: {os.environ[\"VIRTUAL_ENV\"]}')

print('\nğŸ“¦ í•µì‹¬ íŒ¨í‚¤ì§€ í™•ì¸:')

# SGLang í•µì‹¬ í™•ì¸
try:
    import sglang
    print(f'ğŸš€ SGLang: {sglang.__version__} âœ…')

    # SGLang ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    from sglang import function, system, user, assistant, gen
    print('   â”œâ”€ í•µì‹¬ ê¸°ëŠ¥: âœ…')

    try:
        from sglang.srt.server import launch_server
        print('   â”œâ”€ ì„œë²„ ëŸ°ì²˜: âœ…')
    except:
        print('   â”œâ”€ ì„œë²„ ëŸ°ì²˜: âš ï¸')

except ImportError as e:
    print(f'ğŸš€ SGLang: âŒ ({e})')

# ê¸°ë³¸ íŒ¨í‚¤ì§€ë“¤
packages = [
    ('torch', 'PyTorch'),
    ('transformers', 'Transformers'),
    ('fastapi', 'FastAPI'),
    ('streamlit', 'Streamlit'),
    ('redis', 'Redis'),
    ('pandas', 'Pandas'),
    ('yaml', 'PyYAML'),
    ('pydantic', 'Pydantic')
]

for pkg, name in packages:
    try:
        if pkg == 'yaml':
            import yaml as module
        else:
            module = __import__(pkg)
        version = getattr(module, '__version__', 'Unknown')
        print(f'{name}: {version} âœ…')
    except ImportError:
        print(f'{name}: âŒ')

print('\nğŸ® GPU ë° ê°€ì†:')
try:
    import torch
    if torch.cuda.is_available():
        print(f'CUDA: {torch.version.cuda} âœ…')
        print(f'GPU: {torch.cuda.get_device_name()} âœ…')
        memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f'ë©”ëª¨ë¦¬: {memory:.1f}GB âœ…')

        # Flash Attention í™•ì¸
        try:
            import flash_attn
            print(f'Flash Attention: âœ…')
        except ImportError:
            print(f'Flash Attention: âš ï¸ (ì„±ëŠ¥ ì œí•œ)')

        # FlashInfer í™•ì¸ (SGLang í•µì‹¬)
        try:
            import flashinfer
            print(f'FlashInfer: âœ… (SGLang ìµœì í™”)')
        except ImportError:
            print(f'FlashInfer: âš ï¸ (SGLang ì„±ëŠ¥ ì œí•œ)')

    else:
        print('GPU: CPU ëª¨ë“œ ğŸ’»')
except Exception as e:
    print(f'GPU í™•ì¸ ì‹¤íŒ¨: {e}')

# ìŠ¤íŠ¸ë¦¬ë° ì§€ì› í™•ì¸
try:
    from sse_starlette.sse import EventSourceResponse
    print('SSE ìŠ¤íŠ¸ë¦¬ë°: âœ…')
except ImportError:
    print('SSE ìŠ¤íŠ¸ë¦¬ë°: âŒ')

print('\nğŸš€ SGLang ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ:')

# ì¢…í•© ì ìˆ˜ ê³„ì‚°
score = 0
try:
    import sglang; score += 30
except: pass
try:
    import torch; score += 20
    if torch.cuda.is_available(): score += 20
except: pass
try:
    import transformers; score += 10
except: pass
try:
    import fastapi; score += 10
except: pass
try:
    import flashinfer; score += 10
except: pass

if score >= 90:
    print('ğŸŒŸ ì™„ë²½ (90+ì ) - SGLang ìµœê³  ì„±ëŠ¥')
elif score >= 70:
    print('âœ¨ ìš°ìˆ˜ (70+ì ) - SGLang ê³ ì„±ëŠ¥')
elif score >= 50:
    print('âœ… ì–‘í˜¸ (50+ì ) - SGLang ê¸°ë³¸ ì„±ëŠ¥')
else:
    print('âš ï¸ ì œí•œì  ({score}ì ) - ì¶”ê°€ ì„¤ì¹˜ í•„ìš”')

print(f'ì¢…í•© ì ìˆ˜: {score}/100')
"
}

# ì™„ë£Œ ì•ˆë‚´ ë° ë‹¤ìŒ ë‹¨ê³„
show_completion_info() {
    echo ""
    echo "========================================"
    echo -e "${GREEN}ğŸ‰ SGLang íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!${NC}"
    echo "========================================"
    echo ""
    echo -e "${BLUE}ğŸ“‹ ì„¤ì¹˜ ìš”ì•½:${NC}"
    echo "Framework: SGLang (ê³ ì„±ëŠ¥ LLM ì„œë¹™)"
    echo "Python: $(python --version)"
    echo "Environment: $([ ! -z "$CONDA_DEFAULT_ENV" ] && echo "Conda ($CONDA_DEFAULT_ENV)" || echo "$([ ! -z "$VIRTUAL_ENV" ] && echo "venv" || echo "System")")"
    echo "GPU Support: $([ "$GPU_AVAILABLE" = true ] && echo "í™œì„±í™”" || echo "CPU ëª¨ë“œ")"

    echo ""
    echo -e "${BLUE}ğŸš€ ë‹¤ìŒ ë‹¨ê³„:${NC}"
    echo ""
    echo "1. ì„¤ì • íŒŒì¼ í™•ì¸:"
    echo "   ls config/sglang_*.yaml"
    echo ""
    echo "2. Redis ì‹œì‘ (ì„ íƒì‚¬í•­):"
    echo "   docker run -d --name korean-redis -p 6379:6379 redis:alpine"
    echo ""
    echo "3. SGLang ì‹œìŠ¤í…œ ì‹œì‘:"
    echo "   bash scripts/start_korean_sglang.sh"
    echo ""
    echo "4. ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:"
    echo "   bash scripts/test_sglang_korean.sh"
    echo ""
    echo "5. ëŒ€ì‹œë³´ë“œ ì‹œì‘:"
    echo "   streamlit run dashboard/sglang_app.py --server.port 8501"
    echo ""
    echo -e "${BLUE}ğŸ’¡ SGLang ìµœì í™” íŒ:${NC}"
    echo "- GPU ë©”ëª¨ë¦¬ 8GB ì´í•˜: --mem-fraction-static 0.6"
    echo "- ë™ì‹œ ì‚¬ìš©ì ë§ìŒ: --max-running-requests 20"
    echo "- ê¸´ ì»¨í…ìŠ¤íŠ¸: --chunked-prefill-size 8192"
    echo "- ìºì‹œ ìµœì í™”: --enable-prefix-caching"
    echo ""
    echo -e "${BLUE}ğŸ”§ ë¬¸ì œ í•´ê²°:${NC}"
    echo "- SGLang í…ŒìŠ¤íŠ¸: python -c 'import sglang; print(sglang.__version__)'"
    echo "- GPU í™•ì¸: nvidia-smi"
    echo "- Flash ë¼ì´ë¸ŒëŸ¬ë¦¬: python -c 'import flashinfer' (ì¤‘ìš”)"
    echo "- ë¡œê·¸ í™•ì¸: tail -f logs/sglang_server.log"
    echo ""
    echo -e "${PURPLE}ğŸŒŸ SGLang vs vLLM ì˜ˆìƒ ì„±ëŠ¥:${NC}"
    echo "- ì²˜ë¦¬ëŸ‰: 20-30% í–¥ìƒ"
    echo "- ì§€ì—°ì‹œê°„: 25% ë‹¨ì¶•"
    echo "- ë©”ëª¨ë¦¬ íš¨ìœ¨: 15% ê°œì„ "
    echo "- ë™ì‹œ ì‚¬ìš©ì: 2ë°° ì¦ê°€"

    # ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ ì €ì¥
    echo ""
    echo "íŒ¨í‚¤ì§€ ëª©ë¡ ì €ì¥ ì¤‘..."
    pip freeze > installed_sglang_packages_$(date +%Y%m%d_%H%M%S).txt
    echo -e "${GREEN}âœ… íŒ¨í‚¤ì§€ ëª©ë¡ ì €ì¥ ì™„ë£Œ${NC}"

    echo ""
    echo "SGLang ì„¤ì¹˜ ì™„ë£Œ ì‹œê°„: $(date)"
    echo ""
    echo -e "${PURPLE}ğŸš€ SGLangìœ¼ë¡œ í•œêµ­ì–´ AIì˜ ìƒˆë¡œìš´ ì„±ëŠ¥ì„ ê²½í—˜í•˜ì„¸ìš”!${NC}"
}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
main() {
    echo "SGLang ì„¤ì¹˜ ì‹œì‘ ì‹œê°„: $(date)"
    echo ""

    check_environment
    upgrade_basic_tools
    install_pytorch
    install_sglang
    install_korean_packages
    install_web_packages
    install_storage_packages
    install_dev_tools
    download_korean_models
    verify_installation
    show_completion_info
}

# ë„ì›€ë§
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "SGLang ê¸°ë°˜ Korean Token Limiter ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸"
    echo ""
    echo "ì‚¬ìš©ë²•:"
    echo "  $0              # ì „ì²´ ì„¤ì¹˜"
    echo "  $0 --gpu-only   # GPU íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜"
    echo "  $0 --cpu-only   # CPU ì „ìš© ì„¤ì¹˜"
    echo "  $0 --minimal    # SGLang í•µì‹¬ë§Œ ì„¤ì¹˜"
    echo "  $0 --help       # ì´ ë„ì›€ë§ í‘œì‹œ"
    echo ""
    echo "ì˜µì…˜:"
    echo "  --gpu-only      GPU ë° SGLang ê³ ì„±ëŠ¥ íŒ¨í‚¤ì§€ë§Œ"
    echo "  --cpu-only      CPU ì „ìš© (ì„±ëŠ¥ ì œí•œ)"
    echo "  --minimal       SGLang + í•µì‹¬ íŒ¨í‚¤ì§€ë§Œ"
    echo "  --skip-models   ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸°"
    echo ""
    echo "ìš”êµ¬ì‚¬í•­:"
    echo "  - Python 3.10+ (SGLang í•„ìˆ˜)"
    echo "  - NVIDIA GPU + CUDA 12.1+ (ê¶Œì¥)"
    echo "  - 8GB+ RAM (16GB ê¶Œì¥)"
    echo "  - 15GB+ ë””ìŠ¤í¬ ê³µê°„"
    echo ""
    echo "SGLang íŠ¹ì§•:"
    echo "  - vLLM ëŒ€ë¹„ 20-30% ì„±ëŠ¥ í–¥ìƒ"
    echo "  - ë™ì  ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ìµœì í™”"
    echo "  - KV ìºì‹œ ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ"
    echo "  - í•œêµ­ì–´ ëª¨ë¸ì— íŠ¹í™”ëœ ìµœì í™”"
    echo ""
    exit 0
fi

# ì˜µì…˜ ì²˜ë¦¬
if [ "$1" = "--cpu-only" ]; then
    echo -e "${YELLOW}âš ï¸ CPU ì „ìš© ì„¤ì¹˜ (ì„±ëŠ¥ ì œí•œ)${NC}"
    GPU_AVAILABLE=false
elif [ "$1" = "--gpu-only" ]; then
    echo -e "${PURPLE}ğŸ® GPU ê³ ì„±ëŠ¥ ì„¤ì¹˜${NC}"
    GPU_AVAILABLE=true
elif [ "$1" = "--minimal" ]; then
    echo -e "${BLUE}ğŸ“¦ ìµœì†Œ ì„¤ì¹˜ (SGLang í•µì‹¬ë§Œ)${NC}"
    MINIMAL_INSTALL=true
fi

# ë©”ì¸ ì‹¤í–‰
main "$@"