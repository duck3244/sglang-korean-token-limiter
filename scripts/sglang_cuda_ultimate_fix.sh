#!/bin/bash
# SGLang CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ê·¼ë³¸ì  í•´ê²° ìŠ¤í¬ë¦½íŠ¸

set -e

echo "ðŸ”§ SGLang CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ê·¼ë³¸ì  í•´ê²°"
echo "======================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

echo -e "${BLUE}ðŸ” SGLang ë‚´ë¶€ ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì • ìˆ˜ì •...${NC}"

# SGLang ì†ŒìŠ¤ ì½”ë“œ ìˆ˜ì •ì„ ìœ„í•œ Python ìŠ¤í¬ë¦½íŠ¸
python -c "
import os
import sys
import site

print('SGLang ë‚´ë¶€ ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì • ìˆ˜ì •...')

# SGLang íŒ¨í‚¤ì§€ ê²½ë¡œ ì°¾ê¸°
sglang_path = None
for path in sys.path:
    potential_path = os.path.join(path, 'sglang')
    if os.path.exists(potential_path):
        sglang_path = potential_path
        break

if not sglang_path:
    # site-packagesì—ì„œ ì°¾ê¸°
    for site_path in site.getsitepackages():
        potential_path = os.path.join(site_path, 'sglang')
        if os.path.exists(potential_path):
            sglang_path = potential_path
            break

if sglang_path:
    print(f'SGLang ê²½ë¡œ: {sglang_path}')
    
    # ì£¼ìš” ìˆ˜ì • íŒŒì¼ë“¤
    files_to_modify = [
        'launch_server.py',
        'srt/server.py',
        'srt/managers/controller_single.py',
        'srt/managers/tp_worker.py'
    ]
    
    for file_name in files_to_modify:
        file_path = os.path.join(sglang_path, file_name)
        if os.path.exists(file_path):
            print(f'ìˆ˜ì • ì¤‘: {file_name}')
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ë©€í‹°í”„ë¡œì„¸ì‹± spawn ì„¤ì • ì¶”ê°€
            if 'import multiprocessing' not in content and 'multiprocessing' in content:
                # multiprocessing import ì¶”ê°€
                if 'import os' in content:
                    content = content.replace('import os', '''import os
import multiprocessing

# CUDA ë©€í‹°í”„ë¡œì„¸ì‹± í•´ê²°ì„ ìœ„í•œ spawn ì„¤ì •
try:
    multiprocessing.set_start_method('spawn', force=True)
except RuntimeError:
    pass''')
                else:
                    content = '''import multiprocessing

# CUDA ë©€í‹°í”„ë¡œì„¸ì‹± í•´ê²°ì„ ìœ„í•œ spawn ì„¤ì •
try:
    multiprocessing.set_start_method('spawn', force=True)
except RuntimeError:
    pass

''' + content
            
            # ê¸°ì¡´ì— import multiprocessingì´ ìžˆë‹¤ë©´ spawn ì„¤ì • ì¶”ê°€
            elif 'import multiprocessing' in content and 'set_start_method' not in content:
                content = content.replace('import multiprocessing', '''import multiprocessing

# CUDA ë©€í‹°í”„ë¡œì„¸ì‹± í•´ê²°ì„ ìœ„í•œ spawn ì„¤ì •
try:
    multiprocessing.set_start_method('spawn', force=True)
except RuntimeError:
    pass''')
            
            # íŒŒì¼ ì €ìž¥
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f'âœ… {file_name} ìˆ˜ì • ì™„ë£Œ')
        else:
            print(f'âŒ {file_name} íŒŒì¼ ì—†ìŒ')
    
    print('âœ… SGLang ë‚´ë¶€ ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì • ìˆ˜ì • ì™„ë£Œ')
else:
    print('âŒ SGLang íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
"

echo -e "${GREEN}âœ… SGLang ë‚´ë¶€ ìˆ˜ì • ì™„ë£Œ${NC}"

# CPU ëª¨ë“œ ê°•ì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
echo -e "\n${BLUE}ðŸ“ CPU ëª¨ë“œ ê°•ì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...${NC}"

cat > start_sglang_cpu_mode.py << 'EOF'
#!/usr/bin/env python3
"""
SGLang CPU ëª¨ë“œ ê°•ì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (CUDA ë¬¸ì œ íšŒí”¼)
"""

import sys
import os
import subprocess
import time
import requests
import multiprocessing

def force_cpu_mode():
    """CPU ëª¨ë“œ ê°•ì œ ì„¤ì •"""
    
    print("ðŸ’» CPU ëª¨ë“œ ê°•ì œ ì„¤ì •...")
    
    # CUDA ë¹„í™œì„±í™” í™˜ê²½ ë³€ìˆ˜
    env_vars = {
        'CUDA_VISIBLE_DEVICES': '',  # CUDA ì™„ì „ ë¹„í™œì„±í™”
        'TORCH_MULTIPROCESSING_START_METHOD': 'spawn',
        'TOKENIZERS_PARALLELISM': 'false',
        'SGLANG_DISABLE_FLASHINFER_WARNING': '1'
    }
    
    for key, value in env_vars.items():
        os.environ[key] = value
        print(f"ðŸ”§ {key}={value}")

def start_sglang_cpu(model_path="microsoft/DialoGPT-medium", port=8000):
    """SGLang CPU ëª¨ë“œë¡œ ì‹œìž‘"""
    
    print("ðŸš€ SGLang CPU ëª¨ë“œ ì‹œìž‘")
    print(f"ëª¨ë¸: {model_path}")
    print(f"í¬íŠ¸: {port}")
    
    # CPU ëª¨ë“œ ê°•ì œ ì„¤ì •
    force_cpu_mode()
    
    # ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì •
    try:
        multiprocessing.set_start_method('spawn', force=True)
        print(f"âœ… ë©€í‹°í”„ë¡œì„¸ì‹±: {multiprocessing.get_start_method()}")
    except RuntimeError:
        pass
    
    # CPU ì „ìš© ëª…ë ¹ì–´
    cmd = [
        sys.executable, "-m", "sglang.launch_server",
        "--model-path", model_path,
        "--port", str(port),
        "--host", "127.0.0.1",
        "--trust-remote-code",
        "--max-running-requests", "2",  # CPU ëª¨ë“œì—ì„œëŠ” ì ê²Œ
        "--max-total-tokens", "1024",   # í† í° ìˆ˜ ì œí•œ
        "--dtype", "float32",           # CPU í˜¸í™˜ íƒ€ìž…
        "--disable-cuda-graph",
        "--disable-flashinfer"
    ]
    
    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")
    
    try:
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("logs", exist_ok=True)
        
        # ì„œë²„ ì‹œìž‘
        with open("logs/sglang_cpu.log", "w") as log_file:
            process = subprocess.Popen(
                cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                env=os.environ.copy()
            )
        
        print(f"âœ… CPU ëª¨ë“œ ì„œë²„ ì‹œìž‘ (PID: {process.pid})")
        
        # ì„œë²„ ì¤€ë¹„ ëŒ€ê¸°
        print("â³ CPU ëª¨ë“œ ì„œë²„ ì¤€ë¹„ ëŒ€ê¸°...")
        for i in range(180):  # CPU ëª¨ë“œëŠ” ë” ì˜¤ëž˜ ê±¸ë¦´ ìˆ˜ ìžˆìŒ
            if process.poll() is not None:
                print("âŒ ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨")
                return None
            
            try:
                response = requests.get(f"http://127.0.0.1:{port}/get_model_info", timeout=5)
                if response.status_code == 200:
                    print(f"âœ… CPU ëª¨ë“œ ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! ({i+1}ì´ˆ)")
                    
                    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
                    try:
                        model_info = response.json()
                        print(f"ëª¨ë¸: {model_info.get('model_path', 'Unknown')}")
                    except:
                        pass
                    
                    return process
            except:
                pass
            
            if i % 30 == 0 and i > 0:
                print(f"ëŒ€ê¸° ì¤‘... {i}ì´ˆ (CPU ëª¨ë“œëŠ” ëŠë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤)")
            
            time.sleep(1)
        
        print("âŒ CPU ëª¨ë“œ ì„œë²„ ì‹œìž‘ ì‹œê°„ ì´ˆê³¼")
        process.terminate()
        return None
        
    except Exception as e:
        print(f"âŒ CPU ëª¨ë“œ ì„œë²„ ì‹œìž‘ ì‹¤íŒ¨: {e}")
        return None

def main():
    print("ðŸ’» SGLang CPU ëª¨ë“œ (CUDA ë¬¸ì œ íšŒí”¼)")
    print("=" * 50)
    
    model_path = sys.argv[1] if len(sys.argv) > 1 else "microsoft/DialoGPT-medium"
    port = int(sys.argv[2]) if len(sys.argv) > 2 else 8000
    
    process = start_sglang_cpu(model_path, port)
    
    if process:
        print("\nðŸŽ‰ SGLang CPU ëª¨ë“œ ì„±ê³µ!")
        print("=" * 50)
        print()
        print("ðŸ’¡ CPU ëª¨ë“œ íŠ¹ì§•:")
        print("   - CUDA ë¬¸ì œ ì™„ì „ íšŒí”¼")
        print("   - ì†ë„ëŠ” ëŠë¦¬ì§€ë§Œ ì•ˆì •ì ")
        print("   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì ìŒ")
        print()
        print("ðŸ§ª í…ŒìŠ¤íŠ¸:")
        print(f"curl http://127.0.0.1:{port}/get_model_info")
        print()
        print("ðŸ‡°ðŸ‡· Token Limiter (ë‹¤ë¥¸ í„°ë¯¸ë„):")
        print("python main_sglang.py")
        print()
        print("ðŸ›‘ ì¢…ë£Œ: Ctrl+C")
        
        try:
            process.wait()
        except KeyboardInterrupt:
            print("\nðŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘...")
            process.terminate()
            process.wait()
            print("âœ… ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")
    else:
        print("âŒ CPU ëª¨ë“œ ì„œë²„ ì‹œìž‘ ì‹¤íŒ¨")
        
        if os.path.exists("logs/sglang_cpu.log"):
            print("\n=== CPU ëª¨ë“œ ë¡œê·¸ ===")
            with open("logs/sglang_cpu.log", "r") as f:
                print(f.read()[-2000:])
        
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
EOF

chmod +x start_sglang_cpu_mode.py

echo -e "${GREEN}âœ… CPU ëª¨ë“œ ê°•ì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: start_sglang_cpu_mode.py${NC}"

# ëŒ€ì•ˆ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (Docker ì‚¬ìš©)
echo -e "\n${BLUE}ðŸ“ Docker ê¸°ë°˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...${NC}"

cat > start_sglang_docker.sh << 'EOF'
#!/bin/bash
# SGLang Docker ê¸°ë°˜ ì‹¤í–‰ (CUDA ë¬¸ì œ ì™„ì „ íšŒí”¼)

echo "ðŸ³ SGLang Docker ê¸°ë°˜ ì‹¤í–‰"
echo "========================="

MODEL_PATH="${1:-microsoft/DialoGPT-medium}"
PORT="${2:-8000}"

echo "ëª¨ë¸: $MODEL_PATH"
echo "í¬íŠ¸: $PORT"

# Docker ì´ë¯¸ì§€ í™•ì¸
if ! docker images | grep -q "sglang"; then
    echo "SGLang Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
    
    # Dockerfile ìƒì„±
    cat > Dockerfile.sglang << 'DOCKER_EOF'
FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-devel

# SGLang ì„¤ì¹˜
RUN pip install "sglang[all]==0.2.15" --no-cache-dir

# ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì •
ENV TORCH_MULTIPROCESSING_START_METHOD=spawn
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
ENV TOKENIZERS_PARALLELISM=false

WORKDIR /app

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì‹œìž‘ ëª…ë ¹ì–´
ENTRYPOINT ["python", "-m", "sglang.launch_server"]
DOCKER_EOF

    # Docker ì´ë¯¸ì§€ ë¹Œë“œ
    docker build -f Dockerfile.sglang -t sglang:latest .
    
    if [ $? -eq 0 ]; then
        echo "âœ… SGLang Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ"
    else
        echo "âŒ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨"
        exit 1
    fi
fi

# Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
echo "SGLang Docker ì»¨í…Œì´ë„ˆ ì‹œìž‘..."

docker run -d \
    --name sglang-korean \
    --gpus all \
    -p $PORT:8000 \
    -e TORCH_MULTIPROCESSING_START_METHOD=spawn \
    -e PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \
    sglang:latest \
    --model-path "$MODEL_PATH" \
    --host 0.0.0.0 \
    --port 8000 \
    --trust-remote-code \
    --mem-fraction-static 0.7 \
    --max-running-requests 4

if [ $? -eq 0 ]; then
    echo "âœ… SGLang Docker ì»¨í…Œì´ë„ˆ ì‹œìž‘ ì™„ë£Œ"
    
    # ì»¨í…Œì´ë„ˆ ì¤€ë¹„ ëŒ€ê¸°
    echo "â³ ì»¨í…Œì´ë„ˆ ì¤€ë¹„ ëŒ€ê¸°..."
    for i in {1..60}; do
        if curl -s http://localhost:$PORT/get_model_info > /dev/null 2>&1; then
            echo "âœ… SGLang Docker ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!"
            break
        fi
        sleep 2
    done
    
    echo ""
    echo "ðŸ³ Docker ì»¨í…Œì´ë„ˆ ì •ë³´:"
    docker ps | grep sglang-korean
    
    echo ""
    echo "ðŸ“‹ ê´€ë¦¬ ëª…ë ¹ì–´:"
    echo "  ë¡œê·¸ í™•ì¸: docker logs sglang-korean"
    echo "  ì»¨í…Œì´ë„ˆ ì¤‘ì§€: docker stop sglang-korean"
    echo "  ì»¨í…Œì´ë„ˆ ì œê±°: docker rm sglang-korean"
    
else
    echo "âŒ Docker ì»¨í…Œì´ë„ˆ ì‹œìž‘ ì‹¤íŒ¨"
    exit 1
fi
EOF

chmod +x start_sglang_docker.sh

echo -e "${GREEN}âœ… Docker ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: start_sglang_docker.sh${NC}"

# ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ìƒì„±
echo -e "\n${BLUE}ðŸ“ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ìƒì„±...${NC}"

cat > sglang_troubleshooting_guide.md << 'EOF'
# SGLang CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

## ðŸ” ë¬¸ì œ ë¶„ì„
```
RuntimeError: Cannot re-initialize CUDA in forked subprocess. 
To use CUDA with multiprocessing, you must use the 'spawn' start method
```

## ðŸ’¡ í•´ê²° ë°©ë²• (ìš°ì„ ìˆœìœ„ë³„)

### 1. CPU ëª¨ë“œ ì‹¤í–‰ (ê°€ìž¥ ì•ˆì •ì )
```bash
python start_sglang_cpu_mode.py
```
**ìž¥ì **: CUDA ë¬¸ì œ ì™„ì „ íšŒí”¼, ì•ˆì •ì 
**ë‹¨ì **: ì†ë„ ëŠë¦¼

### 2. Docker ì‹¤í–‰ (ê¶Œìž¥)
```bash
bash start_sglang_docker.sh
```
**ìž¥ì **: ì™„ì „ ê²©ë¦¬ëœ í™˜ê²½, CUDA ë¬¸ì œ í•´ê²°
**ë‹¨ì **: Docker ì„¤ì¹˜ í•„ìš”

### 3. í™˜ê²½ ë³€ìˆ˜ + ìž¬ì‹œìž‘
```bash
export TORCH_MULTIPROCESSING_START_METHOD=spawn
export CUDA_VISIBLE_DEVICES=0
python -m sglang.launch_server --model-path microsoft/DialoGPT-medium
```

### 4. ì™„ì „ ìƒˆë¡œìš´ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
```bash
# ìƒˆ í„°ë¯¸ë„ ì—´ê¸°
conda activate sglang_korean
export TORCH_MULTIPROCESSING_START_METHOD=spawn
python start_sglang_cpu_mode.py
```

## ðŸŽ¯ RTX 4060 íŠ¹í™” ê¶Œìž¥ì‚¬í•­

1. **CPU ëª¨ë“œ ì‚¬ìš©** (ê°€ìž¥ ì•ˆì •ì )
2. **ë©”ëª¨ë¦¬ ì œí•œ**: `--mem-fraction-static 0.6`
3. **ë™ì‹œ ìš”ì²­ ì œí•œ**: `--max-running-requests 2`
4. **í† í° ì œí•œ**: `--max-total-tokens 1024`

## ðŸ“Š ì„±ëŠ¥ ë¹„êµ

| ëª¨ë“œ | ì†ë„ | ì•ˆì •ì„± | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|------|------|--------|---------------|
| GPU (ë¬¸ì œ ìžˆìŒ) | â­â­â­â­â­ | â­â­ | ë†’ìŒ |
| CPU | â­â­ | â­â­â­â­â­ | ë‚®ìŒ |
| Docker | â­â­â­â­ | â­â­â­â­â­ | ì¤‘ê°„ |

## ðŸ”§ ë””ë²„ê¹… ëª…ë ¹ì–´

```bash
# ë©€í‹°í”„ë¡œì„¸ì‹± ë°©ë²• í™•ì¸
python -c "import multiprocessing; print(multiprocessing.get_start_method())"

# CUDA ìƒíƒœ í™•ì¸
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $TORCH_MULTIPROCESSING_START_METHOD
echo $CUDA_VISIBLE_DEVICES
```
EOF

echo -e "${GREEN}âœ… ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ìƒì„±: sglang_troubleshooting_guide.md${NC}"

# í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
echo -e "\n${BLUE}ðŸ“ í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...${NC}"

cat > run_sglang_ultimate.sh << 'EOF'
#!/bin/bash
# SGLang ê¶ê·¹ì  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ëª¨ë“  í•´ê²°ì±… í†µí•©)

echo "ðŸš€ SGLang ê¶ê·¹ì  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
echo "=============================="

MODEL_PATH="${1:-microsoft/DialoGPT-medium}"
PORT="${2:-8000}"

echo "ëª¨ë¸: $MODEL_PATH"
echo "í¬íŠ¸: $PORT"
echo ""

echo "ì„ íƒí•˜ì„¸ìš”:"
echo "1) CPU ëª¨ë“œ (ê°€ìž¥ ì•ˆì •ì , ëŠë¦¼)"
echo "2) Docker ëª¨ë“œ (ê¶Œìž¥, ë¹ ë¦„)"
echo "3) GPU ëª¨ë“œ ìž¬ì‹œë„ (ìœ„í—˜)"
echo "4) ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ë³´ê¸°"

read -p "ì„ íƒ (1-4): " choice

case $choice in
    1)
        echo "ðŸ’» CPU ëª¨ë“œ ì‹¤í–‰..."
        python start_sglang_cpu_mode.py "$MODEL_PATH" "$PORT"
        ;;
    2)
        echo "ðŸ³ Docker ëª¨ë“œ ì‹¤í–‰..."
        bash start_sglang_docker.sh "$MODEL_PATH" "$PORT"
        ;;
    3)
        echo "âš ï¸ GPU ëª¨ë“œ ìž¬ì‹œë„..."
        export TORCH_MULTIPROCESSING_START_METHOD=spawn
        python start_sglang_cuda_fixed.py --model "$MODEL_PATH" --port "$PORT"
        ;;
    4)
        echo "ðŸ“– ë¬¸ì œ í•´ê²° ê°€ì´ë“œ:"
        cat sglang_troubleshooting_guide.md
        ;;
    *)
        echo "âŒ ìž˜ëª»ëœ ì„ íƒ"
        exit 1
        ;;
esac
EOF

chmod +x run_sglang_ultimate.sh

echo -e "${GREEN}âœ… í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: run_sglang_ultimate.sh${NC}"

echo ""
echo -e "${GREEN}ðŸŽ‰ SGLang CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ê·¼ë³¸ì  í•´ê²° ì™„ë£Œ!${NC}"
echo "======================================================="

echo -e "${BLUE}ðŸŽ¯ í•´ê²° ë°©ë²•ë“¤:${NC}"
echo "âœ… SGLang ë‚´ë¶€ ì†ŒìŠ¤ ì½”ë“œ ìˆ˜ì •"
echo "âœ… CPU ëª¨ë“œ ê°•ì œ ì‹¤í–‰ (ê°€ìž¥ ì•ˆì •ì )"
echo "âœ… Docker ê¸°ë°˜ ì‹¤í–‰ (ê¶Œìž¥)"
echo "âœ… í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
echo "âœ… ì™„ì „í•œ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ"

echo ""
echo -e "${BLUE}ðŸš€ ê¶Œìž¥ ì‚¬ìš© ë°©ë²•:${NC}"
echo ""
echo "1. ê°€ìž¥ ì•ˆì •ì  (CPU ëª¨ë“œ):"
echo "   python start_sglang_cpu_mode.py"
echo ""
echo "2. ê¶Œìž¥ ë°©ë²• (Docker):"
echo "   bash start_sglang_docker.sh"
echo ""
echo "3. í†µí•© ì„ íƒ ë©”ë‰´:"
echo "   bash run_sglang_ultimate.sh"

echo ""
echo -e "${PURPLE}ðŸ’¡ RTX 4060ì—ì„œëŠ” CPU ëª¨ë“œê°€ ê°€ìž¥ ì•ˆì •ì ìž…ë‹ˆë‹¤!${NC}"
echo "ì†ë„ëŠ” ëŠë¦¬ì§€ë§Œ CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œë¥¼ ì™„ì „ížˆ íšŒí”¼í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤."

echo ""
echo "ê·¼ë³¸ì  í•´ê²° ì™„ë£Œ ì‹œê°„: $(date)"