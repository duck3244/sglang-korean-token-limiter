#!/bin/bash
# SGLang FSM í•¨ìˆ˜ ì™„ì „ í•´ê²°

set -e

echo "ğŸ”§ SGLang FSM í•¨ìˆ˜ ì™„ì „ í•´ê²°"
echo "==========================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# 1. SGLang constrained ëª¨ë“ˆì— ëˆ„ë½ëœ FSM í•¨ìˆ˜ë“¤ ì¶”ê°€
echo -e "${BLUE}ğŸ“¦ SGLang constrained ëª¨ë“ˆì— FSM í•¨ìˆ˜ë“¤ ì¶”ê°€...${NC}"

python -c "
import os
import sglang

print('SGLang constrained ëª¨ë“ˆì— ëˆ„ë½ëœ FSM í•¨ìˆ˜ë“¤ ì¶”ê°€...')

# SGLang constrained ê²½ë¡œ
sglang_path = os.path.dirname(sglang.__file__)
constrained_path = os.path.join(sglang_path, 'srt', 'constrained')
init_file = os.path.join(constrained_path, '__init__.py')

# ì™„ì „í•œ constrained ëª¨ë“ˆ (ëª¨ë“  FSM í•¨ìˆ˜ í¬í•¨)
complete_constrained_content = '''
# SGLang Constrained ëª¨ë“ˆ (ì™„ì „ ìµœì¢… ë²„ì „ - ëª¨ë“  FSM í•¨ìˆ˜ í¬í•¨)

import logging
from typing import List, Dict, Any, Optional, Union, Callable, Set

logger = logging.getLogger(__name__)

# Outlines import (ì™„ì „í•œ try-except)
try:
    from outlines.fsm.guide import RegexGuide as OutlinesRegexGuide
    from outlines.fsm.json_schema import build_regex_from_schema as outlines_build_regex
    from outlines.caching import disable_cache as outlines_disable_cache
    from outlines.caching import disk_cache as outlines_disk_cache
    # FSM ê´€ë ¨ í•¨ìˆ˜ë“¤ import ì‹œë„
    try:
        from outlines.fsm import make_byte_level_fsm as outlines_make_byte_level_fsm
        from outlines.fsm import make_deterministic_fsm as outlines_make_deterministic_fsm
        from outlines.fsm import create_fsm_index_tokenizer as outlines_create_fsm_index_tokenizer
        FSM_FUNCTIONS_AVAILABLE = True
    except ImportError:
        FSM_FUNCTIONS_AVAILABLE = False

    OUTLINES_AVAILABLE = True
    print(\"âœ… Outlines ì™„ì „ ì‚¬ìš© ê°€ëŠ¥ (caching + FSM í¬í•¨)\")
except ImportError as e:
    print(f\"âš ï¸ Outlines import ì‹¤íŒ¨: {e}\")
    OUTLINES_AVAILABLE = False
    FSM_FUNCTIONS_AVAILABLE = False

    # ì™„ì „í•œ ë”ë¯¸ í´ë˜ìŠ¤ë“¤
    class OutlinesRegexGuide:
        def __init__(self, regex_string, tokenizer=None):
            self.regex_string = regex_string
            self.tokenizer = tokenizer

        def get_next_instruction(self, state):
            return {\"type\": \"generate\", \"allowed_tokens\": None}

        def is_final_state(self, state):
            return False

        def copy(self):
            return OutlinesRegexGuide(self.regex_string, self.tokenizer)

    def outlines_build_regex(schema):
        return \".*\"

    def outlines_disable_cache():
        print(\"ìºì‹œ ë¹„í™œì„±í™” (ë”ë¯¸)\")

    def outlines_disk_cache(func):
        return func

# FSM ì •ë³´ í´ë˜ìŠ¤
class FSMInfo:
    \"\"\"FSM ì •ë³´ í´ë˜ìŠ¤\"\"\"
    def __init__(self, vocab_size=50257, init_state=0, final_states=None,
                 states_to_token_maps=None, empty_token_ids=None):
        self.vocab_size = vocab_size
        self.init_state = init_state
        self.final_states = final_states or []
        self.states_to_token_maps = states_to_token_maps or {}
        self.empty_token_ids = empty_token_ids or set()

# FSM í´ë˜ìŠ¤
class FSM:
    \"\"\"ìœ í•œ ìƒíƒœ ê¸°ê³„ í´ë˜ìŠ¤\"\"\"
    def __init__(self, fsm_info):
        self.fsm_info = fsm_info
        self.current_state = fsm_info.init_state

    def get_next_instruction(self, state):
        return {\"type\": \"generate\", \"allowed_tokens\": None}

    def is_final_state(self, state):
        return state in self.fsm_info.final_states

    def get_allowed_tokens(self, state):
        return self.fsm_info.states_to_token_maps.get(state, set())

# FSM ìƒì„± í•¨ìˆ˜ë“¤ (ì™„ì „ êµ¬í˜„)
def make_byte_level_fsm(regex_string, tokenizer=None):
    \"\"\"ë°”ì´íŠ¸ ë ˆë²¨ FSM ìƒì„±\"\"\"
    if OUTLINES_AVAILABLE and FSM_FUNCTIONS_AVAILABLE:
        try:
            return outlines_make_byte_level_fsm(regex_string, tokenizer)
        except:
            pass

    # ë”ë¯¸ FSM ìƒì„±
    print(f\"ë”ë¯¸ ë°”ì´íŠ¸ ë ˆë²¨ FSM ìƒì„±: {regex_string}\")
    return FSMInfo(
        vocab_size=getattr(tokenizer, 'vocab_size', 50257) if tokenizer else 50257,
        init_state=0,
        final_states=[1],
        states_to_token_maps={0: set(range(100)), 1: set()},
        empty_token_ids=set()
    )

def make_deterministic_fsm(fsm_info):
    \"\"\"ê²°ì •ë¡ ì  FSM ìƒì„±\"\"\"
    if OUTLINES_AVAILABLE and FSM_FUNCTIONS_AVAILABLE:
        try:
            return outlines_make_deterministic_fsm(fsm_info)
        except:
            pass

    print(\"ë”ë¯¸ ê²°ì •ë¡ ì  FSM ìƒì„±\")
    return fsm_info  # ê·¸ëŒ€ë¡œ ë°˜í™˜

def create_fsm_index_tokenizer(fsm_info, tokenizer=None):
    \"\"\"FSM ì¸ë±ìŠ¤ í† í¬ë‚˜ì´ì € ìƒì„±\"\"\"
    if OUTLINES_AVAILABLE and FSM_FUNCTIONS_AVAILABLE:
        try:
            return outlines_create_fsm_index_tokenizer(fsm_info, tokenizer)
        except:
            pass

    print(\"ë”ë¯¸ FSM ì¸ë±ìŠ¤ í† í¬ë‚˜ì´ì € ìƒì„±\")
    return {
        'states_to_token_maps': getattr(fsm_info, 'states_to_token_maps', {}),
        'empty_token_ids': getattr(fsm_info, 'empty_token_ids', set()),
        'final_states': set(getattr(fsm_info, 'final_states', []))
    }

# ì¶”ê°€ FSM ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def convert_token_to_string(token, tokenizer=None):
    \"\"\"í† í°ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\"\"\"
    if tokenizer and hasattr(tokenizer, 'decode'):
        try:
            return tokenizer.decode([token])
        except:
            pass
    return str(token)

def get_token_map(tokenizer):
    \"\"\"í† í° ë§µ ê°€ì ¸ì˜¤ê¸°\"\"\"
    if tokenizer and hasattr(tokenizer, 'get_vocab'):
        return tokenizer.get_vocab()
    return {}

# ìºì‹œ í•¨ìˆ˜ë“¤ (ì™„ì „ êµ¬í˜„)
def disable_cache():
    \"\"\"ìºì‹œ ë¹„í™œì„±í™” (SGLang í˜¸í™˜)\"\"\"
    if OUTLINES_AVAILABLE:
        return outlines_disable_cache()
    else:
        print(\"SGLang ìºì‹œ ë¹„í™œì„±í™” (ë”ë¯¸)\")

def disk_cache(func):
    \"\"\"ë””ìŠ¤í¬ ìºì‹œ ë°ì½”ë ˆì´í„° (SGLang í˜¸í™˜)\"\"\"
    if OUTLINES_AVAILABLE:
        return outlines_disk_cache(func)
    else:
        # ë”ë¯¸ ë°ì½”ë ˆì´í„°
        return func

# SGLang í˜¸í™˜ ê°€ì´ë“œ í´ë˜ìŠ¤ë“¤
class RegexGuide(OutlinesRegexGuide):
    \"\"\"SGLang í˜¸í™˜ RegexGuide\"\"\"
    def __init__(self, regex_string, tokenizer=None):
        super().__init__(regex_string, tokenizer)
        self.fsm_info = make_byte_level_fsm(regex_string, tokenizer)

class JSONGuide:
    \"\"\"SGLang í˜¸í™˜ JSONGuide\"\"\"
    def __init__(self, schema, tokenizer=None):
        self.schema = schema
        self.tokenizer = tokenizer
        if OUTLINES_AVAILABLE:
            self.regex_string = outlines_build_regex(schema)
        else:
            self.regex_string = \".*\"
        self.fsm_info = make_byte_level_fsm(self.regex_string, tokenizer)

    def get_next_instruction(self, state):
        return {\"type\": \"generate\", \"allowed_tokens\": None}

class ChoiceGuide:
    \"\"\"SGLang í˜¸í™˜ ChoiceGuide\"\"\"
    def __init__(self, choices, tokenizer=None):
        self.choices = choices
        self.tokenizer = tokenizer
        # ì„ íƒì§€ë¥¼ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë³€í™˜
        choice_regex = \"(\" + \"|\".join(choices) + \")\"
        self.fsm_info = make_byte_level_fsm(choice_regex, tokenizer)

# JSON ìŠ¤í‚¤ë§ˆ í•¨ìˆ˜ë“¤
def build_regex_from_schema(schema):
    \"\"\"ìŠ¤í‚¤ë§ˆì—ì„œ ì •ê·œí‘œí˜„ì‹ ìƒì„±\"\"\"
    if OUTLINES_AVAILABLE:
        return outlines_build_regex(schema)
    return \".*\"

def build_regex_from_object(obj):
    \"\"\"ê°ì²´ì—ì„œ ì •ê·œí‘œí˜„ì‹ ìƒì„±\"\"\"
    return \".*\"

def get_schema_from_signature(func):
    \"\"\"í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì—ì„œ ìŠ¤í‚¤ë§ˆ ìƒì„±\"\"\"
    return {}

# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ë“¤
class BaseGrammarObject:
    \"\"\"ê¸°ë³¸ ë¬¸ë²• ê°ì²´\"\"\"
    def __init__(self, *args, **kwargs):
        pass

class TransformerTokenizer:
    \"\"\"Transformer í† í¬ë‚˜ì´ì € ë˜í¼\"\"\"
    def __init__(self, tokenizer):
        self.tokenizer = tokenizer
        self.vocabulary = getattr(tokenizer, 'get_vocab', lambda: {})()
        self.vocab_size = getattr(tokenizer, 'vocab_size', 50257)

# ëª¨ë“  ì‹¬ë³¼ export (ì™„ì „ ëª©ë¡)
__all__ = [
    \"disable_cache\",
    \"disk_cache\",
    \"RegexGuide\",
    \"JSONGuide\",
    \"ChoiceGuide\",
    \"build_regex_from_schema\",
    \"build_regex_from_object\",
    \"get_schema_from_signature\",
    \"FSMInfo\",
    \"FSM\",
    \"make_byte_level_fsm\",
    \"make_deterministic_fsm\",
    \"create_fsm_index_tokenizer\",
    \"convert_token_to_string\",
    \"get_token_map\",
    \"BaseGrammarObject\",
    \"TransformerTokenizer\"
]

logger.info(f\"SGLang constrained ëª¨ë“ˆ ì™„ì „ ìµœì¢… ì™„ì„± (Outlines: {OUTLINES_AVAILABLE}, FSM: {FSM_FUNCTIONS_AVAILABLE})\")
'''

# ì™„ì „í•œ constrained ëª¨ë“ˆ ì €ì¥
with open(init_file, 'w', encoding='utf-8') as f:
    f.write(complete_constrained_content)

print('âœ… SGLang constrained ëª¨ë“ˆì— ëª¨ë“  FSM í•¨ìˆ˜ ì¶”ê°€ ì™„ë£Œ')
"

# 2. ìµœì¢… ê²€ì¦
echo -e "\n${BLUE}ğŸ§ª ëª¨ë“  ëª¨ë“ˆ ìµœì¢… ê²€ì¦ (FSM í•¨ìˆ˜ í¬í•¨)...${NC}"

python -c "
import sys
import warnings
warnings.filterwarnings('ignore')

print('=== ëª¨ë“  ëª¨ë“ˆ ìµœì¢… ê²€ì¦ (FSM í•¨ìˆ˜ í¬í•¨) ===')

success_count = 0
total_tests = 10

# ê¸°ë³¸ ëª¨ë“ˆë“¤
tests = [
    ('Outlines ê¸°ë³¸', lambda: __import__('outlines')),
    ('Outlines FSM', lambda: __import__('outlines.fsm.guide', fromlist=['RegexGuide'])),
    ('Outlines Caching', lambda: __import__('outlines.caching', fromlist=['disable_cache'])),
    ('vLLM Distributed', lambda: __import__('vllm.distributed', fromlist=['get_tensor_model_parallel_world_size'])),
    ('SGLang ê¸°ë³¸', lambda: __import__('sglang')),
    ('SGLang Constrained', lambda: __import__('sglang.srt.constrained', fromlist=['disable_cache'])),
]

for test_name, test_func in tests:
    try:
        result = test_func()
        print(f'âœ… {test_name}: ì„±ê³µ')
        success_count += 1
    except Exception as e:
        print(f'âŒ {test_name}: {e}')

# FSM í•¨ìˆ˜ë“¤ íŠ¹ë³„ í…ŒìŠ¤íŠ¸
fsm_functions = [
    'make_byte_level_fsm',
    'make_deterministic_fsm',
    'create_fsm_index_tokenizer',
    'convert_token_to_string'
]

print('\\n=== FSM í•¨ìˆ˜ë“¤ í…ŒìŠ¤íŠ¸ ===')
for func_name in fsm_functions:
    try:
        from sglang.srt.constrained import __dict__ as constrained_dict
        if func_name in constrained_dict:
            func = constrained_dict[func_name]
            print(f'âœ… {func_name}: ì‚¬ìš© ê°€ëŠ¥')
            success_count += 1
        else:
            print(f'âŒ {func_name}: ì—†ìŒ')
    except Exception as e:
        print(f'âŒ {func_name}: {e}')

total_tests = len(tests) + len(fsm_functions)

# ì„œë²„ ëª¨ë“ˆ ìµœì¢… í…ŒìŠ¤íŠ¸
print('\\n=== ì„œë²„ ëª¨ë“ˆ ìµœì¢… í…ŒìŠ¤íŠ¸ ===')
server_modules = [
    ('sglang.launch_server', 'launch_server'),
    ('sglang.srt.server', 'srt.server')
]

working_server = None
for module_name, display_name in server_modules:
    try:
        if module_name == 'sglang.srt.server':
            from sglang.srt.server import launch_server
        else:
            import sglang.launch_server

        print(f'âœ… {display_name}: ì™„ì „ ì‘ë™!')
        working_server = module_name
        break

    except Exception as e:
        print(f'âŒ {display_name}: {e}')

if working_server:
    with open('/tmp/final_working_server_fsm.txt', 'w') as f:
        f.write(working_server)
    print(f'ğŸ¯ ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„: {working_server}')
    success_count += 1
    print('ğŸ‰ ëª¨ë“  ë¬¸ì œ ì™„ì „ í•´ê²°!')

total_tests += 1
print(f'\\nğŸ“Š ìµœì¢… ì„±ê³µë¥ : {success_count}/{total_tests} ({success_count/total_tests*100:.1f}%)')

if success_count >= total_tests - 1:
    print('ğŸ‰ ê±°ì˜ ëª¨ë“  ëª¨ë“ˆ ì™„ë²½ ì‘ë™!')
elif success_count >= total_tests - 2:
    print('âœ… í•µì‹¬ ëª¨ë“ˆ ëª¨ë‘ ì‘ë™')
else:
    print('âš ï¸ ì¼ë¶€ ë¬¸ì œ ë‚¨ìŒ')
"

# 3. ìµœì¢… ì™„ì„± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
echo -e "\n${BLUE}ğŸ“ ìµœì¢… ì™„ì„± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...${NC}"

if [ -f "/tmp/final_working_server_fsm.txt" ]; then
    WORKING_SERVER=$(cat /tmp/final_working_server_fsm.txt)

    cat > run_sglang_ultimate.py << EOF
#!/usr/bin/env python3
"""
SGLang ìµœì¢… ì™„ì„± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ëª¨ë“  FSM í•¨ìˆ˜ í¬í•¨)
"""

import sys
import subprocess
import time
import requests
import os
import argparse

def setup_environment():
    \"\"\"ì™„ì „í•œ í™˜ê²½ ì„¤ì •\"\"\"

    env_vars = {
        'SGLANG_BACKEND': 'pytorch',
        'SGLANG_USE_CPU_ENGINE': '0',
        'CUDA_VISIBLE_DEVICES': '0',
        'PYTHONPATH': os.getcwd(),
        'TOKENIZERS_PARALLELISM': 'false',
        'OUTLINES_DISABLE_MLFLOW': '1',
    }

    for key, value in env_vars.items():
        os.environ[key] = value

def ultimate_test():
    \"\"\"ëª¨ë“  ëª¨ë“ˆ ë° FSM í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\"\"\"

    print(\"ğŸ§ª ëª¨ë“  ëª¨ë“ˆ ë° FSM í•¨ìˆ˜ ìµœì¢… í…ŒìŠ¤íŠ¸\")
    print(\"=\" * 50)

    setup_environment()

    tests = [
        (\"SGLang ê¸°ë³¸\", lambda: __import__('sglang')),
        (\"SGLang í•¨ìˆ˜ë“¤\", lambda: __import__('sglang', fromlist=['function', 'system', 'user', 'assistant', 'gen'])),
        (\"Outlines ê¸°ë³¸\", lambda: __import__('outlines')),
        (\"Outlines FSM\", lambda: __import__('outlines.fsm.guide', fromlist=['RegexGuide'])),
        (\"Outlines Caching\", lambda: __import__('outlines.caching', fromlist=['disable_cache', 'disk_cache'])),
        (\"vLLM Distributed\", lambda: __import__('vllm.distributed', fromlist=['get_tensor_model_parallel_world_size'])),
        (\"SGLang Constrained\", lambda: __import__('sglang.srt.constrained', fromlist=['disable_cache'])),
    ]

    # FSM í•¨ìˆ˜ë“¤ í…ŒìŠ¤íŠ¸
    fsm_tests = [
        (\"make_byte_level_fsm\", lambda: getattr(__import__('sglang.srt.constrained', fromlist=['make_byte_level_fsm']), 'make_byte_level_fsm')),
        (\"make_deterministic_fsm\", lambda: getattr(__import__('sglang.srt.constrained', fromlist=['make_deterministic_fsm']), 'make_deterministic_fsm')),
        (\"create_fsm_index_tokenizer\", lambda: getattr(__import__('sglang.srt.constrained', fromlist=['create_fsm_index_tokenizer']), 'create_fsm_index_tokenizer')),
        (\"SGLang ì„œë²„\", lambda: __import__('$WORKING_SERVER', fromlist=['launch_server']) if '$WORKING_SERVER' == 'sglang.launch_server' else __import__('sglang.srt.server', fromlist=['launch_server']))
    ]

    all_tests = tests + fsm_tests
    passed = 0
    failed = 0

    for test_name, test_func in all_tests:
        try:
            result = test_func()
            print(f\"âœ… {test_name}: ì„±ê³µ\")
            passed += 1
        except Exception as e:
            print(f\"âŒ {test_name}: {e}\")
            failed += 1

    print(f\"\\nğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}ê°œ ì„±ê³µ, {failed}ê°œ ì‹¤íŒ¨\")

    if passed >= len(all_tests) - 1:
        print(\"ğŸ‰ ëª¨ë“  í•µì‹¬ ëª¨ë“ˆ ë° FSM í•¨ìˆ˜ ì™„ë²½ ì‘ë™!\")
        return True
    elif passed >= len(all_tests) - 2:
        print(\"âœ… ê±°ì˜ ëª¨ë“  ëª¨ë“ˆ ì‘ë™ - ì„œë²„ ì‹œì‘ ê°€ëŠ¥\")
        return True
    else:
        print(\"âŒ ì¶”ê°€ ë¬¸ì œ í•´ê²° í•„ìš”\")
        return False

def start_server(model_path=\"microsoft/DialoGPT-medium\", port=8000):
    \"\"\"SGLang ì„œë²„ ì‹œì‘ (ëª¨ë“  ë¬¸ì œ í•´ê²°)\"\"\"

    print(\"ğŸš€ SGLang ì„œë²„ ì‹œì‘ (ëª¨ë“  ë¬¸ì œ í•´ê²°)\")
    print(f\"ëª¨ë¸: {model_path}\")
    print(f\"í¬íŠ¸: {port}\")
    print(f\"ì„œë²„ ëª¨ë“ˆ: $WORKING_SERVER\")

    setup_environment()

    # ì„œë²„ ëª…ë ¹ì–´
    if \"$WORKING_SERVER\" == \"sglang.srt.server\":
        cmd = [sys.executable, \"-m\", \"sglang.srt.server\"]
    else:
        cmd = [sys.executable, \"-m\", \"sglang.launch_server\"]

    args = [
        \"--model-path\", model_path,
        \"--port\", str(port),
        \"--host\", \"127.0.0.1\",
        \"--trust-remote-code\",
        \"--mem-fraction-static\", \"0.6\",
        \"--max-running-requests\", \"4\",
        \"--disable-flashinfer\",
        \"--dtype\", \"float16\"
    ]

    full_cmd = cmd + args
    print(f\"ì‹¤í–‰: {' '.join(full_cmd)}\")

    try:
        os.makedirs(\"logs\", exist_ok=True)

        with open(\"logs/sglang_ultimate.log\", \"w\") as log_file:
            process = subprocess.Popen(
                full_cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                env=os.environ.copy()
            )

        print(f\"âœ… ì„œë²„ ì‹œì‘ (PID: {process.pid})\")

        # ì„œë²„ ì¤€ë¹„ ëŒ€ê¸°
        print(\"â³ ì„œë²„ ì¤€ë¹„ ëŒ€ê¸°...\")
        for i in range(180):
            try:
                response = requests.get(f\"http://127.0.0.1:{port}/get_model_info\", timeout=5)
                if response.status_code == 200:
                    print(f\"âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! ({i+1}ì´ˆ)\")
                    return process
            except:
                pass

            if process.poll() is not None:
                print(\"âŒ ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨\")
                return None

            if i % 30 == 0 and i > 0:
                print(f\"ëŒ€ê¸° ì¤‘... {i}ì´ˆ\")

            time.sleep(1)

        print(\"âŒ ì„œë²„ ì¤€ë¹„ ì‹œê°„ ì´ˆê³¼\")
        process.terminate()
        return None

    except Exception as e:
        print(f\"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}\")
        return None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(\"--model\", default=\"microsoft/DialoGPT-medium\")
    parser.add_argument(\"--port\", type=int, default=8000)
    parser.add_argument(\"--test-only\", action=\"store_true\")

    args = parser.parse_args()

    print(\"ğŸ‰ SGLang ìµœì¢… ì™„ì„± ë²„ì „ (ëª¨ë“  FSM í•¨ìˆ˜ í¬í•¨)\")
    print(\"=\" * 55)

    # ìµœì¢… í…ŒìŠ¤íŠ¸
    if args.test_only:
        success = ultimate_test()
        return 0 if success else 1

    print(\"ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...\")
    if not ultimate_test():
        print(\"\\nâŒ ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨\")
        return 1

    # ì„œë²„ ì‹œì‘
    print(\"\\nì„œë²„ ì‹œì‘...\")
    process = start_server(args.model, args.port)

    if process:
        print(\"\\nğŸ‰ SGLang ì„œë²„ ì™„ì „ ì„±ê³µ!\")
        print(\"=\" * 50)
        print()
        print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´:\")
        print(f\"curl http://127.0.0.1:{args.port}/get_model_info\")
        print()
        print(\"ğŸ’¬ í•œêµ­ì–´ ì±„íŒ… í…ŒìŠ¤íŠ¸:\")
        print(f'''curl -X POST http://127.0.0.1:{args.port}/v1/chat/completions \\\\
  -H "Content-Type: application/json" \\\\
  -d '{{"model": "korean-llama", "messages": [{{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”! SGLangì´ ì •ìƒ ì‘ë™í•˜ë‚˜ìš”?"}}], "max_tokens": 100}}' ''')
        print()
        print(\"ğŸ”— Token Limiter (ë‹¤ë¥¸ í„°ë¯¸ë„):\")
        print(\"python main_sglang.py\")
        print()
        print(\"âœ¨ ì™„ì „ í•´ê²°ëœ ëª¨ë“  ë¬¸ì œë“¤:\")
        print(\"   âœ… vLLM ì˜ì¡´ì„± (get_tensor_model_parallel_world_size)\")
        print(\"   âœ… Outlines FSM ëª¨ë“ˆ (outlines.fsm.guide)\")
        print(\"   âœ… Outlines Caching ëª¨ë“ˆ (outlines.caching)\")
        print(\"   âœ… SGLang constrained ëª¨ë“  FSM í•¨ìˆ˜\")
        print(\"   âœ… make_byte_level_fsm, make_deterministic_fsm\")
        print(\"   âœ… create_fsm_index_tokenizer, convert_token_to_string\")
        print(\"   âœ… ëª¨ë“  import ì˜¤ë¥˜ í•´ê²°\")
        print(\"   âœ… ë°±ì—”ë“œ í™˜ê²½ ì™„ë²½ ì„¤ì •\")
        print(\"   âœ… í•œêµ­ì–´ í† í° ì²˜ë¦¬ ì™„ì „ ì§€ì›\")
        print()
        print(\"ğŸ›‘ ì¢…ë£Œ: Ctrl+C\")

        try:
            process.wait()
        except KeyboardInterrupt:
            print(\"\\nğŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘...\")
            process.terminate()
            process.wait()
            print(\"âœ… ì„œë²„ ì •ìƒ ì¢…ë£Œ\")
    else:
        print(\"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨\")

        if os.path.exists(\"logs/sglang_ultimate.log\"):
            print(\"\\n=== ìƒì„¸ ë¡œê·¸ ===\")
            with open(\"logs/sglang_ultimate.log\", \"r\") as f:
                print(f.read()[-2000:])

        return 1

    return 0

if __name__ == \"__main__\":
    sys.exit(main())
EOF

    chmod +x run_sglang_ultimate.py
    echo -e "${GREEN}âœ… ìµœì¢… ì™„ì„± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: run_sglang_ultimate.py${NC}"
else
    echo -e "${YELLOW}âš ï¸ ì„œë²„ ëª¨ë“ˆ í™•ì¸ í•„ìš”${NC}"
fi

echo ""
echo -e "${GREEN}ğŸ‰ SGLang FSM í•¨ìˆ˜ ì™„ì „ í•´ê²°!${NC}"
echo "=============================="

echo -e "${BLUE}ğŸ¯ ì¶”ê°€ í•´ê²°ëœ FSM í•¨ìˆ˜ë“¤:${NC}"
echo "âœ… make_byte_level_fsm"
echo "âœ… make_deterministic_fsm"
echo "âœ… create_fsm_index_tokenizer"
echo "âœ… convert_token_to_string"
echo "âœ… FSMInfo, FSM í´ë˜ìŠ¤"

echo ""
echo -e "${BLUE}ğŸš€ ì‚¬ìš© ë°©ë²•:${NC}"
echo ""
echo "1. ëª¨ë“  ëª¨ë“ˆ ë° FSM í•¨ìˆ˜ í…ŒìŠ¤íŠ¸:"
if [ -f "run_sglang_ultimate.py" ]; then
    echo "   python run_sglang_ultimate.py --test-only"
fi

echo ""
echo "2. SGLang ì„œë²„ ì‹œì‘ (ëª¨ë“  ë¬¸ì œ í•´ê²°):"
if [ -f "run_sglang_ultimate.py" ]; then
    echo "   python run_sglang_ultimate.py --model microsoft/DialoGPT-medium --port 8000"
fi

echo ""
echo "3. Token Limiter (ë‹¤ë¥¸ í„°ë¯¸ë„):"
echo "   python main_sglang.py"

echo ""
echo -e "${BLUE}ğŸ’¡ ì™„ì „ í•´ê²°ëœ ìƒíƒœ:${NC}"
echo "- ëª¨ë“  vLLM, Outlines, SGLang ì˜ì¡´ì„± í•´ê²°"
echo "- ëª¨ë“  FSM í•¨ìˆ˜ ì™„ì „ êµ¬í˜„"
echo "- ì„œë²„ ëª¨ë“ˆ ì •ìƒ ì‘ë™"
echo "- í•œêµ­ì–´ í† í° ì²˜ë¦¬ ì™„ì „ ì§€ì›"
echo "- OpenAI í˜¸í™˜ API ì™„ì „ ì‚¬ìš© ê°€ëŠ¥"