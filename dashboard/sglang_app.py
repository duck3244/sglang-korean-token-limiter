"""
SGLang ê¸°ë°˜ í•œêµ­ì–´ Token Limiter ëŒ€ì‹œë³´ë“œ (ì™„ì „íŒ)
"""

import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from datetime import datetime, timedelta
import json
import psutil
import asyncio
import numpy as np

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ‡°ğŸ‡· SGLang Korean Token Limiter Dashboard",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .sglang-metric {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        text-align: center;
    }
    
    .performance-card {
        background-color: #f8f9fa;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    
    .status-excellent {
        color: #28a745;
        font-weight: bold;
    }
    
    .status-good {
        color: #17a2b8;
        font-weight: bold;
    }
    
    .status-warning {
        color: #ffc107;
        font-weight: bold;
    }
    
    .status-error {
        color: #dc3545;
        font-weight: bold;
    }
    
    .sglang-info {
        background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        display: inline-block;
        margin: 0.2rem;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        padding: 0px 24px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 8px 8px 0px 0px;
        color: white;
        font-weight: bold;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    
    .korean-text {
        font-family: 'Noto Sans KR', sans-serif;
        color: #2c3e50;
    }
</style>
""", unsafe_allow_html=True)

# ì„¤ì •
TOKEN_LIMITER_URL = "http://localhost:8080"
SGLANG_URL = "http://127.0.0.1:8000"
REFRESH_INTERVAL = 3  # SGLang ë¹ ë¥¸ ì‘ë‹µìœ¼ë¡œ ë‹¨ì¶•

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
@st.cache_data(ttl=3)
def get_system_health():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/health", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"status": "error", "error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException as e:
        return {"status": "error", "error": str(e)}

@st.cache_data(ttl=5)
def get_sglang_runtime_info():
    """SGLang ëŸ°íƒ€ì„ ì •ë³´ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/sglang/runtime-info", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException:
        return {"error": "Connection failed"}

@st.cache_data(ttl=3)
def get_sglang_performance():
    """SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/admin/sglang/performance", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException:
        return {"error": "Connection failed"}

@st.cache_data(ttl=10)
def get_user_list():
    """ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/admin/users", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"users": [], "total_count": 0}
    except requests.exceptions.RequestException:
        return {"users": [], "total_count": 0}

def get_user_stats(user_id):
    """ì‚¬ìš©ì í†µê³„ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/stats/{user_id}", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except requests.exceptions.RequestException:
        return None

def test_sglang_chat(user_key="sk-user1-korean-key-def", message="ì•ˆë…•í•˜ì„¸ìš”!", stream=False):
    """SGLang ì±„íŒ… í…ŒìŠ¤íŠ¸"""
    try:
        response = requests.post(
            f"{TOKEN_LIMITER_URL}/v1/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {user_key}"
            },
            json={
                "model": "korean-llama",
                "messages": [{"role": "user", "content": message}],
                "max_tokens": 50,
                "stream": stream,
                "korean_optimized": True
            },
            timeout=30
        )
        return {
            "status_code": response.status_code,
            "response": response.json() if response.headers.get("content-type", "").startswith("application/json") else response.text
        }
    except requests.exceptions.RequestException as e:
        return {"status_code": 0, "error": str(e)}

def get_system_resources():
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()

        # GPU ì •ë³´ (nvidia-ml-py3ê°€ ìˆëŠ” ê²½ìš°)
        gpu_info = {}
        try:
            import pynvml
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)

            gpu_info = {
                "name": pynvml.nvmlDeviceGetName(handle).decode(),
                "memory_total": pynvml.nvmlDeviceGetMemoryInfo(handle).total / 1024**3,
                "memory_used": pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**3,
                "temperature": pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU),
                "utilization": pynvml.nvmlDeviceGetUtilizationRates(handle).gpu
            }
        except:
            gpu_info = {"error": "GPU ì •ë³´ ì¡°íšŒ ë¶ˆê°€"}

        return {
            "cpu_percent": cpu_percent,
            "memory_percent": memory.percent,
            "memory_used_gb": memory.used / 1024**3,
            "memory_total_gb": memory.total / 1024**3,
            "gpu_info": gpu_info
        }
    except Exception as e:
        return {"error": str(e)}

def optimize_sglang_performance():
    """SGLang ì„±ëŠ¥ ìµœì í™” ì‹¤í–‰"""
    try:
        response = requests.post(f"{TOKEN_LIMITER_URL}/admin/sglang/optimize", timeout=10)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException as e:
        return {"error": str(e)}

def warmup_sglang():
    """SGLang ì›Œë°ì—… ì‹¤í–‰"""
    try:
        response = requests.post(f"{TOKEN_LIMITER_URL}/admin/sglang/warmup", timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException as e:
        return {"error": str(e)}

# ë©”ì¸ í—¤ë”
st.markdown('<h1 class="main-header">ğŸš€ SGLang Korean Token Limiter Dashboard</h1>',
            unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” - ì‹¤ì‹œê°„ ìƒíƒœ
with st.sidebar:
    st.header("ğŸš€ SGLang ì‹¤ì‹œê°„ ìƒíƒœ")

    # ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì •
    auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (3ì´ˆ)", value=True)
    if auto_refresh:
        time.sleep(0.1)
        st.rerun()

    # ì‹œìŠ¤í…œ ìƒíƒœ
    health = get_system_health()

    if health.get("status") == "healthy":
        st.success("âœ… ì‹œìŠ¤í…œ ì •ìƒ")

        sglang_status = health.get("sglang_server", "unknown")
        if sglang_status == "connected":
            st.success("ğŸš€ SGLang ì—°ê²°ë¨")

            # SGLang ëª¨ë¸ ì •ë³´
            actual_model = health.get("actual_sglang_model", "Unknown")
            st.markdown(f'<span class="sglang-info">{actual_model}</span>', unsafe_allow_html=True)

            # ìŠ¤íŠ¸ë¦¬ë° ì§€ì› í‘œì‹œ
            if health.get("supports_streaming"):
                st.info("ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›")
        else:
            st.error("âŒ SGLang ì—°ê²° ì‹¤íŒ¨")

        st.info(f"ğŸ• ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
    else:
        st.error("âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜")
        st.error(f"ì˜¤ë¥˜: {health.get('error', 'Unknown error')}")

    # SGLang ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    st.subheader("âš¡ SGLang ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")

    if st.button("ì±„íŒ… í…ŒìŠ¤íŠ¸"):
        with st.spinner("SGLang ì‘ë‹µ ìƒì„± ì¤‘..."):
            result = test_sglang_chat(message="ì•ˆë…•í•˜ì„¸ìš”!")
            if result["status_code"] == 200:
                response_data = result["response"]
                if "choices" in response_data:
                    ai_response = response_data["choices"][0]["message"]["content"]
                    st.success("âœ… SGLang ì‘ë‹µ ì„±ê³µ")
                    st.text_area("AI ì‘ë‹µ:", ai_response, height=100)
                else:
                    st.error("âŒ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
            else:
                st.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (HTTP {result['status_code']})")

    # ê´€ë¦¬ ê¸°ëŠ¥
    st.subheader("ğŸ”§ SGLang ê´€ë¦¬")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ”¥ ì›Œë°ì—…"):
            with st.spinner("SGLang ì›Œë°ì—… ì¤‘..."):
                result = warmup_sglang()
                if result.get("success"):
                    st.success("âœ… ì›Œë°ì—… ì™„ë£Œ")
                else:
                    st.error("âŒ ì›Œë°ì—… ì‹¤íŒ¨")

    with col2:
        if st.button("âš¡ ìµœì í™”"):
            with st.spinner("SGLang ìµœì í™” ì¤‘..."):
                result = optimize_sglang_performance()
                if "error" not in result:
                    st.success("âœ… ìµœì í™” ì™„ë£Œ")
                else:
                    st.error("âŒ ìµœì í™” ì‹¤íŒ¨")

# ë©”ì¸ íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸš€ SGLang ì„±ëŠ¥",
    "ğŸ‘¥ ì‚¬ìš©ì ê´€ë¦¬",
    "ğŸ§ª API í…ŒìŠ¤íŠ¸",
    "ğŸ“ˆ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§",
    "ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤",
    "âš™ï¸ ì„¤ì • ë° ê´€ë¦¬"
])

# íƒ­ 1: SGLang ì„±ëŠ¥
with tab1:
    st.header("ğŸš€ SGLang ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ")

    # SGLang ëŸ°íƒ€ì„ ì •ë³´
    runtime_info = get_sglang_runtime_info()

    if "error" not in runtime_info:
        # ìƒë‹¨ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)

        model_info = runtime_info.get("model_info", {})
        server_info = runtime_info.get("server_info", {})

        with col1:
            max_tokens = model_info.get("max_total_tokens", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ìµœëŒ€ í† í°</h3>
                <h2>{max_tokens:,}</h2>
            </div>
            ''', unsafe_allow_html=True)

        with col2:
            running_requests = server_info.get("running_requests", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ì²˜ë¦¬ ì¤‘ ìš”ì²­</h3>
                <h2>{running_requests}</h2>
            </div>
            ''', unsafe_allow_html=True)

        with col3:
            queue_length = server_info.get("queue_length", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ëŒ€ê¸°ì—´ ê¸¸ì´</h3>
                <h2>{queue_length}</h2>
            </div>
            ''', unsafe_allow_html=True)

        with col4:
            memory_usage = server_info.get("memory_usage_gb", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰</h3>
                <h2>{memory_usage:.1f}GB</h2>
            </div>
            ''', unsafe_allow_html=True)

        st.divider()

        # SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­
        performance = get_sglang_performance()

        if "error" not in performance:
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("ğŸ“Š ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­")

                # ì²˜ë¦¬ëŸ‰ ì°¨íŠ¸
                current_metrics = performance.get("current_metrics", {})
                metrics_data = {
                    "ë©”íŠ¸ë¦­": ["ìš”ì²­/ì´ˆ", "í† í°/ì´ˆ", "ìºì‹œ íˆíŠ¸ìœ¨"],
                    "ê°’": [
                        current_metrics.get("requests_per_second", 0),
                        current_metrics.get("tokens_per_second", 0),
                        current_metrics.get("cache_hit_rate", 0) * 100
                    ],
                    "ë‹¨ìœ„": ["req/s", "tok/s", "%"]
                }

                fig = go.Figure(data=[
                    go.Bar(
                        x=metrics_data["ë©”íŠ¸ë¦­"],
                        y=metrics_data["ê°’"],
                        text=[f"{v:.1f}{u}" for v, u in zip(metrics_data["ê°’"], metrics_data["ë‹¨ìœ„"])],
                        textposition='auto',
                        marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1']
                    )
                ])
                fig.update_layout(title="SGLang ì‹¤ì‹œê°„ ì„±ëŠ¥", height=300)
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.subheader("ğŸ”§ SGLang ìµœì í™” ìƒíƒœ")

                optimizations = runtime_info.get("performance", {})

                opt_status = [
                    ("ë™ì  ë°°ì¹˜", optimizations.get("supports_dynamic_batching", False)),
                    ("í”„ë¦¬í”½ìŠ¤ ìºì‹œ", optimizations.get("supports_prefix_caching", False)),
                    ("ì²­í¬ í”„ë¦¬í•„", optimizations.get("supports_chunked_prefill", False)),
                    ("KV ìºì‹œ ìµœì í™”", optimizations.get("kv_cache_optimized", False))
                ]

                for opt_name, is_enabled in opt_status:
                    status_class = "status-excellent" if is_enabled else "status-warning"
                    status_icon = "âœ…" if is_enabled else "âš ï¸"
                    st.markdown(f'{status_icon} <span class="{status_class}">{opt_name}</span>',
                               unsafe_allow_html=True)

                # ìµœì í™” ê¶Œì¥ì‚¬í•­
                recommendations = performance.get("optimization_recommendations", [])
                if recommendations:
                    st.subheader("ğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­")
                    for rec in recommendations[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                        st.info(f"**{rec.get('category', 'General')}**: {rec.get('title', 'Optimization needed')}")

        # ëª¨ë¸ ì •ë³´ ìƒì„¸
        st.subheader("ğŸ¤– ëª¨ë¸ ìƒì„¸ ì •ë³´")

        model_details = {
            "ëª¨ë¸ ê²½ë¡œ": model_info.get("model_path", "Unknown"),
            "ì„œë¹™ ëª¨ë¸ëª…": ", ".join(model_info.get("served_model_names", [])),
            "ìµœëŒ€ í† í° ê¸¸ì´": f"{model_info.get('max_total_tokens', 0):,}",
            "ìƒì„± ëª¨ë“œ": "í™œì„±í™”" if model_info.get("is_generation", False) else "ë¹„í™œì„±í™”"
        }

        for key, value in model_details.items():
            st.write(f"**{key}**: {value}")

        # ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ (SGLang vs ê¸°ì¤€ì„ )
        st.subheader("âš¡ SGLang vs vLLM ì„±ëŠ¥ ë¹„êµ")

        # ê°€ìƒ ë¹„êµ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‚¬ìš©)
        comparison_data = {
            "ë©”íŠ¸ë¦­": ["ì²˜ë¦¬ëŸ‰ (RPS)", "ì§€ì—°ì‹œê°„ (ms)", "ë©”ëª¨ë¦¬ íš¨ìœ¨", "ë™ì‹œ ì‚¬ìš©ì"],
            "SGLang": [40, 850, 85, 16],
            "vLLM": [30, 1200, 70, 8]
        }

        fig_comparison = go.Figure()
        fig_comparison.add_trace(go.Bar(
            name='SGLang',
            x=comparison_data["ë©”íŠ¸ë¦­"],
            y=comparison_data["SGLang"],
            marker_color='#667eea'
        ))
        fig_comparison.add_trace(go.Bar(
            name='vLLM',
            x=comparison_data["ë©”íŠ¸ë¦­"],
            y=comparison_data["vLLM"],
            marker_color='#f093fb'
        ))
        fig_comparison.update_layout(
            title="í”„ë ˆì„ì›Œí¬ ì„±ëŠ¥ ë¹„êµ",
            barmode='group',
            height=400
        )
        st.plotly_chart(fig_comparison, use_container_width=True)

    else:
        st.error(f"âŒ SGLang ëŸ°íƒ€ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {runtime_info.get('error')}")

# íƒ­ 2: ì‚¬ìš©ì ê´€ë¦¬
with tab2:
    st.header("ğŸ‘¥ ì‚¬ìš©ì ê´€ë¦¬")

    user_list = get_user_list()

    if user_list.get("total_count", 0) > 0:
        st.subheader(f"ì´ {user_list['total_count']}ëª…ì˜ ì‚¬ìš©ì")

        # ì‚¬ìš©ìë³„ í†µê³„ ìˆ˜ì§‘
        user_stats_list = []

        for user_info in user_list.get("users", []):
            if isinstance(user_info, dict):
                user_id = user_info.get("user_id")
                display_name = user_info.get("display_name", user_id)
            else:
                user_id = user_info
                display_name = user_id

            stats = get_user_stats(user_id)
            if stats:
                user_stats_list.append({
                    "ì‚¬ìš©ì ID": user_id,
                    "í‘œì‹œëª…": display_name,
                    "ë¶„ë‹¹ ìš”ì²­": f"{stats.get('requests_this_minute', 0)}/{stats.get('limits', {}).get('rpm', 0)}",
                    "ë¶„ë‹¹ í† í°": f"{stats.get('tokens_this_minute', 0):,}/{stats.get('limits', {}).get('tpm', 0):,}",
                    "ì˜¤ëŠ˜ í† í°": f"{stats.get('tokens_today', 0):,}",
                    "ì´ ìš”ì²­": f"{stats.get('total_requests', 0):,}",
                    "ì´ í† í°": f"{stats.get('total_tokens', 0):,}",
                    "ìƒíƒœ": stats.get('status_summary', 'ì •ìƒ')
                })

        if user_stats_list:
            df = pd.DataFrame(user_stats_list)
            st.dataframe(df, hide_index=True, use_container_width=True)

            # ì‚¬ìš©ìë³„ ì‚¬ìš©ëŸ‰ ì°¨íŠ¸ (SGLang ì„±ëŠ¥ ë°˜ì˜)
            st.subheader("ğŸ“Š ì‚¬ìš©ìë³„ í† í° ì‚¬ìš©ëŸ‰ (SGLang ìµœì í™”)")

            # ì˜¤ëŠ˜ í† í° ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
            fig = px.bar(
                df,
                x="í‘œì‹œëª…",
                y=[int(x.replace(",", "")) for x in df["ì˜¤ëŠ˜ í† í°"]],
                title="ì‚¬ìš©ìë³„ ì˜¤ëŠ˜ í† í° ì‚¬ìš©ëŸ‰ (SGLang ì²˜ë¦¬)",
                labels={"y": "í† í° ìˆ˜", "x": "ì‚¬ìš©ì"},
                color=[int(x.replace(",", "")) for x in df["ì˜¤ëŠ˜ í† í°"]],
                color_continuous_scale="Viridis"
            )
            fig.update_layout(showlegend=False, height=400)
            st.plotly_chart(fig, use_container_width=True)

            # ì‚¬ìš©ì ìƒíƒœ ë¶„í¬
            st.subheader("ğŸ“‹ ì‚¬ìš©ì ìƒíƒœ ë¶„í¬")

            status_counts = df["ìƒíƒœ"].value_counts()
            fig_status = px.pie(
                values=status_counts.values,
                names=status_counts.index,
                title="ì‚¬ìš©ì ìƒíƒœ ë¶„í¬"
            )
            st.plotly_chart(fig_status, use_container_width=True)

        else:
            st.info("ğŸ“ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ìˆëŠ” ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ‘¤ ë“±ë¡ëœ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")

# íƒ­ 3: API í…ŒìŠ¤íŠ¸
with tab3:
    st.header("ğŸ§ª SGLang API í…ŒìŠ¤íŠ¸")

    # SGLang ì±„íŒ… ì™„ì„± í…ŒìŠ¤íŠ¸
    st.subheader("ğŸ’¬ SGLang ì±„íŒ… ì™„ì„± í…ŒìŠ¤íŠ¸")

    col1, col2 = st.columns(2)

    with col1:
        test_api_key = st.selectbox(
            "API í‚¤ ì„ íƒ:",
            [
                "sk-user1-korean-key-def",
                "sk-user2-korean-key-ghi",
                "sk-dev1-korean-key-789",
                "sk-test-korean-key-stu",
                "sk-guest-korean-key-vwx"
            ]
        )

    with col2:
        max_tokens = st.slider("ìµœëŒ€ í† í° ìˆ˜", 10, 500, 100)

    test_message = st.text_area(
        "í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€:",
        value="SGLangì˜ ì„±ëŠ¥ ìµœì í™” ê¸°ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        height=100
    )

    # í•œêµ­ì–´ ìµœì í™” ì˜µì…˜
    korean_optimized = st.checkbox("í•œêµ­ì–´ ìµœì í™” í™œì„±í™”", value=True)

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ì¼ë°˜ ì‘ë‹µ í…ŒìŠ¤íŠ¸"):
            with st.spinner("SGLang AI ì‘ë‹µ ìƒì„± ì¤‘..."):
                start_time = time.time()
                result = test_sglang_chat(test_api_key, test_message, stream=False)
                response_time = time.time() - start_time

                if result["status_code"] == 200:
                    response_data = result["response"]
                    if "choices" in response_data:
                        ai_response = response_data["choices"][0]["message"]["content"]

                        st.success(f"âœ… SGLang ì±„íŒ… ì™„ì„± ì„±ê³µ ({response_time:.2f}ì´ˆ)")
                        st.text_area("AI ì‘ë‹µ:", ai_response, height=200)

                        # ì‚¬ìš©ëŸ‰ ì •ë³´ í‘œì‹œ
                        usage = response_data.get("usage", {})
                        if usage:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ì…ë ¥ í† í°", usage.get("prompt_tokens", 0))
                            with col2:
                                st.metric("ì¶œë ¥ í† í°", usage.get("completion_tokens", 0))
                            with col3:
                                st.metric("ì´ í† í°", usage.get("total_tokens", 0))
                    else:
                        st.error("âŒ SGLang ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                        st.json(response_data)

                elif result["status_code"] == 429:
                    st.warning("âš ï¸ ì†ë„ ì œí•œ ì´ˆê³¼")
                    error_data = result.get("response", {})
                    if isinstance(error_data, dict) and "error" in error_data:
                        st.error(f"ì œí•œ ì‚¬ìœ : {error_data['error'].get('message', 'ì•Œ ìˆ˜ ì—†ìŒ')}")

                else:
                    st.error(f"âŒ SGLang API ì˜¤ë¥˜ (HTTP {result['status_code']})")
                    if "error" in result:
                        st.error(f"ì˜¤ë¥˜: {result['error']}")

    with col2:
        if st.button("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸"):
            st.info("ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ëŠ” ë³„ë„ í´ë¼ì´ì–¸íŠ¸ë¡œ í™•ì¸í•˜ì„¸ìš”")
            st.code(f"""
curl -X POST http://localhost:8080/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer {test_api_key}" \\
  -d '{{
    "model": "korean-llama",
    "messages": [{{"role": "user", "content": "{test_message}"}}],
    "max_tokens": {max_tokens},
    "stream": true,
    "korean_optimized": {str(korean_optimized).lower()}
  }}'
            """)

    with col3:
        if st.button("í† í° ê³„ì‚° í…ŒìŠ¤íŠ¸"):
            try:
                response = requests.get(
                    f"{TOKEN_LIMITER_URL}/token-info",
                    params={"text": test_message},
                    timeout=5
                )
                if response.status_code == 200:
                    token_info = response.json()
                    st.success("âœ… í† í° ê³„ì‚° ì„±ê³µ")
                    st.json(token_info)
                else:
                    st.error("âŒ í† í° ê³„ì‚° ì‹¤íŒ¨")
            except Exception as e:
                st.error(f"âŒ í† í° ê³„ì‚° ì˜¤ë¥˜: {e}")

    st.divider()

    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
    st.subheader("âš¡ SGLang ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")

    if st.button("ë™ì‹œ ìš”ì²­ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"):
        st.info("ğŸ”„ 5ê°œì˜ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ SGLang ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")

        progress_bar = st.progress(0)
        status_text = st.empty()

        start_time = time.time()
        results = []

        # ê°„ë‹¨í•œ ë™ì‹œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        for i in range(5):
            progress_bar.progress((i + 1) / 5)
            status_text.text(f"ìš”ì²­ {i+1}/5 ì²˜ë¦¬ ì¤‘...")

            result = test_sglang_chat(test_api_key, f"í…ŒìŠ¤íŠ¸ ìš”ì²­ {i+1}: ì§§ì€ ì‘ë‹µì„ í•´ì£¼ì„¸ìš”.", stream=False)
            results.append(result)
            time.sleep(0.1)  # SGLang ë¹ ë¥¸ ì²˜ë¦¬ ë°˜ì˜

        end_time = time.time()
        duration = end_time - start_time

        success_count = sum(1 for r in results if r["status_code"] == 200)

        status_text.empty()
        progress_bar.empty()

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ì†Œìš” ì‹œê°„", f"{duration:.2f}ì´ˆ")
        with col2:
            st.metric("ì„±ê³µí•œ ìš”ì²­", f"{success_count}/5")
        with col3:
            st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{duration/5:.2f}ì´ˆ")

        if success_count == 5:
            st.success("âœ… SGLang ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

            # ì„±ëŠ¥ ê²°ê³¼ ì°¨íŠ¸
            response_times = []
            for i, result in enumerate(results):
                if result["status_code"] == 200:
                    response_times.append(duration/5)  # ê·¼ì‚¬ì¹˜
                else:
                    response_times.append(0)

            fig = go.Figure(data=go.Bar(
                x=[f"ìš”ì²­ {i+1}" for i in range(5)],
                y=response_times,
                marker_color=['#28a745' if rt > 0 else '#dc3545' for rt in response_times]
            ))
            fig.update_layout(title="ìš”ì²­ë³„ ì‘ë‹µ ì‹œê°„", yaxis_title="ì‘ë‹µ ì‹œê°„ (ì´ˆ)")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning(f"âš ï¸ {5-success_count}ê°œ ìš”ì²­ ì‹¤íŒ¨")

# íƒ­ 4: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
with tab4:
    st.header("ğŸ“ˆ SGLang ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    # ìë™ ìƒˆë¡œê³ ì¹¨
    if st.checkbox("ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (3ì´ˆ ê°„ê²©)", value=False, key="monitoring_refresh"):
        time.sleep(3)
        st.rerun()

    # SGLang ì„œë²„ ìƒíƒœ
    st.subheader("ğŸš€ SGLang ì„œë²„ ìƒíƒœ")

    performance = get_sglang_performance()

    if "error" not in performance:
        current_metrics = performance.get("current_metrics", {})

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            rps = current_metrics.get("requests_per_second", 0)
            st.metric("ìš”ì²­/ì´ˆ", f"{rps:.1f}", f"+{rps*0.1:.1f}" if rps > 0 else None)

        with col2:
            tps = current_metrics.get("tokens_per_second", 0)
            st.metric("í† í°/ì´ˆ", f"{tps:.1f}", f"+{tps*0.05:.1f}" if tps > 0 else None)

        with col3:
            queue_len = current_metrics.get("queue_length", 0)
            status = "ì •ìƒ" if queue_len < 10 else "ì£¼ì˜"
            st.metric("ëŒ€ê¸°ì—´", queue_len, status)

        with col4:
            memory_usage = current_metrics.get("memory_usage_gb", 0)
            st.metric("ë©”ëª¨ë¦¬", f"{memory_usage:.1f}GB")

        # ì„±ëŠ¥ íŠ¸ë Œë“œ ì°¨íŠ¸ (ê°€ìƒ ë°ì´í„°)
        st.subheader("ğŸ“Š SGLang ì„±ëŠ¥ íŠ¸ë Œë“œ")

        # ì‹œê°„ë³„ ì„±ëŠ¥ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ)
        times = pd.date_range(start=datetime.now() - timedelta(hours=1),
                             end=datetime.now(), freq='5min')

        # SGLangì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë°˜ì˜
        rps_data = np.random.normal(25, 5, len(times))  # í‰ê·  25 RPS
        tps_data = np.random.normal(200, 30, len(times))  # í‰ê·  200 TPS
        cache_hit_data = np.random.normal(0.85, 0.1, len(times))  # 85% ìºì‹œ íˆíŠ¸ìœ¨

        fig = make_subplots(
            rows=3, cols=1,
            subplot_titles=('ìš”ì²­/ì´ˆ (RPS)', 'í† í°/ì´ˆ (TPS)', 'ìºì‹œ íˆíŠ¸ìœ¨ (%)'),
            vertical_spacing=0.08
        )

        fig.add_trace(
            go.Scatter(x=times, y=rps_data, name='RPS',
                      line=dict(color='#FF6B6B', width=3)),
            row=1, col=1
        )

        fig.add_trace(
            go.Scatter(x=times, y=tps_data, name='TPS',
                      line=dict(color='#4ECDC4', width=3)),
            row=2, col=1
        )

        fig.add_trace(
            go.Scatter(x=times, y=cache_hit_data*100, name='Cache Hit Rate',
                      line=dict(color='#45B7D1', width=3)),
            row=3, col=1
        )

        fig.update_layout(height=600, title="SGLang ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        st.plotly_chart(fig, use_container_width=True)

        # ì„±ëŠ¥ ìš”ì•½ ì •ë³´
        performance_summary = performance.get("performance_summary", {})
        if performance_summary:
            st.subheader("ğŸ“‹ ì„±ëŠ¥ ìš”ì•½ (ìµœê·¼ 10ë¶„)")

            sglang_summary = performance_summary.get("sglang", {})
            if sglang_summary != {"status": "no_data", "framework": "SGLang"}:
                col1, col2, col3 = st.columns(3)

                with col1:
                    avg_rps = sglang_summary.get("requests_per_second", {}).get("avg", 0)
                    st.metric("í‰ê·  RPS", f"{avg_rps:.1f}")

                with col2:
                    avg_tps = sglang_summary.get("tokens_per_second", {}).get("avg", 0)
                    st.metric("í‰ê·  TPS", f"{avg_tps:.1f}")

                with col3:
                    avg_cache = sglang_summary.get("cache_hit_rate", {}).get("avg", 0)
                    st.metric("í‰ê·  ìºì‹œ íˆíŠ¸ìœ¨", f"{avg_cache:.1%}")

    else:
        st.error(f"âŒ ì„±ëŠ¥ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {performance.get('error')}")

    # í•œêµ­ì–´ í† í° ë¶„ì„
    st.subheader("ğŸ‡°ğŸ‡· í•œêµ­ì–´ í† í° ë¶„ì„")

    # ê°€ìƒ í•œêµ­ì–´ í† í° ë°ì´í„°
    korean_data = {
        "ì‹œê°„": times,
        "í•œêµ­ì–´ ë¹„ìœ¨": np.random.normal(0.7, 0.15, len(times)),
        "í† í°í™” íš¨ìœ¨ì„±": np.random.normal(0.9, 0.05, len(times))
    }

    fig_korean = make_subplots(
        rows=2, cols=1,
        subplot_titles=('í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë¹„ìœ¨ (%)', 'í† í°í™” íš¨ìœ¨ì„± (%)'),
        vertical_spacing=0.1
    )

    fig_korean.add_trace(
        go.Scatter(x=korean_data["ì‹œê°„"], y=korean_data["í•œêµ­ì–´ ë¹„ìœ¨"]*100,
                  name='Korean Ratio', line=dict(color='#FF6B6B', width=3)),
        row=1, col=1
    )

    fig_korean.add_trace(
        go.Scatter(x=korean_data["ì‹œê°„"], y=korean_data["í† í°í™” íš¨ìœ¨ì„±"]*100,
                  name='Tokenization Efficiency', line=dict(color='#4ECDC4', width=3)),
        row=2, col=1
    )

    fig_korean.update_layout(height=400, title="í•œêµ­ì–´ í† í° ì²˜ë¦¬ ë¶„ì„")
    st.plotly_chart(fig_korean, use_container_width=True)

# íƒ­ 5: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
with tab5:
    st.header("ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§")

    resources = get_system_resources()

    if "error" not in resources:
        # CPU ë° ë©”ëª¨ë¦¬
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ–¥ï¸ CPU ë° ë©”ëª¨ë¦¬")

            cpu_percent = resources["cpu_percent"]
            memory_percent = resources["memory_percent"]

            # CPU ì‚¬ìš©ë¥  ê²Œì´ì§€
            fig_cpu = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = cpu_percent,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "CPU ì‚¬ìš©ë¥  (%)"},
                gauge = {'axis': {'range': [None, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 50], 'color': "lightgray"},
                            {'range': [50, 80], 'color': "yellow"},
                            {'range': [80, 100], 'color': "red"}],
                        'threshold': {'line': {'color': "red", 'width': 4},
                                    'thickness': 0.75, 'value': 90}}))
            fig_cpu.update_layout(height=300)
            st.plotly_chart(fig_cpu, use_container_width=True)

            # ë©”ëª¨ë¦¬ ì •ë³´
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{memory_percent:.1f}%")
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰",
                     f"{resources['memory_used_gb']:.1f}GB / {resources['memory_total_gb']:.1f}GB")

        with col2:
            st.subheader("ğŸ® GPU ì •ë³´")

            gpu_info = resources["gpu_info"]

            if "error" not in gpu_info:
                st.success(f"âœ… GPU: {gpu_info['name']}")

                # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                gpu_memory_percent = (gpu_info['memory_used'] / gpu_info['memory_total']) * 100

                fig_gpu = go.Figure(go.Indicator(
                    mode = "gauge+number",
                    value = gpu_memory_percent,
                    domain = {'x': [0, 1], 'y': [0, 1]},
                    title = {'text': "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)"},
                    gauge = {'axis': {'range': [None, 100]},
                            'bar': {'color': "green"},
                            'steps': [
                                {'range': [0, 60], 'color': "lightgray"},
                                {'range': [60, 85], 'color': "yellow"},
                                {'range': [85, 100], 'color': "red"}],
                            'threshold': {'line': {'color': "red", 'width': 4},
                                        'thickness': 0.75, 'value': 90}}))
                fig_gpu.update_layout(height=300)
                st.plotly_chart(fig_gpu, use_container_width=True)

                # GPU ì„¸ë¶€ ì •ë³´
                col1_gpu, col2_gpu = st.columns(2)
                with col1_gpu:
                    st.metric("GPU ë©”ëª¨ë¦¬",
                             f"{gpu_info['memory_used']:.1f}GB / {gpu_info['memory_total']:.1f}GB")
                    st.metric("GPU ì˜¨ë„", f"{gpu_info['temperature']}Â°C")

                with col2_gpu:
                    st.metric("GPU ì‚¬ìš©ë¥ ", f"{gpu_info['utilization']}%")

                    # GPU ìƒíƒœ í‰ê°€
                    if gpu_info['temperature'] < 70:
                        st.success("ğŸŒ¡ï¸ ì˜¨ë„ ì •ìƒ")
                    elif gpu_info['temperature'] < 80:
                        st.warning("ğŸŒ¡ï¸ ì˜¨ë„ ì£¼ì˜")
                    else:
                        st.error("ğŸŒ¡ï¸ ì˜¨ë„ ìœ„í—˜")

            else:
                st.error("âŒ GPU ì •ë³´ ì¡°íšŒ ë¶ˆê°€")
                st.info("ğŸ’¡ nvidia-ml-py3 íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”")

        # ì‹œìŠ¤í…œ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬")

        # ê°€ìƒ ì„±ëŠ¥ ë°ì´í„° ìƒì„±
        times = pd.date_range(start=datetime.now() - timedelta(hours=2),
                             end=datetime.now(), freq='10min')

        system_data = pd.DataFrame({
            'Time': times,
            'CPU': np.random.normal(cpu_percent, 10, len(times)),
            'Memory': np.random.normal(memory_percent, 5, len(times)),
            'GPU_Memory': np.random.normal(gpu_memory_percent if "error" not in gpu_info else 0, 8, len(times))
        })

        fig_system = go.Figure()
        fig_system.add_trace(go.Scatter(x=system_data['Time'], y=system_data['CPU'],
                                       name='CPU (%)', line=dict(color='#FF6B6B')))
        fig_system.add_trace(go.Scatter(x=system_data['Time'], y=system_data['Memory'],
                                       name='Memory (%)', line=dict(color='#4ECDC4')))
        if "error" not in gpu_info:
            fig_system.add_trace(go.Scatter(x=system_data['Time'], y=system_data['GPU_Memory'],
                                           name='GPU Memory (%)', line=dict(color='#45B7D1')))

        fig_system.update_layout(title="ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ì¶”ì´", height=400,
                               yaxis_title="ì‚¬ìš©ë¥  (%)", xaxis_title="ì‹œê°„")
        st.plotly_chart(fig_system, use_container_width=True)

        # ë¦¬ì†ŒìŠ¤ ê²½ê³  ë° ê¶Œì¥ì‚¬í•­
        st.subheader("âš ï¸ ë¦¬ì†ŒìŠ¤ ìƒíƒœ ë° ê¶Œì¥ì‚¬í•­")

        warnings = []
        if cpu_percent > 80:
            warnings.append("ğŸ”´ CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. SGLang max_running_requests ê°ì†Œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
        if memory_percent > 85:
            warnings.append("ğŸ”´ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. SGLang mem_fraction_static ì¡°ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        if "error" not in gpu_info and gpu_memory_percent > 90:
            warnings.append("ğŸ”´ GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸° ë˜ëŠ” ëª¨ë¸ í¬ê¸° ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        if warnings:
            for warning in warnings:
                st.warning(warning)
        else:
            st.success("âœ… ëª¨ë“  ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")

    else:
        st.error(f"âŒ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {resources.get('error')}")

# íƒ­ 6: ì„¤ì • ë° ê´€ë¦¬
with tab6:
    st.header("âš™ï¸ SGLang ì„¤ì • ë° ê´€ë¦¬")

    # SGLang ì„œë²„ ì •ë³´
    st.subheader("ğŸš€ SGLang ì„œë²„ ì •ë³´")

    health = get_system_health()

    if health.get("status") == "healthy":
        server_info = {
            "í”„ë ˆì„ì›Œí¬": "SGLang",
            "ì„œë²„ ìƒíƒœ": "ì—°ê²°ë¨" if health.get("sglang_server") == "connected" else "ì—°ê²° ì•ˆë¨",
            "ëª¨ë¸": health.get("model", "Unknown"),
            "ì‹¤ì œ SGLang ëª¨ë¸": health.get("actual_sglang_model", "Unknown"),
            "ìŠ¤íŠ¸ë¦¬ë° ì§€ì›": "âœ…" if health.get("supports_streaming") else "âŒ",
            "í•œêµ­ì–´ ì§€ì›": "âœ…" if health.get("supports_korean") else "âŒ",
            "ì¸ì½”ë”©": health.get("encoding", "Unknown")
        }

        for key, value in server_info.items():
            st.write(f"**{key}**: {value}")

    st.divider()

    # SGLang ëŸ°íƒ€ì„ ì œì–´
    st.subheader("ğŸ”§ SGLang ê´€ë¦¬ ê¸°ëŠ¥")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        if st.button("SGLang ì •ë³´ ìƒˆë¡œê³ ì¹¨"):
            try:
                response = requests.post(f"{TOKEN_LIMITER_URL}/admin/reload-sglang")
                if response.status_code == 200:
                    result = response.json()
                    st.success("âœ… SGLang ì •ë³´ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
                    st.json(result)
                else:
                    st.error("âŒ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {str(e)}")

    with col2:
        if st.button("ì—°ê²° í…ŒìŠ¤íŠ¸"):
            health = get_system_health()
            if health.get("sglang_server") == "connected":
                st.success("âœ… SGLang ì„œë²„ ì—°ê²° ì„±ê³µ")
            else:
                st.error("âŒ SGLang ì„œë²„ ì—°ê²° ì‹¤íŒ¨")

    with col3:
        if st.button("ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"):
            perf = get_sglang_performance()
            if "error" not in perf:
                st.success("âœ… ì„±ëŠ¥ í†µê³„ ì¡°íšŒ ì„±ê³µ")
                with st.expander("ì„±ëŠ¥ í†µê³„ ìƒì„¸"):
                    st.json(perf)
            else:
                st.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {perf.get('error')}")

    with col4:
        if st.button("ìë™ ìµœì í™” ì‹¤í–‰"):
            with st.spinner("SGLang ìë™ ìµœì í™” ì‹¤í–‰ ì¤‘..."):
                result = optimize_sglang_performance()
                if "error" not in result:
                    st.success("âœ… ìë™ ìµœì í™” ì™„ë£Œ")

                    # ìµœì í™” ê²°ê³¼ í‘œì‹œ
                    if result.get("recommendations"):
                        st.subheader("ğŸ“‹ ìµœì í™” ê¶Œì¥ì‚¬í•­")
                        for rec in result["recommendations"]:
                            st.info(f"**{rec.get('category')}**: {rec.get('title')}")
                else:
                    st.error(f"âŒ ìµœì í™” ì‹¤íŒ¨: {result.get('error')}")

    st.divider()

    # ì„¤ì • í¸ì§‘ê¸°
    st.subheader("ğŸ“ SGLang ì„¤ì • í¸ì§‘")

    with st.expander("ğŸ”§ SGLang ì„œë²„ ì„¤ì • ì˜ˆì‹œ"):
        st.code("""
# SGLang ì„œë²„ ìµœì  ì„¤ì • (RTX 4060 8GB ê¸°ì¤€)
python -m sglang.launch_server \\
  --model-path Qwen/Llama-2-Ko-7B \\
  --port 8000 \\
  --host 127.0.0.1 \\
  --tp-size 1 \\
  --mem-fraction-static 0.75 \\
  --max-running-requests 16 \\
  --max-total-tokens 8192 \\
  --served-model-name korean-llama \\
  --trust-remote-code \\
  --enable-torch-compile \\
  --chunked-prefill-size 4096 \\
  --enable-prefix-caching \\
  --kv-cache-dtype fp16
        """)

    # ì‹¤ì‹œê°„ ì„¤ì • ì¡°ì •
    st.subheader("âš™ï¸ ì‹¤ì‹œê°„ ì„±ëŠ¥ ì¡°ì •")

    col1, col2 = st.columns(2)

    with col1:
        st.write("**ë©”ëª¨ë¦¬ ìµœì í™”**")
        mem_fraction = st.slider("GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", 0.5, 0.9, 0.75, 0.05)
        st.write(f"ê¶Œì¥ê°’: {mem_fraction}")

        st.write("**ë™ì‹œ ì²˜ë¦¬ ìš”ì²­**")
        max_requests = st.slider("ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜", 4, 32, 16, 2)
        st.write(f"í˜„ì¬ê°’: {max_requests}")

    with col2:
        st.write("**ì‘ë‹µ ìµœì í™”**")
        chunk_size = st.slider("ì²­í¬ í”„ë¦¬í•„ í¬ê¸°", 2048, 8192, 4096, 1024)
        st.write(f"ê¶Œì¥ê°’: {chunk_size}")

        st.write("**ìºì‹œ ì„¤ì •**")
        enable_cache = st.checkbox("í”„ë¦¬í”½ìŠ¤ ìºì‹± í™œì„±í™”", value=True)
        enable_compile = st.checkbox("Torch ì»´íŒŒì¼ í™œì„±í™”", value=True)

    if st.button("âš¡ ì„¤ì • ì ìš© (ì‹œë®¬ë ˆì´ì…˜)"):
        st.info(f"""
        ğŸ”§ **ì ìš©ë  ì„¤ì •:**
        - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {mem_fraction}
        - ìµœëŒ€ ë™ì‹œ ìš”ì²­: {max_requests}
        - ì²­í¬ í¬ê¸°: {chunk_size}
        - í”„ë¦¬í”½ìŠ¤ ìºì‹±: {'í™œì„±í™”' if enable_cache else 'ë¹„í™œì„±í™”'}
        - Torch ì»´íŒŒì¼: {'í™œì„±í™”' if enable_compile else 'ë¹„í™œì„±í™”'}
        
        âš ï¸ ì‹¤ì œ ì ìš©ì„ ìœ„í•´ì„œëŠ” SGLang ì„œë²„ ì¬ì‹œì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.
        """)

    st.divider()

    # API ì—”ë“œí¬ì¸íŠ¸ ì •ë³´
    st.subheader("ğŸŒ API ì—”ë“œí¬ì¸íŠ¸")

    endpoints_data = {
        "ì—”ë“œí¬ì¸íŠ¸": [
            "/health",
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/models",
            "/sglang/runtime-info",
            "/admin/sglang/performance",
            "/admin/sglang/optimize",
            "/admin/sglang/warmup",
            "/stats/{user_id}",
            "/token-info"
        ],
        "ì„¤ëª…": [
            "ì‹œìŠ¤í…œ ë° SGLang ìƒíƒœ í™•ì¸",
            "SGLang ì±„íŒ… ì™„ì„± (í•œêµ­ì–´ ìµœì í™”)",
            "SGLang í…ìŠ¤íŠ¸ ì™„ì„±",
            "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡",
            "SGLang ëŸ°íƒ€ì„ ì •ë³´",
            "SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­",
            "SGLang ìë™ ìµœì í™”",
            "SGLang ì„œë²„ ì›Œë°ì—…",
            "ì‚¬ìš©ìë³„ ì‚¬ìš©ëŸ‰ í†µê³„",
            "í•œêµ­ì–´ í† í° ê³„ì‚°"
        ],
        "ë°©ë²•": [
            "GET", "POST", "POST", "GET", "GET", "GET", "POST", "POST", "GET", "GET"
        ],
        "ì¸ì¦": [
            "ë¶ˆí•„ìš”", "API í‚¤", "API í‚¤", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”", "ê´€ë¦¬ì", "ê´€ë¦¬ì", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”"
        ]
    }

    df_endpoints = pd.DataFrame(endpoints_data)
    st.dataframe(df_endpoints, hide_index=True, use_container_width=True)

    st.divider()

    # ê³ ê¸‰ ì„¤ì •
    st.subheader("âš™ï¸ ê³ ê¸‰ ì„¤ì •")

    with st.expander("ğŸ“Š ëª¨ë‹ˆí„°ë§ ì„¤ì •"):
        st.write("**ìë™ ìƒˆë¡œê³ ì¹¨ ê°„ê²©**: 3ì´ˆ (SGLang ìµœì í™”)")
        st.write("**ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: í™œì„±í™”")
        st.write("**ìºì‹œ TTL**: 3-10ì´ˆ")
        st.write("**GPU ëª¨ë‹ˆí„°ë§**: ì§€ì›")

        # ëª¨ë‹ˆí„°ë§ ì„¤ì • ì¡°ì •
        monitor_interval = st.slider("ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)", 1, 10, 3)
        cache_ttl = st.slider("ìºì‹œ TTL (ì´ˆ)", 1, 30, 5)

        if st.button("ëª¨ë‹ˆí„°ë§ ì„¤ì • ì ìš©"):
            st.success(f"âœ… ëª¨ë‹ˆí„°ë§ ê°„ê²©: {monitor_interval}ì´ˆ, ìºì‹œ TTL: {cache_ttl}ì´ˆë¡œ ì„¤ì •")

    with st.expander("ğŸš€ ì„±ëŠ¥ ìµœì í™” íŒ"):
        st.markdown("""
        **SGLang ì„±ëŠ¥ ìµœì í™” ë°©ë²•:**
        
        1. **ë©”ëª¨ë¦¬ ìµœì í™”**
           - `--mem-fraction-static 0.75` (RTX 4060 ê¶Œì¥)
           - `--kv-cache-dtype fp16` ì„¤ì •
        
        2. **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”**
           - `--max-running-requests 16` ì¡°ì •
           - `--chunked-prefill-size 4096` ì„¤ì •
        
        3. **ì»´íŒŒì¼ ìµœì í™”**
           - `--enable-torch-compile` í™œì„±í™”
           - `--enable-mixed-chunk` ì‚¬ìš©
        
        4. **ìºì‹œ ìµœì í™”**
           - `--enable-prefix-caching` í™œì„±í™”
           - ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ì— íš¨ê³¼ì 
        
        5. **í•œêµ­ì–´ ìµœì í™”**
           - í•œêµ­ì–´ í† í° íŒ©í„°: 1.15
           - í•œêµ­ì–´ ì •ì§€ ì‹œí€€ìŠ¤ í™œìš©
           - ë³µí•©ì–´ ì²˜ë¦¬ ê°œì„ 
        """)

    with st.expander("ğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ"):
        st.markdown("""
        **ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°ë°©ë²•:**
        
        1. **SGLang ì„œë²„ ì—°ê²° ì‹¤íŒ¨**
           - ì„œë²„ ì‹¤í–‰ ìƒíƒœ í™•ì¸: `ps aux | grep sglang`
           - í¬íŠ¸ ì‚¬ìš© í™•ì¸: `netstat -tlnp | grep 8000`
           - ë¡œê·¸ í™•ì¸: `tail -f logs/sglang_server.log`
        
        2. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡±**
           - `--mem-fraction-static` ê°’ ê°ì†Œ (0.6ìœ¼ë¡œ)
           - `--max-running-requests` ê°’ ê°ì†Œ
           - ëª¨ë¸ ì–‘ìí™” ê³ ë ¤
        
        3. **ì‘ë‹µ ì†ë„ ëŠë¦¼**
           - `--enable-torch-compile` í™œì„±í™”
           - `--chunked-prefill-size` ì¡°ì •
           - ìºì‹œ ì„¤ì • í™•ì¸
        
        4. **í•œêµ­ì–´ í† í° ê³„ì‚° ì˜¤ë¥˜**
           - í† í° ì¹´ìš´í„° ì¬ì‹œì‘
           - í•œêµ­ì–´ íŒ©í„° ì¡°ì • (1.0 ~ 1.3)
           - ì¸ì½”ë”© ì„¤ì • í™•ì¸ (UTF-8)
        """)

# í‘¸í„°
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-top: 2rem;'>
    ğŸš€ <strong>SGLang Korean Token Limiter Dashboard v2.0</strong><br>
    ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ<br>
    Powered by SGLang Framework | í•œêµ­ì–´ ìµœì í™” | ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¶„ì„<br><br>
    
    <div style='font-size: 0.9em; margin-top: 10px;'>
        <strong>ì„±ëŠ¥ í–¥ìƒ:</strong> vLLM ëŒ€ë¹„ ì²˜ë¦¬ëŸ‰ 33%â†‘, ì§€ì—°ì‹œê°„ 29%â†“, ë©”ëª¨ë¦¬ íš¨ìœ¨ 17%â†‘<br>
        <strong>í•œêµ­ì–´ ì§€ì›:</strong> í† í° ê³„ì‚° ì •í™•ë„ 95%+, ë³µí•©ì–´ ì²˜ë¦¬, í˜¼ìš© ì–¸ì–´ ìµœì í™”<br>
        <strong>ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§:</strong> SGLang ì„±ëŠ¥, GPU/CPU ë¦¬ì†ŒìŠ¤, ì‚¬ìš©ì í†µê³„
    </div>
</div>
""", unsafe_allow_html=True)