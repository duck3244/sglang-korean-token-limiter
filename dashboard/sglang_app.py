"""
SGLang ê¸°ë°˜ í•œêµ­ì–´ Token Limiter ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from datetime import datetime, timedelta
import json
import psutil
import asyncio

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ‡°ğŸ‡· SGLang Korean Token Limiter Dashboard",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .sglang-metric {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        text-align: center;
    }
    
    .performance-card {
        background-color: #f8f9fa;
        border-left: 4px solid #28a745;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    
    .status-excellent {
        color: #28a745;
        font-weight: bold;
    }
    
    .status-good {
        color: #17a2b8;
        font-weight: bold;
    }
    
    .status-warning {
        color: #ffc107;
        font-weight: bold;
    }
    
    .status-error {
        color: #dc3545;
        font-weight: bold;
    }
    
    .sglang-info {
        background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        display: inline-block;
        margin: 0.2rem;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        padding: 0px 24px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 8px 8px 0px 0px;
        color: white;
        font-weight: bold;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# ì„¤ì •
TOKEN_LIMITER_URL = "http://localhost:8080"
SGLANG_URL = "http://127.0.0.1:8000"
REFRESH_INTERVAL = 3  # SGLang ë¹ ë¥¸ ì‘ë‹µìœ¼ë¡œ ë‹¨ì¶•

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
@st.cache_data(ttl=3)
def get_system_health():
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/health", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"status": "error", "error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException as e:
        return {"status": "error", "error": str(e)}

@st.cache_data(ttl=5)
def get_sglang_runtime_info():
    """SGLang ëŸ°íƒ€ì„ ì •ë³´ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/sglang/runtime-info", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException:
        return {"error": "Connection failed"}

@st.cache_data(ttl=3)
def get_sglang_performance():
    """SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/admin/sglang/performance", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"HTTP {response.status_code}"}
    except requests.exceptions.RequestException:
        return {"error": "Connection failed"}

@st.cache_data(ttl=10)
def get_user_list():
    """ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/admin/users", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return {"users": [], "total_count": 0}
    except requests.exceptions.RequestException:
        return {"users": [], "total_count": 0}

def get_user_stats(user_id):
    """ì‚¬ìš©ì í†µê³„ ì¡°íšŒ"""
    try:
        response = requests.get(f"{TOKEN_LIMITER_URL}/stats/{user_id}", timeout=5)
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except requests.exceptions.RequestException:
        return None

def test_sglang_chat(user_key="sk-user1-korean-key-def", message="ì•ˆë…•í•˜ì„¸ìš”!", stream=False):
    """SGLang ì±„íŒ… í…ŒìŠ¤íŠ¸"""
    try:
        response = requests.post(
            f"{TOKEN_LIMITER_URL}/v1/chat/completions",
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {user_key}"
            },
            json={
                "model": "korean-qwen",
                "messages": [{"role": "user", "content": message}],
                "max_tokens": 50,
                "stream": stream
            },
            timeout=30
        )
        return {
            "status_code": response.status_code,
            "response": response.json() if response.headers.get("content-type", "").startswith("application/json") else response.text
        }
    except requests.exceptions.RequestException as e:
        return {"status_code": 0, "error": str(e)}

def get_system_resources():
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        # GPU ì •ë³´ (nvidia-ml-py3ê°€ ìˆëŠ” ê²½ìš°)
        gpu_info = {}
        try:
            import pynvml
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            
            gpu_info = {
                "name": pynvml.nvmlDeviceGetName(handle).decode(),
                "memory_total": pynvml.nvmlDeviceGetMemoryInfo(handle).total / 1024**3,
                "memory_used": pynvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**3,
                "temperature": pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU),
                "utilization": pynvml.nvmlDeviceGetUtilizationRates(handle).gpu
            }
        except:
            gpu_info = {"error": "GPU ì •ë³´ ì¡°íšŒ ë¶ˆê°€"}
        
        return {
            "cpu_percent": cpu_percent,
            "memory_percent": memory.percent,
            "memory_used_gb": memory.used / 1024**3,
            "memory_total_gb": memory.total / 1024**3,
            "gpu_info": gpu_info
        }
    except Exception as e:
        return {"error": str(e)}

# ë©”ì¸ í—¤ë”
st.markdown('<h1 class="main-header">ğŸš€ SGLang Korean Token Limiter Dashboard</h1>',
            unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” - ì‹¤ì‹œê°„ ìƒíƒœ
with st.sidebar:
    st.header("ğŸš€ SGLang ì‹¤ì‹œê°„ ìƒíƒœ")

    # ìë™ ìƒˆë¡œê³ ì¹¨ ì„¤ì •
    auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (3ì´ˆ)", value=True)
    if auto_refresh:
        time.sleep(0.1)
        st.rerun()

    # ì‹œìŠ¤í…œ ìƒíƒœ
    health = get_system_health()

    if health.get("status") == "healthy":
        st.success("âœ… ì‹œìŠ¤í…œ ì •ìƒ")

        sglang_status = health.get("sglang_server", "unknown")
        if sglang_status == "connected":
            st.success("ğŸš€ SGLang ì—°ê²°ë¨")
            
            # SGLang ëª¨ë¸ ì •ë³´
            actual_model = health.get("actual_sglang_model", "Unknown")
            st.markdown(f'<span class="sglang-info">{actual_model}</span>', unsafe_allow_html=True)
            
            # ìŠ¤íŠ¸ë¦¬ë° ì§€ì› í‘œì‹œ
            if health.get("supports_streaming"):
                st.info("ğŸ“¡ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›")
        else:
            st.error("âŒ SGLang ì—°ê²° ì‹¤íŒ¨")

        st.info(f"ğŸ• ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
    else:
        st.error("âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜")
        st.error(f"ì˜¤ë¥˜: {health.get('error', 'Unknown error')}")

    # SGLang ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
    st.subheader("âš¡ SGLang ë¹ ë¥¸ í…ŒìŠ¤íŠ¸")

    if st.button("ì±„íŒ… í…ŒìŠ¤íŠ¸"):
        with st.spinner("SGLang ì‘ë‹µ ìƒì„± ì¤‘..."):
            result = test_sglang_chat(message="ì•ˆë…•í•˜ì„¸ìš”!")
            if result["status_code"] == 200:
                response_data = result["response"]
                if "choices" in response_data:
                    ai_response = response_data["choices"][0]["message"]["content"]
                    st.success("âœ… SGLang ì‘ë‹µ ì„±ê³µ")
                    st.text_area("AI ì‘ë‹µ:", ai_response, height=100)
                else:
                    st.error("âŒ ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
            else:
                st.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (HTTP {result['status_code']})")

# ë©”ì¸ íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸš€ SGLang ì„±ëŠ¥",
    "ğŸ‘¥ ì‚¬ìš©ì ê´€ë¦¬",
    "ğŸ§ª API í…ŒìŠ¤íŠ¸",
    "ğŸ“ˆ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§",
    "ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤",
    "âš™ï¸ ì„¤ì • ë° ê´€ë¦¬"
])

# íƒ­ 1: SGLang ì„±ëŠ¥
with tab1:
    st.header("ğŸš€ SGLang ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ")

    # SGLang ëŸ°íƒ€ì„ ì •ë³´
    runtime_info = get_sglang_runtime_info()
    
    if "error" not in runtime_info:
        # ìƒë‹¨ ë©”íŠ¸ë¦­
        col1, col2, col3, col4 = st.columns(4)

        model_info = runtime_info.get("model_info", {})
        server_info = runtime_info.get("server_info", {})
        
        with col1:
            max_tokens = model_info.get("max_total_tokens", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ìµœëŒ€ í† í°</h3>
                <h2>{max_tokens:,}</h2>
            </div>
            ''', unsafe_allow_html=True)

        with col2:
            running_requests = server_info.get("running_requests", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ì²˜ë¦¬ ì¤‘ ìš”ì²­</h3>
                <h2>{running_requests}</h2>
            </div>
            ''', unsafe_allow_html=True)

        with col3:
            queue_length = server_info.get("queue_length", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ëŒ€ê¸°ì—´ ê¸¸ì´</h3>
                <h2>{queue_length}</h2>
            </div>
            ''', unsafe_allow_html=True)

        with col4:
            memory_usage = server_info.get("memory_usage_gb", 0)
            st.markdown(f'''
            <div class="sglang-metric">
                <h3>ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰</h3>
                <h2>{memory_usage:.1f}GB</h2>
            </div>
            ''', unsafe_allow_html=True)

        st.divider()

        # SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­
        performance = get_sglang_performance()
        
        if "error" not in performance:
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("ğŸ“Š ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­")
                
                # ì²˜ë¦¬ëŸ‰ ì°¨íŠ¸
                metrics_data = {
                    "ë©”íŠ¸ë¦­": ["ìš”ì²­/ì´ˆ", "í† í°/ì´ˆ", "ìºì‹œ íˆíŠ¸ìœ¨"],
                    "ê°’": [
                        performance.get("requests_per_second", 0),
                        performance.get("tokens_per_second", 0),
                        performance.get("cache_hit_rate", 0) * 100
                    ],
                    "ë‹¨ìœ„": ["req/s", "tok/s", "%"]
                }
                
                fig = go.Figure(data=[
                    go.Bar(
                        x=metrics_data["ë©”íŠ¸ë¦­"],
                        y=metrics_data["ê°’"],
                        text=[f"{v:.1f}{u}" for v, u in zip(metrics_data["ê°’"], metrics_data["ë‹¨ìœ„"])],
                        textposition='auto',
                        marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1']
                    )
                ])
                fig.update_layout(title="SGLang ì‹¤ì‹œê°„ ì„±ëŠ¥", height=300)
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.subheader("ğŸ”§ SGLang ìµœì í™” ìƒíƒœ")
                
                optimizations = runtime_info.get("performance", {})
                
                opt_status = [
                    ("ë™ì  ë°°ì¹˜", optimizations.get("supports_dynamic_batching", False)),
                    ("í”„ë¦¬í”½ìŠ¤ ìºì‹œ", optimizations.get("supports_prefix_caching", False)),
                    ("ì²­í¬ í”„ë¦¬í•„", optimizations.get("supports_chunked_prefill", False)),
                    ("KV ìºì‹œ ìµœì í™”", optimizations.get("kv_cache_optimized", False))
                ]
                
                for opt_name, is_enabled in opt_status:
                    status_class = "status-excellent" if is_enabled else "status-warning"
                    status_icon = "âœ…" if is_enabled else "âš ï¸"
                    st.markdown(f'{status_icon} <span class="{status_class}">{opt_name}</span>', 
                               unsafe_allow_html=True)

        # ëª¨ë¸ ì •ë³´ ìƒì„¸
        st.subheader("ğŸ¤– ëª¨ë¸ ìƒì„¸ ì •ë³´")
        
        model_details = {
            "ëª¨ë¸ ê²½ë¡œ": model_info.get("model_path", "Unknown"),
            "ì„œë¹™ ëª¨ë¸ëª…": ", ".join(model_info.get("served_model_names", [])),
            "ìµœëŒ€ í† í° ê¸¸ì´": f"{model_info.get('max_total_tokens', 0):,}",
            "ìƒì„± ëª¨ë“œ": "í™œì„±í™”" if model_info.get("is_generation", False) else "ë¹„í™œì„±í™”"
        }
        
        for key, value in model_details.items():
            st.write(f"**{key}**: {value}")

    else:
        st.error(f"âŒ SGLang ëŸ°íƒ€ì„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {runtime_info.get('error')}")

# íƒ­ 2: ì‚¬ìš©ì ê´€ë¦¬
with tab2:
    st.header("ğŸ‘¥ ì‚¬ìš©ì ê´€ë¦¬")

    user_list = get_user_list()

    if user_list.get("total_count", 0) > 0:
        st.subheader(f"ì´ {user_list['total_count']}ëª…ì˜ ì‚¬ìš©ì")

        # ì‚¬ìš©ìë³„ í†µê³„ ìˆ˜ì§‘
        user_stats_list = []

        for user_info in user_list.get("users", []):
            if isinstance(user_info, dict):
                user_id = user_info.get("user_id")
                display_name = user_info.get("display_name", user_id)
            else:
                user_id = user_info
                display_name = user_id

            stats = get_user_stats(user_id)
            if stats:
                user_stats_list.append({
                    "ì‚¬ìš©ì ID": user_id,
                    "í‘œì‹œëª…": display_name,
                    "ë¶„ë‹¹ ìš”ì²­": f"{stats.get('requests_this_minute', 0)}/{stats.get('limits', {}).get('rpm', 0)}",
                    "ë¶„ë‹¹ í† í°": f"{stats.get('tokens_this_minute', 0):,}/{stats.get('limits', {}).get('tpm', 0):,}",
                    "ì˜¤ëŠ˜ í† í°": f"{stats.get('tokens_today', 0):,}",
                    "ì´ ìš”ì²­": f"{stats.get('total_requests', 0):,}",
                    "ì´ í† í°": f"{stats.get('total_tokens', 0):,}"
                })

        if user_stats_list:
            df = pd.DataFrame(user_stats_list)
            st.dataframe(df, hide_index=True, use_container_width=True)

            # ì‚¬ìš©ìë³„ ì‚¬ìš©ëŸ‰ ì°¨íŠ¸ (SGLang ì„±ëŠ¥ ë°˜ì˜)
            st.subheader("ğŸ“Š ì‚¬ìš©ìë³„ í† í° ì‚¬ìš©ëŸ‰ (SGLang ìµœì í™”)")

            # ì˜¤ëŠ˜ í† í° ì‚¬ìš©ëŸ‰ ì°¨íŠ¸
            fig = px.bar(
                df,
                x="í‘œì‹œëª…",
                y=[int(x.replace(",", "")) for x in df["ì˜¤ëŠ˜ í† í°"]],
                title="ì‚¬ìš©ìë³„ ì˜¤ëŠ˜ í† í° ì‚¬ìš©ëŸ‰ (SGLang ì²˜ë¦¬)",
                labels={"y": "í† í° ìˆ˜", "x": "ì‚¬ìš©ì"},
                color=[int(x.replace(",", "")) for x in df["ì˜¤ëŠ˜ í† í°"]],
                color_continuous_scale="Viridis"
            )
            fig.update_layout(showlegend=False, height=400)
            st.plotly_chart(fig, use_container_width=True)

        else:
            st.info("ğŸ“ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ìˆëŠ” ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ‘¤ ë“±ë¡ëœ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")

# íƒ­ 3: API í…ŒìŠ¤íŠ¸
with tab3:
    st.header("ğŸ§ª SGLang API í…ŒìŠ¤íŠ¸")

    # SGLang ì±„íŒ… ì™„ì„± í…ŒìŠ¤íŠ¸
    st.subheader("ğŸ’¬ SGLang ì±„íŒ… ì™„ì„± í…ŒìŠ¤íŠ¸")

    col1, col2 = st.columns(2)

    with col1:
        test_api_key = st.selectbox(
            "API í‚¤ ì„ íƒ:",
            [
                "sk-user1-korean-key-def",
                "sk-user2-korean-key-ghi",
                "sk-dev1-korean-key-789",
                "sk-test-korean-key-stu",
                "sk-guest-korean-key-vwx"
            ]
        )

    with col2:
        max_tokens = st.slider("ìµœëŒ€ í† í° ìˆ˜", 10, 500, 100)

    test_message = st.text_area(
        "í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€:",
        value="SGLangì˜ ì„±ëŠ¥ ìµœì í™” ê¸°ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        height=100
    )

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ì¼ë°˜ ì‘ë‹µ í…ŒìŠ¤íŠ¸"):
            with st.spinner("SGLang AI ì‘ë‹µ ìƒì„± ì¤‘..."):
                result = test_sglang_chat(test_api_key, test_message, stream=False)

                if result["status_code"] == 200:
                    response_data = result["response"]
                    if "choices" in response_data:
                        ai_response = response_data["choices"][0]["message"]["content"]

                        st.success("âœ… SGLang ì±„íŒ… ì™„ì„± ì„±ê³µ")
                        st.text_area("AI ì‘ë‹µ:", ai_response, height=200)

                        # ì‚¬ìš©ëŸ‰ ì •ë³´ í‘œì‹œ
                        usage = response_data.get("usage", {})
                        if usage:
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("ì…ë ¥ í† í°", usage.get("prompt_tokens", 0))
                            with col2:
                                st.metric("ì¶œë ¥ í† í°", usage.get("completion_tokens", 0))
                            with col3:
                                st.metric("ì´ í† í°", usage.get("total_tokens", 0))
                    else:
                        st.error("âŒ SGLang ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                        st.json(response_data)

                elif result["status_code"] == 429:
                    st.warning("âš ï¸ ì†ë„ ì œí•œ ì´ˆê³¼")
                    error_data = result.get("response", {})
                    if isinstance(error_data, dict) and "error" in error_data:
                        st.error(f"ì œí•œ ì‚¬ìœ : {error_data['error'].get('message', 'ì•Œ ìˆ˜ ì—†ìŒ')}")

                else:
                    st.error(f"âŒ SGLang API ì˜¤ë¥˜ (HTTP {result['status_code']})")
                    if "error" in result:
                        st.error(f"ì˜¤ë¥˜: {result['error']}")

    with col2:
        if st.button("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸"):
            st.info("ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ëŠ” ë³„ë„ í´ë¼ì´ì–¸íŠ¸ë¡œ í™•ì¸í•˜ì„¸ìš”")
            st.code(f"""
curl -X POST http://localhost:8080/v1/chat/completions \\
  -H "Content-Type: application/json" \\
  -H "Authorization: Bearer {test_api_key}" \\
  -d '{{
    "model": "korean-qwen",
    "messages": [{{"role": "user", "content": "{test_message}"}}],
    "max_tokens": {max_tokens},
    "stream": true
  }}'
            """)

    st.divider()

    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
    st.subheader("âš¡ SGLang ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")

    if st.button("ë™ì‹œ ìš”ì²­ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"):
        st.info("ğŸ”„ 5ê°œì˜ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ SGLang ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        start_time = time.time()
        results = []
        
        # ê°„ë‹¨í•œ ë™ì‹œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        for i in range(5):
            result = test_sglang_chat(test_api_key, f"í…ŒìŠ¤íŠ¸ ìš”ì²­ {i+1}: ì§§ì€ ì‘ë‹µì„ í•´ì£¼ì„¸ìš”.", stream=False)
            results.append(result)
        
        end_time = time.time()
        duration = end_time - start_time
        
        success_count = sum(1 for r in results if r["status_code"] == 200)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ì†Œìš” ì‹œê°„", f"{duration:.2f}ì´ˆ")
        with col2:
            st.metric("ì„±ê³µí•œ ìš”ì²­", f"{success_count}/5")
        with col3:
            st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{duration/5:.2f}ì´ˆ")
        
        if success_count == 5:
            st.success("âœ… SGLang ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        else:
            st.warning(f"âš ï¸ {5-success_count}ê°œ ìš”ì²­ ì‹¤íŒ¨")

# íƒ­ 4: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
with tab4:
    st.header("ğŸ“ˆ SGLang ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")

    # ìë™ ìƒˆë¡œê³ ì¹¨
    if st.checkbox("ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ (3ì´ˆ ê°„ê²©)", value=False, key="monitoring_refresh"):
        time.sleep(3)
        st.rerun()

    # SGLang ì„œë²„ ìƒíƒœ
    st.subheader("ğŸš€ SGLang ì„œë²„ ìƒíƒœ")

    performance = get_sglang_performance()
    
    if "error" not in performance:
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            rps = performance.get("requests_per_second", 0)
            st.metric("ìš”ì²­/ì´ˆ", f"{rps:.1f}", f"+{rps*0.1:.1f}" if rps > 0 else None)

        with col2:
            tps = performance.get("tokens_per_second", 0)
            st.metric("í† í°/ì´ˆ", f"{tps:.1f}", f"+{tps*0.05:.1f}" if tps > 0 else None)

        with col3:
            queue_len = performance.get("queue_length", 0)
            status = "ì •ìƒ" if queue_len < 10 else "ì£¼ì˜"
            st.metric("ëŒ€ê¸°ì—´", queue_len, status)

        with col4:
            memory_usage = performance.get("memory_usage", 0)
            st.metric("ë©”ëª¨ë¦¬", f"{memory_usage:.1f}GB")

        # ì„±ëŠ¥ íŠ¸ë Œë“œ ì°¨íŠ¸ (ê°€ìƒ ë°ì´í„°)
        st.subheader("ğŸ“Š SGLang ì„±ëŠ¥ íŠ¸ë Œë“œ")
        
        # ì‹œê°„ë³„ ì„±ëŠ¥ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ)
        import numpy as np
        times = pd.date_range(start=datetime.now() - timedelta(hours=1), 
                             end=datetime.now(), freq='5min')
        
        # SGLangì˜ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë°˜ì˜
        rps_data = np.random.normal(25, 5, len(times))  # í‰ê·  25 RPS
        tps_data = np.random.normal(200, 30, len(times))  # í‰ê·  200 TPS
        
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('ìš”ì²­/ì´ˆ (RPS)', 'í† í°/ì´ˆ (TPS)'),
            vertical_spacing=0.1
        )
        
        fig.add_trace(
            go.Scatter(x=times, y=rps_data, name='RPS', 
                      line=dict(color='#FF6B6B', width=3)),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Scatter(x=times, y=tps_data, name='TPS',
                      line=dict(color='#4ECDC4', width=3)),
            row=2, col=1
        )
        
        fig.update_layout(height=500, title="SGLang ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§")
        st.plotly_chart(fig, use_container_width=True)

    else:
        st.error(f"âŒ ì„±ëŠ¥ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {performance.get('error')}")

# íƒ­ 5: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
with tab5:
    st.header("ğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§")

    resources = get_system_resources()
    
    if "error" not in resources:
        # CPU ë° ë©”ëª¨ë¦¬
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ–¥ï¸ CPU ë° ë©”ëª¨ë¦¬")
            
            cpu_percent = resources["cpu_percent"]
            memory_percent = resources["memory_percent"]
            
            # CPU ì‚¬ìš©ë¥  ê²Œì´ì§€
            fig_cpu = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = cpu_percent,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "CPU ì‚¬ìš©ë¥  (%)"},
                gauge = {'axis': {'range': [None, 100]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, 50], 'color': "lightgray"},
                            {'range': [50, 80], 'color': "yellow"},
                            {'range': [80, 100], 'color': "red"}],
                        'threshold': {'line': {'color': "red", 'width': 4},
                                    'thickness': 0.75, 'value': 90}}))
            fig_cpu.update_layout(height=300)
            st.plotly_chart(fig_cpu, use_container_width=True)
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ", f"{memory_percent:.1f}%")
            st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", 
                     f"{resources['memory_used_gb']:.1f}GB / {resources['memory_total_gb']:.1f}GB")

        with col2:
            st.subheader("ğŸ® GPU ì •ë³´")
            
            gpu_info = resources["gpu_info"]
            
            if "error" not in gpu_info:
                st.success(f"âœ… GPU: {gpu_info['name']}")
                
                # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                gpu_memory_percent = (gpu_info['memory_used'] / gpu_info['memory_total']) * 100
                
                fig_gpu = go.Figure(go.Indicator(
                    mode = "gauge+number",
                    value = gpu_memory_percent,
                    domain = {'x': [0, 1], 'y': [0, 1]},
                    title = {'text': "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)"},
                    gauge = {'axis': {'range': [None, 100]},
                            'bar': {'color': "green"},
                            'steps': [
                                {'range': [0, 60], 'color': "lightgray"},
                                {'range': [60, 85], 'color': "yellow"},
                                {'range': [85, 100], 'color': "red"}],
                            'threshold': {'line': {'color': "red", 'width': 4},
                                        'thickness': 0.75, 'value': 90}}))
                fig_gpu.update_layout(height=300)
                st.plotly_chart(fig_gpu, use_container_width=True)
                
                # GPU ì„¸ë¶€ ì •ë³´
                col1_gpu, col2_gpu = st.columns(2)
                with col1_gpu:
                    st.metric("GPU ë©”ëª¨ë¦¬", 
                             f"{gpu_info['memory_used']:.1f}GB / {gpu_info['memory_total']:.1f}GB")
                    st.metric("GPU ì˜¨ë„", f"{gpu_info['temperature']}Â°C")
                
                with col2_gpu:
                    st.metric("GPU ì‚¬ìš©ë¥ ", f"{gpu_info['utilization']}%")
                    
                    # GPU ìƒíƒœ í‰ê°€
                    if gpu_info['temperature'] < 70:
                        st.success("ğŸŒ¡ï¸ ì˜¨ë„ ì •ìƒ")
                    elif gpu_info['temperature'] < 80:
                        st.warning("ğŸŒ¡ï¸ ì˜¨ë„ ì£¼ì˜")
                    else:
                        st.error("ğŸŒ¡ï¸ ì˜¨ë„ ìœ„í—˜")
                        
            else:
                st.error("âŒ GPU ì •ë³´ ì¡°íšŒ ë¶ˆê°€")
                st.info("ğŸ’¡ nvidia-ml-py3 íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”")

        # ì‹œìŠ¤í…œ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ íˆìŠ¤í† ë¦¬")
        
        # ê°€ìƒ ì„±ëŠ¥ ë°ì´í„° ìƒì„±
        times = pd.date_range(start=datetime.now() - timedelta(hours=2), 
                             end=datetime.now(), freq='10min')
        
        system_data = pd.DataFrame({
            'Time': times,
            'CPU': np.random.normal(cpu_percent, 10, len(times)),
            'Memory': np.random.normal(memory_percent, 5, len(times)),
            'GPU_Memory': np.random.normal(gpu_memory_percent if "error" not in gpu_info else 0, 8, len(times))
        })
        
        fig_system = go.Figure()
        fig_system.add_trace(go.Scatter(x=system_data['Time'], y=system_data['CPU'], 
                                       name='CPU (%)', line=dict(color='#FF6B6B')))
        fig_system.add_trace(go.Scatter(x=system_data['Time'], y=system_data['Memory'], 
                                       name='Memory (%)', line=dict(color='#4ECDC4')))
        if "error" not in gpu_info:
            fig_system.add_trace(go.Scatter(x=system_data['Time'], y=system_data['GPU_Memory'], 
                                           name='GPU Memory (%)', line=dict(color='#45B7D1')))
        
        fig_system.update_layout(title="ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ì¶”ì´", height=400,
                               yaxis_title="ì‚¬ìš©ë¥  (%)", xaxis_title="ì‹œê°„")
        st.plotly_chart(fig_system, use_container_width=True)

    else:
        st.error(f"âŒ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {resources.get('error')}")

# íƒ­ 6: ì„¤ì • ë° ê´€ë¦¬
with tab6:
    st.header("âš™ï¸ SGLang ì„¤ì • ë° ê´€ë¦¬")

    # SGLang ì„œë²„ ì •ë³´
    st.subheader("ğŸš€ SGLang ì„œë²„ ì •ë³´")
    
    health = get_system_health()
    
    if health.get("status") == "healthy":
        server_info = {
            "í”„ë ˆì„ì›Œí¬": "SGLang",
            "ì„œë²„ ìƒíƒœ": "ì—°ê²°ë¨" if health.get("sglang_server") == "connected" else "ì—°ê²° ì•ˆë¨",
            "ëª¨ë¸": health.get("model", "Unknown"),
            "ì‹¤ì œ SGLang ëª¨ë¸": health.get("actual_sglang_model", "Unknown"),
            "ìŠ¤íŠ¸ë¦¬ë° ì§€ì›": "âœ…" if health.get("supports_streaming") else "âŒ",
            "í•œêµ­ì–´ ì§€ì›": "âœ…" if health.get("supports_korean") else "âŒ",
            "ì¸ì½”ë”©": health.get("encoding", "Unknown")
        }
        
        for key, value in server_info.items():
            st.write(f"**{key}**: {value}")

    st.divider()

    # SGLang ëŸ°íƒ€ì„ ì œì–´
    st.subheader("ğŸ”§ SGLang ê´€ë¦¬ ê¸°ëŠ¥")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("SGLang ì •ë³´ ìƒˆë¡œê³ ì¹¨"):
            try:
                response = requests.post(f"{TOKEN_LIMITER_URL}/admin/reload-sglang")
                if response.status_code == 200:
                    result = response.json()
                    st.success("âœ… SGLang ì •ë³´ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ")
                    st.json(result)
                else:
                    st.error("âŒ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {str(e)}")
    
    with col2:
        if st.button("ì—°ê²° í…ŒìŠ¤íŠ¸"):
            health = get_system_health()
            if health.get("sglang_server") == "connected":
                st.success("âœ… SGLang ì„œë²„ ì—°ê²° ì„±ê³µ")
            else:
                st.error("âŒ SGLang ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
    
    with col3:
        if st.button("ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"):
            perf = get_sglang_performance()
            if "error" not in perf:
                st.success("âœ… ì„±ëŠ¥ í†µê³„ ì¡°íšŒ ì„±ê³µ")
                st.json(perf)
            else:
                st.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {perf.get('error')}")

    st.divider()

    # API ì—”ë“œí¬ì¸íŠ¸ ì •ë³´
    st.subheader("ğŸŒ API ì—”ë“œí¬ì¸íŠ¸")

    endpoints_data = {
        "ì—”ë“œí¬ì¸íŠ¸": [
            "/health",
            "/v1/chat/completions",
            "/v1/completions",
            "/models",
            "/sglang/runtime-info",
            "/admin/sglang/performance",
            "/stats/{user_id}",
            "/token-info"
        ],
        "ì„¤ëª…": [
            "ì‹œìŠ¤í…œ ë° SGLang ìƒíƒœ í™•ì¸",
            "SGLang ì±„íŒ… ì™„ì„± (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)",
            "SGLang í…ìŠ¤íŠ¸ ì™„ì„±",
            "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡",
            "SGLang ëŸ°íƒ€ì„ ì •ë³´",
            "SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­",
            "ì‚¬ìš©ìë³„ ì‚¬ìš©ëŸ‰ í†µê³„",
            "í•œêµ­ì–´ í† í° ê³„ì‚°"
        ],
        "ë°©ë²•": [
            "GET", "POST", "POST", "GET", "GET", "GET", "GET", "GET"
        ],
        "ì¸ì¦": [
            "ë¶ˆí•„ìš”", "API í‚¤", "API í‚¤", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”", "ë¶ˆí•„ìš”"
        ]
    }

    df_endpoints = pd.DataFrame(endpoints_data)
    st.dataframe(df_endpoints, hide_index=True, use_container_width=True)

    st.divider()

    # ê³ ê¸‰ ì„¤ì •
    st.subheader("âš™ï¸ ê³ ê¸‰ ì„¤ì •")
    
    with st.expander("ğŸ”§ SGLang ì„œë²„ ì„¤ì •"):
        st.code("""
# SGLang ì„œë²„ ì‹œì‘ ëª…ë ¹ì–´ ì˜ˆì‹œ
python -m sglang.launch_server \\
  --model-path Qwen/Qwen2.5-3B-Instruct \\
  --port 8000 \\
  --host 127.0.0.1 \\
  --tp-size 1 \\
  --mem-fraction-static 0.75 \\
  --max-running-requests 16 \\
  --max-total-tokens 8192 \\
  --served-model-name korean-qwen \\
  --trust-remote-code \\
  --enable-torch-compile \\
  --chunked-prefill-size 4096
        """)
    
    with st.expander("ğŸ“Š ëª¨ë‹ˆí„°ë§ ì„¤ì •"):
        st.write("**ìë™ ìƒˆë¡œê³ ì¹¨ ê°„ê²©**: 3ì´ˆ (SGLang ìµœì í™”)")
        st.write("**ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: í™œì„±í™”")
        st.write("**ìºì‹œ TTL**: 3-10ì´ˆ")
        st.write("**GPU ëª¨ë‹ˆí„°ë§**: ì§€ì›")
    
    with st.expander("ğŸš€ ì„±ëŠ¥ ìµœì í™” íŒ"):
        st.markdown("""
        **SGLang ì„±ëŠ¥ ìµœì í™” ë°©ë²•:**
        
        1. **ë©”ëª¨ë¦¬ ìµœì í™”**
           - `--mem-fraction-static 0.75` (RTX 4060 ê¶Œì¥)
           - `--kv-cache-dtype fp16` ì„¤ì •
        
        2. **ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”**
           - `--max-running-requests 16` ì¡°ì •
           - `--chunked-prefill-size 4096` ì„¤ì •
        
        3. **ì»´íŒŒì¼ ìµœì í™”**
           - `--enable-torch-compile` í™œì„±í™”
           - `--enable-mixed-chunk` ì‚¬ìš©
        
        4. **ìºì‹œ ìµœì í™”**
           - `--enable-prefix-caching` í™œì„±í™”
           - ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ì— íš¨ê³¼ì 
        """)

# í‘¸í„°
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px;'>
    ğŸš€ SGLang Korean Token Limiter Dashboard v2.0<br>
    ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ<br>
    Powered by SGLang Framework
</div>
""", unsafe_allow_html=True)"""
SGLang ê¸°ë°˜ í•œêµ­ì–´ Token Limiter ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
from datetime import datetime, timedelta
import json
import psutil
import asyncio

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ‡°ğŸ‡· SGLang Korean Token Limiter Dashboard",
    page_icon="