#!/usr/bin/env python3
"""
SGLang ë¹ ë¥¸ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ (ì˜µì…˜ ìˆ˜ì • ë²„ì „)
"""

import sys
import subprocess
import time
import requests
import os

def start_sglang_quick():
    """SGLang ì„œë²„ ë¹ ë¥¸ ì‹œì‘ (ìœ íš¨í•œ ì˜µì…˜ë§Œ ì‚¬ìš©)"""

    print("ğŸš€ SGLang ì„œë²„ ë¹ ë¥¸ ì‹œì‘ (ì˜µì…˜ ìˆ˜ì • ë²„ì „)")
    print("=" * 50)

    # ê¸°ë³¸ ì„¤ì •
    model_path = "microsoft/DialoGPT-medium"
    port = 8000

    # GPU í™•ì¸
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            gpu_name = torch.cuda.get_device_name()
            print(f"âœ… GPU: {gpu_name}")
        else:
            print("ğŸ’» CPU ëª¨ë“œ")
    except:
        gpu_available = False
        print("ğŸ’» CPU ëª¨ë“œ")

    # ì„œë²„ ëª…ë ¹ì–´ (ìœ íš¨í•œ ì˜µì…˜ë§Œ ì‚¬ìš©)
    cmd = [
        sys.executable, "-m", "sglang.launch_server",
        "--model-path", model_path,
        "--port", str(port),
        "--host", "127.0.0.1",
        "--trust-remote-code"
    ]

    # GPU ì‚¬ìš© ì‹œ ì¶”ê°€ ì˜µì…˜
    if gpu_available:
        cmd.extend([
            "--mem-fraction-static", "0.75",
            "--max-running-requests", "6",
            "--kv-cache-dtype", "auto",  # auto ì‚¬ìš© (fp16 ëŒ€ì‹ )
            "--tensor-parallel-size", "1"
        ])

        # RTX 4060 ê°ì§€ ì‹œ ì•ˆì „ ì˜µì…˜
        if "4060" in gpu_name:
            cmd.extend([
                "--disable-cuda-graph",
                "--disable-flashinfer"
            ])
    else:
        # CPU ëª¨ë“œ
        cmd.extend([
            "--disable-cuda-graph",
            "--disable-flashinfer"
        ])

    print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {' '.join(cmd)}")

    try:
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("logs", exist_ok=True)

        # ì„œë²„ ì‹œì‘
        with open("logs/sglang_quick.log", "w") as log_file:
            process = subprocess.Popen(
                cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT
            )

        print(f"âœ… ì„œë²„ ì‹œì‘ (PID: {process.pid})")

        # ì„œë²„ ì¤€ë¹„ ëŒ€ê¸°
        print("â³ ì„œë²„ ì¤€ë¹„ ëŒ€ê¸°...")
        for i in range(120):
            try:
                response = requests.get(f"http://127.0.0.1:{port}/get_model_info", timeout=3)
                if response.status_code == 200:
                    print(f"âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! ({i+1}ì´ˆ)")

                    # ëª¨ë¸ ì •ë³´ í‘œì‹œ
                    model_info = response.json()
                    print(f"ëª¨ë¸: {model_info.get('model_path', 'Unknown')}")

                    print()
                    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´:")
                    print(f"curl http://127.0.0.1:{port}/get_model_info")
                    print()
                    print("ğŸ›‘ ì¢…ë£Œ: Ctrl+C")

                    # ì„œë²„ ëŒ€ê¸°
                    try:
                        process.wait()
                    except KeyboardInterrupt:
                        print("\nğŸ›‘ ì„œë²„ ì¢…ë£Œ ì¤‘...")
                        process.terminate()
                        process.wait()
                        print("âœ… ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")

                    return 0
            except:
                pass

            # í”„ë¡œì„¸ìŠ¤ ì²´í¬
            if process.poll() is not None:
                print("âŒ ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë¨")
                if os.path.exists("logs/sglang_quick.log"):
                    print("\n=== ë¡œê·¸ ===")
                    with open("logs/sglang_quick.log", "r") as f:
                        print(f.read()[-1000:])
                return 1

            if i % 20 == 0 and i > 0:
                print(f"ëŒ€ê¸° ì¤‘... {i}ì´ˆ")

            time.sleep(1)

        print("âŒ ì„œë²„ ì‹œì‘ ì‹œê°„ ì´ˆê³¼")
        process.terminate()
        return 1

    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(start_sglang_quick())
