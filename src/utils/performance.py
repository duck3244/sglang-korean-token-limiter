"""
SGLang ê¸°ë°˜ í•œêµ­ì–´ Token Limiter ì„±ëŠ¥ ìµœì í™” ìœ í‹¸ë¦¬í‹°
"""

import time
import asyncio
import psutil
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import threading
from collections import deque

try:
    import pynvml

    PYNVML_AVAILABLE = True
except ImportError:
    PYNVML_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class SystemMetrics:
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­"""
    cpu_percent: float
    memory_percent: float
    memory_used_gb: float
    memory_total_gb: float
    disk_usage_percent: float
    timestamp: float


@dataclass
class GPUMetrics:
    """GPU ë©”íŠ¸ë¦­"""
    gpu_id: int
    name: str
    memory_used_gb: float
    memory_total_gb: float
    memory_percent: float
    utilization_percent: float
    temperature: int
    power_draw_watts: float
    timestamp: float


@dataclass
class SGLangPerformanceMetrics:
    """SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    requests_per_second: float
    tokens_per_second: float
    avg_response_time: float
    queue_length: int
    running_requests: int
    cache_hit_rate: float
    batch_size_avg: float
    memory_usage_gb: float
    error_rate: float
    timestamp: float


@dataclass
class KoreanTokenMetrics:
    """í•œêµ­ì–´ í† í° ì²˜ë¦¬ ë©”íŠ¸ë¦­"""
    korean_char_count: int
    total_char_count: int
    korean_ratio: float
    estimated_tokens: int
    actual_tokens: int
    tokenization_efficiency: float
    timestamp: float


class PerformanceMonitor:
    """SGLang ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""

    def __init__(self, history_size: int = 1000):
        self.history_size = history_size
        self.system_metrics_history = deque(maxlen=history_size)
        self.gpu_metrics_history = deque(maxlen=history_size)
        self.sglang_metrics_history = deque(maxlen=history_size)
        self.korean_token_metrics_history = deque(maxlen=history_size)

        self.monitoring = False
        self.monitor_thread = None
        self.monitor_interval = 10  # 10ì´ˆ ê°„ê²©

        # GPU ì´ˆê¸°í™”
        self.gpu_available = self._init_gpu()

        # ì„±ëŠ¥ ì„ê³„ê°’ (SGLang ìµœì í™” ê¸°ì¤€)
        self.thresholds = {
            "cpu_warning": 80.0,
            "cpu_critical": 95.0,
            "memory_warning": 85.0,
            "memory_critical": 95.0,
            "gpu_memory_warning": 90.0,
            "gpu_memory_critical": 98.0,
            "gpu_temp_warning": 80,
            "gpu_temp_critical": 90,
            "response_time_warning": 3.0,  # SGLang ë¹ ë¥¸ ì‘ë‹µ
            "response_time_critical": 5.0,
            "cache_hit_rate_warning": 0.6,  # SGLang ìºì‹œ íš¨ìœ¨
            "error_rate_warning": 0.05,  # 5% ì—ëŸ¬ìœ¨
            "error_rate_critical": 0.10  # 10% ì—ëŸ¬ìœ¨
        }

    def _init_gpu(self) -> bool:
        """GPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”"""
        if not PYNVML_AVAILABLE:
            logger.info("pynvml ì—†ìŒ - GPU ëª¨ë‹ˆí„°ë§ ë¹„í™œì„±í™”")
            return False

        try:
            pynvml.nvmlInit()
            gpu_count = pynvml.nvmlDeviceGetCount()
            logger.info(f"âœ… GPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”: {gpu_count}ê°œ GPU ê°ì§€")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ GPU ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def start_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring:
            logger.warning("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return

        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        logger.info(f"ğŸš€ SGLang ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {self.monitor_interval}ì´ˆ)")

    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("â¹ï¸ SGLang ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")

    def _monitor_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring:
            try:
                # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                system_metrics = self.get_system_metrics()
                self.system_metrics_history.append(system_metrics)

                # GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                if self.gpu_available:
                    gpu_metrics = self.get_gpu_metrics()
                    if gpu_metrics:
                        self.gpu_metrics_history.extend(gpu_metrics)

                # ê²½ê³  ìƒíƒœ ì²´í¬
                self._check_alerts(system_metrics)

                time.sleep(self.monitor_interval)

            except Exception as e:
                logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(5)

    def get_system_metrics(self) -> SystemMetrics:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')

            return SystemMetrics(
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                memory_used_gb=memory.used / (1024 ** 3),
                memory_total_gb=memory.total / (1024 ** 3),
                disk_usage_percent=disk.percent,
                timestamp=time.time()
            )
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return SystemMetrics(0, 0, 0, 0, 0, time.time())

    def get_gpu_metrics(self) -> List[GPUMetrics]:
        """GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        if not self.gpu_available:
            return []

        gpu_metrics = []
        try:
            gpu_count = pynvml.nvmlDeviceGetCount()

            for i in range(gpu_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(i)

                # GPU ê¸°ë³¸ ì •ë³´
                name = pynvml.nvmlDeviceGetName(handle).decode()

                # ë©”ëª¨ë¦¬ ì •ë³´
                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                memory_total_gb = memory_info.total / (1024 ** 3)
                memory_used_gb = memory_info.used / (1024 ** 3)
                memory_percent = (memory_info.used / memory_info.total) * 100

                # ì‚¬ìš©ë¥ 
                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
                utilization_percent = utilization.gpu

                # ì˜¨ë„
                temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)

                # ì „ë ¥ ì‚¬ìš©ëŸ‰
                try:
                    power_draw = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # mW to W
                except:
                    power_draw = 0.0

                gpu_metrics.append(GPUMetrics(
                    gpu_id=i,
                    name=name,
                    memory_used_gb=memory_used_gb,
                    memory_total_gb=memory_total_gb,
                    memory_percent=memory_percent,
                    utilization_percent=utilization_percent,
                    temperature=temperature,
                    power_draw_watts=power_draw,
                    timestamp=time.time()
                ))

        except Exception as e:
            logger.error(f"âŒ GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        return gpu_metrics

    def record_sglang_metrics(self, metrics: Dict[str, Any]):
        """SGLang ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        try:
            sglang_metrics = SGLangPerformanceMetrics(
                requests_per_second=metrics.get("requests_per_second", 0.0),
                tokens_per_second=metrics.get("tokens_per_second", 0.0),
                avg_response_time=metrics.get("avg_response_time", 0.0),
                queue_length=metrics.get("queue_length", 0),
                running_requests=metrics.get("running_requests", 0),
                cache_hit_rate=metrics.get("cache_hit_rate", 0.0),
                batch_size_avg=metrics.get("batch_size_avg", 0.0),
                memory_usage_gb=metrics.get("memory_usage_gb", 0.0),
                error_rate=metrics.get("error_rate", 0.0),
                timestamp=time.time()
            )

            self.sglang_metrics_history.append(sglang_metrics)
            logger.debug(
                f"ğŸ“Š SGLang ë©”íŠ¸ë¦­ ê¸°ë¡: RPS={sglang_metrics.requests_per_second:.1f}, TPS={sglang_metrics.tokens_per_second:.1f}")

        except Exception as e:
            logger.error(f"âŒ SGLang ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {e}")

    def record_korean_token_metrics(self, korean_chars: int, total_chars: int,
                                    estimated_tokens: int, actual_tokens: Optional[int] = None):
        """í•œêµ­ì–´ í† í° ë©”íŠ¸ë¦­ ê¸°ë¡"""
        try:
            korean_ratio = korean_chars / total_chars if total_chars > 0 else 0

            if actual_tokens is not None:
                efficiency = actual_tokens / estimated_tokens if estimated_tokens > 0 else 1.0
            else:
                efficiency = 1.0
                actual_tokens = estimated_tokens

            korean_metrics = KoreanTokenMetrics(
                korean_char_count=korean_chars,
                total_char_count=total_chars,
                korean_ratio=korean_ratio,
                estimated_tokens=estimated_tokens,
                actual_tokens=actual_tokens,
                tokenization_efficiency=efficiency,
                timestamp=time.time()
            )

            self.korean_token_metrics_history.append(korean_metrics)
            logger.debug(f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ í† í° ë©”íŠ¸ë¦­: {korean_chars}/{total_chars} í•œê¸€, íš¨ìœ¨ì„±: {efficiency:.2f}")

        except Exception as e:
            logger.error(f"âŒ í•œêµ­ì–´ í† í° ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {e}")

    def _check_alerts(self, system_metrics: SystemMetrics):
        """ê²½ê³  ìƒíƒœ ì²´í¬"""
        alerts = []

        # CPU ê²½ê³ 
        if system_metrics.cpu_percent > self.thresholds["cpu_critical"]:
            alerts.append(f"ğŸ”´ CPU ìœ„í—˜: {system_metrics.cpu_percent:.1f}%")
        elif system_metrics.cpu_percent > self.thresholds["cpu_warning"]:
            alerts.append(f"ğŸŸ¡ CPU ì£¼ì˜: {system_metrics.cpu_percent:.1f}%")

        # ë©”ëª¨ë¦¬ ê²½ê³ 
        if system_metrics.memory_percent > self.thresholds["memory_critical"]:
            alerts.append(f"ğŸ”´ ë©”ëª¨ë¦¬ ìœ„í—˜: {system_metrics.memory_percent:.1f}%")
        elif system_metrics.memory_percent > self.thresholds["memory_warning"]:
            alerts.append(f"ğŸŸ¡ ë©”ëª¨ë¦¬ ì£¼ì˜: {system_metrics.memory_percent:.1f}%")

        # GPU ê²½ê³  (ìµœì‹  GPU ë©”íŠ¸ë¦­ ì‚¬ìš©)
        if self.gpu_metrics_history:
            latest_gpu = self.gpu_metrics_history[-1]

            if latest_gpu.memory_percent > self.thresholds["gpu_memory_critical"]:
                alerts.append(f"ğŸ”´ GPU ë©”ëª¨ë¦¬ ìœ„í—˜: {latest_gpu.memory_percent:.1f}%")
            elif latest_gpu.memory_percent > self.thresholds["gpu_memory_warning"]:
                alerts.append(f"ğŸŸ¡ GPU ë©”ëª¨ë¦¬ ì£¼ì˜: {latest_gpu.memory_percent:.1f}%")

            if latest_gpu.temperature > self.thresholds["gpu_temp_critical"]:
                alerts.append(f"ğŸ”´ GPU ì˜¨ë„ ìœ„í—˜: {latest_gpu.temperature}Â°C")
            elif latest_gpu.temperature > self.thresholds["gpu_temp_warning"]:
                alerts.append(f"ğŸŸ¡ GPU ì˜¨ë„ ì£¼ì˜: {latest_gpu.temperature}Â°C")

        # SGLang ì„±ëŠ¥ ê²½ê³ 
        if self.sglang_metrics_history:
            latest_sglang = self.sglang_metrics_history[-1]

            if latest_sglang.avg_response_time > self.thresholds["response_time_critical"]:
                alerts.append(f"ğŸ”´ SGLang ì‘ë‹µ ì‹œê°„ ìœ„í—˜: {latest_sglang.avg_response_time:.2f}ì´ˆ")
            elif latest_sglang.avg_response_time > self.thresholds["response_time_warning"]:
                alerts.append(f"ğŸŸ¡ SGLang ì‘ë‹µ ì‹œê°„ ì£¼ì˜: {latest_sglang.avg_response_time:.2f}ì´ˆ")

            if latest_sglang.cache_hit_rate < self.thresholds["cache_hit_rate_warning"]:
                alerts.append(f"ğŸŸ¡ SGLang ìºì‹œ íˆíŠ¸ìœ¨ ë‚®ìŒ: {latest_sglang.cache_hit_rate:.1%}")

            if latest_sglang.error_rate > self.thresholds["error_rate_critical"]:
                alerts.append(f"ğŸ”´ SGLang ì—ëŸ¬ìœ¨ ìœ„í—˜: {latest_sglang.error_rate:.1%}")
            elif latest_sglang.error_rate > self.thresholds["error_rate_warning"]:
                alerts.append(f"ğŸŸ¡ SGLang ì—ëŸ¬ìœ¨ ì£¼ì˜: {latest_sglang.error_rate:.1%}")

        # ê²½ê³  ë¡œê¹…
        for alert in alerts:
            logger.warning(alert)

    def get_performance_summary(self, minutes: int = 10) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ (ìµœê·¼ Në¶„)"""
        cutoff_time = time.time() - (minutes * 60)

        # ìµœê·¼ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
        recent_system = [m for m in self.system_metrics_history if m.timestamp > cutoff_time]

        # ìµœê·¼ GPU ë©”íŠ¸ë¦­
        recent_gpu = [m for m in self.gpu_metrics_history if m.timestamp > cutoff_time]

        # ìµœê·¼ SGLang ë©”íŠ¸ë¦­
        recent_sglang = [m for m in self.sglang_metrics_history if m.timestamp > cutoff_time]

        # ìµœê·¼ í•œêµ­ì–´ í† í° ë©”íŠ¸ë¦­
        recent_korean = [m for m in self.korean_token_metrics_history if m.timestamp > cutoff_time]

        summary = {
            "period_minutes": minutes,
            "timestamp": time.time(),
            "system": self._summarize_system_metrics(recent_system),
            "gpu": self._summarize_gpu_metrics(recent_gpu),
            "sglang": self._summarize_sglang_metrics(recent_sglang),
            "korean_tokens": self._summarize_korean_metrics(recent_korean),
            "framework": "SGLang",
            "korean_optimized": True
        }

        return summary

    def _summarize_system_metrics(self, metrics: List[SystemMetrics]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìš”ì•½"""
        if not metrics:
            return {"status": "no_data"}

        cpu_values = [m.cpu_percent for m in metrics]
        memory_values = [m.memory_percent for m in metrics]

        return {
            "cpu": {
                "avg": sum(cpu_values) / len(cpu_values),
                "max": max(cpu_values),
                "min": min(cpu_values),
                "current": cpu_values[-1] if cpu_values else 0
            },
            "memory": {
                "avg": sum(memory_values) / len(memory_values),
                "max": max(memory_values),
                "min": min(memory_values),
                "current": memory_values[-1] if memory_values else 0,
                "total_gb": metrics[-1].memory_total_gb if metrics else 0
            },
            "disk_usage": metrics[-1].disk_usage_percent if metrics else 0,
            "sample_count": len(metrics)
        }

    def _summarize_gpu_metrics(self, metrics: List[GPUMetrics]) -> Dict[str, Any]:
        """GPU ë©”íŠ¸ë¦­ ìš”ì•½"""
        if not metrics:
            return {"status": "no_data", "available": False}

        # GPUë³„ë¡œ ê·¸ë£¹í™”
        gpu_summary = {}
        for metric in metrics:
            gpu_id = metric.gpu_id
            if gpu_id not in gpu_summary:
                gpu_summary[gpu_id] = {
                    "name": metric.name,
                    "memory_percent": [],
                    "utilization": [],
                    "temperature": [],
                    "power_draw": [],
                    "memory_total_gb": metric.memory_total_gb
                }

            gpu_summary[gpu_id]["memory_percent"].append(metric.memory_percent)
            gpu_summary[gpu_id]["utilization"].append(metric.utilization_percent)
            gpu_summary[gpu_id]["temperature"].append(metric.temperature)
            gpu_summary[gpu_id]["power_draw"].append(metric.power_draw_watts)

        # ìš”ì•½ í†µê³„ ê³„ì‚°
        for gpu_id in gpu_summary:
            gpu_data = gpu_summary[gpu_id]
            gpu_summary[gpu_id] = {
                "name": gpu_data["name"],
                "memory_total_gb": gpu_data["memory_total_gb"],
                "memory_percent": {
                    "avg": sum(gpu_data["memory_percent"]) / len(gpu_data["memory_percent"]),
                    "max": max(gpu_data["memory_percent"]),
                    "current": gpu_data["memory_percent"][-1]
                },
                "utilization": {
                    "avg": sum(gpu_data["utilization"]) / len(gpu_data["utilization"]),
                    "max": max(gpu_data["utilization"]),
                    "current": gpu_data["utilization"][-1]
                },
                "temperature": {
                    "avg": sum(gpu_data["temperature"]) / len(gpu_data["temperature"]),
                    "max": max(gpu_data["temperature"]),
                    "current": gpu_data["temperature"][-1]
                },
                "power_draw": {
                    "avg": sum(gpu_data["power_draw"]) / len(gpu_data["power_draw"]),
                    "max": max(gpu_data["power_draw"]),
                    "current": gpu_data["power_draw"][-1]
                }
            }

        return {
            "available": True,
            "gpus": gpu_summary,
            "sample_count": len(metrics)
        }

    def _summarize_sglang_metrics(self, metrics: List[SGLangPerformanceMetrics]) -> Dict[str, Any]:
        """SGLang ë©”íŠ¸ë¦­ ìš”ì•½"""
        if not metrics:
            return {"status": "no_data", "framework": "SGLang"}

        rps_values = [m.requests_per_second for m in metrics]
        tps_values = [m.tokens_per_second for m in metrics]
        response_times = [m.avg_response_time for m in metrics]
        cache_rates = [m.cache_hit_rate for m in metrics]
        error_rates = [m.error_rate for m in metrics]

        return {
            "framework": "SGLang",
            "requests_per_second": {
                "avg": sum(rps_values) / len(rps_values),
                "max": max(rps_values),
                "current": rps_values[-1]
            },
            "tokens_per_second": {
                "avg": sum(tps_values) / len(tps_values),
                "max": max(tps_values),
                "current": tps_values[-1]
            },
            "response_time": {
                "avg": sum(response_times) / len(response_times),
                "max": max(response_times),
                "min": min(response_times),
                "current": response_times[-1]
            },
            "cache_hit_rate": {
                "avg": sum(cache_rates) / len(cache_rates),
                "current": cache_rates[-1]
            },
            "error_rate": {
                "avg": sum(error_rates) / len(error_rates),
                "current": error_rates[-1]
            },
            "queue_length": metrics[-1].queue_length,
            "running_requests": metrics[-1].running_requests,
            "memory_usage_gb": metrics[-1].memory_usage_gb,
            "sample_count": len(metrics)
        }

    def _summarize_korean_metrics(self, metrics: List[KoreanTokenMetrics]) -> Dict[str, Any]:
        """í•œêµ­ì–´ í† í° ë©”íŠ¸ë¦­ ìš”ì•½"""
        if not metrics:
            return {"status": "no_data", "language": "korean"}

        korean_ratios = [m.korean_ratio for m in metrics]
        efficiencies = [m.tokenization_efficiency for m in metrics]
        total_korean_chars = sum(m.korean_char_count for m in metrics)
        total_chars = sum(m.total_char_count for m in metrics)
        total_estimated = sum(m.estimated_tokens for m in metrics)
        total_actual = sum(m.actual_tokens for m in metrics)

        return {
            "language": "korean",
            "korean_ratio": {
                "avg": sum(korean_ratios) / len(korean_ratios),
                "max": max(korean_ratios),
                "current": korean_ratios[-1]
            },
            "tokenization_efficiency": {
                "avg": sum(efficiencies) / len(efficiencies),
                "current": efficiencies[-1]
            },
            "totals": {
                "korean_chars": total_korean_chars,
                "total_chars": total_chars,
                "estimated_tokens": total_estimated,
                "actual_tokens": total_actual,
                "overall_korean_ratio": total_korean_chars / total_chars if total_chars > 0 else 0
            },
            "sample_count": len(metrics)
        }

    def export_metrics(self, filepath: str, minutes: int = 60):
        """ë©”íŠ¸ë¦­ì„ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            cutoff_time = time.time() - (minutes * 60)

            export_data = {
                "export_info": {
                    "timestamp": time.time(),
                    "period_minutes": minutes,
                    "framework": "SGLang",
                    "korean_optimized": True
                },
                "system_metrics": [
                    asdict(m) for m in self.system_metrics_history
                    if m.timestamp > cutoff_time
                ],
                "gpu_metrics": [
                    asdict(m) for m in self.gpu_metrics_history
                    if m.timestamp > cutoff_time
                ],
                "sglang_metrics": [
                    asdict(m) for m in self.sglang_metrics_history
                    if m.timestamp > cutoff_time
                ],
                "korean_token_metrics": [
                    asdict(m) for m in self.korean_token_metrics_history
                    if m.timestamp > cutoff_time
                ],
                "performance_summary": self.get_performance_summary(minutes)
            }

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)

            logger.info(f"ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filepath}")

        except Exception as e:
            logger.error(f"âŒ ë©”íŠ¸ë¦­ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")

    def get_optimization_recommendations(self) -> List[Dict[str, Any]]:
        """ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­"""
        recommendations = []

        # ìµœê·¼ ë©”íŠ¸ë¦­ ë¶„ì„
        if self.system_metrics_history:
            latest_system = self.system_metrics_history[-1]

            # CPU ìµœì í™”
            if latest_system.cpu_percent > 80:
                recommendations.append({
                    "category": "CPU",
                    "severity": "high" if latest_system.cpu_percent > 90 else "medium",
                    "title": "CPU ì‚¬ìš©ë¥  ë†’ìŒ",
                    "description": f"í˜„ì¬ CPU ì‚¬ìš©ë¥ : {latest_system.cpu_percent:.1f}%",
                    "suggestions": [
                        "SGLang max_running_requests ê°’ ê°ì†Œ",
                        "ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ",
                        "ë°°ì¹˜ í¬ê¸° ì¡°ì •"
                    ]
                })

            # ë©”ëª¨ë¦¬ ìµœì í™”
            if latest_system.memory_percent > 85:
                recommendations.append({
                    "category": "Memory",
                    "severity": "high" if latest_system.memory_percent > 95 else "medium",
                    "title": "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ",
                    "description": f"í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {latest_system.memory_percent:.1f}%",
                    "suggestions": [
                        "SGLang mem_fraction_static ê°’ ê°ì†Œ",
                        "KV ìºì‹œ í¬ê¸° ì œí•œ",
                        "ëª¨ë¸ ì–‘ìí™” ê³ ë ¤"
                    ]
                })

        # GPU ìµœì í™”
        if self.gpu_metrics_history:
            latest_gpu = self.gpu_metrics_history[-1]

            if latest_gpu.memory_percent > 90:
                recommendations.append({
                    "category": "GPU",
                    "severity": "high" if latest_gpu.memory_percent > 95 else "medium",
                    "title": "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ",
                    "description": f"í˜„ì¬ GPU ë©”ëª¨ë¦¬: {latest_gpu.memory_percent:.1f}%",
                    "suggestions": [
                        "SGLang chunked_prefill_size ê°ì†Œ",
                        "max_total_tokens ì¡°ì •",
                        "FlashAttention í™œì„±í™”"
                    ]
                })

            if latest_gpu.temperature > 80:
                recommendations.append({
                    "category": "GPU",
                    "severity": "high" if latest_gpu.temperature > 85 else "medium",
                    "title": "GPU ì˜¨ë„ ë†’ìŒ",
                    "description": f"í˜„ì¬ GPU ì˜¨ë„: {latest_gpu.temperature}Â°C",
                    "suggestions": [
                        "íŒ¬ ì„¤ì • í™•ì¸",
                        "ì²˜ë¦¬ëŸ‰ ê°ì†Œ",
                        "ëƒ‰ê° ì‹œìŠ¤í…œ ì ê²€"
                    ]
                })

        # SGLang ì„±ëŠ¥ ìµœì í™”
        if self.sglang_metrics_history:
            latest_sglang = self.sglang_metrics_history[-1]

            if latest_sglang.avg_response_time > 3.0:
                recommendations.append({
                    "category": "SGLang",
                    "severity": "medium",
                    "title": "ì‘ë‹µ ì‹œê°„ ëŠë¦¼",
                    "description": f"í‰ê·  ì‘ë‹µ ì‹œê°„: {latest_sglang.avg_response_time:.2f}ì´ˆ",
                    "suggestions": [
                        "enable_torch_compile=True ì„¤ì •",
                        "prefix_caching í™œì„±í™”",
                        "dynamic_batching ìµœì í™”"
                    ]
                })

            if latest_sglang.cache_hit_rate < 0.6:
                recommendations.append({
                    "category": "SGLang",
                    "severity": "medium",
                    "title": "ìºì‹œ íš¨ìœ¨ì„± ë‚®ìŒ",
                    "description": f"ìºì‹œ íˆíŠ¸ìœ¨: {latest_sglang.cache_hit_rate:.1%}",
                    "suggestions": [
                        "í”„ë¦¬í”½ìŠ¤ ìºì‹± í™œì„±í™”",
                        "ë°˜ë³µì ì¸ í”„ë¡¬í”„íŠ¸ íŒ¨í„´ í™œìš©",
                        "KV ìºì‹œ í¬ê¸° ì¦ê°€"
                    ]
                })

        # í•œêµ­ì–´ í† í° ìµœì í™”
        if self.korean_token_metrics_history:
            recent_korean = self.korean_token_metrics_history[-10:]  # ìµœê·¼ 10ê°œ
            avg_efficiency = sum(m.tokenization_efficiency for m in recent_korean) / len(recent_korean)

            if avg_efficiency < 0.8:
                recommendations.append({
                    "category": "Korean",
                    "severity": "low",
                    "title": "í•œêµ­ì–´ í† í°í™” íš¨ìœ¨ì„± ê°œì„  í•„ìš”",
                    "description": f"í† í°í™” íš¨ìœ¨ì„±: {avg_efficiency:.1%}",
                    "suggestions": [
                        "í•œêµ­ì–´ ì „ìš© í† í¬ë‚˜ì´ì € ì‚¬ìš©",
                        "í† í° ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ ì¡°ì •",
                        "í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ê³ ë ¤"
                    ]
                })

        return recommendations

    def clear_history(self):
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.system_metrics_history.clear()
        self.gpu_metrics_history.clear()
        self.sglang_metrics_history.clear()
        self.korean_token_metrics_history.clear()
        logger.info("ğŸ§¹ ì„±ëŠ¥ ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")


# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
performance_monitor: Optional[PerformanceMonitor] = None


def get_performance_monitor() -> PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global performance_monitor
    if performance_monitor is None:
        performance_monitor = PerformanceMonitor()
    return performance_monitor


def start_performance_monitoring(interval: int = 10):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
    monitor = get_performance_monitor()
    monitor.monitor_interval = interval
    monitor.start_monitoring()


def stop_performance_monitoring():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
    global performance_monitor
    if performance_monitor:
        performance_monitor.stop_monitoring()


async def collect_sglang_metrics(sglang_client) -> Optional[Dict[str, Any]]:
    """SGLang í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    try:
        # SGLang ì„œë²„ ì •ë³´ ì¡°íšŒ
        server_info = await sglang_client.get_server_info()
        if not server_info:
            return None

        # í´ë¼ì´ì–¸íŠ¸ í†µê³„ ì¡°íšŒ
        client_stats = await sglang_client.get_client_statistics()

        # ë©”íŠ¸ë¦­ ì¡°í•©
        metrics = {
            "requests_per_second": server_info.requests_per_second,
            "tokens_per_second": server_info.tokens_per_second,
            "avg_response_time": client_stats.get("avg_response_time", 0.0),
            "queue_length": server_info.queue_length,
            "running_requests": server_info.running_requests,
            "cache_hit_rate": server_info.cache_hit_rate,
            "batch_size_avg": 1.0,  # SGLangì—ì„œ ì œê³µë˜ë©´ ì—…ë°ì´íŠ¸
            "memory_usage_gb": server_info.memory_usage_gb,
            "error_rate": client_stats.get("error_count", 0) / max(client_stats.get("total_requests", 1), 1),
            "success_rate": client_stats.get("success_rate", 100.0) / 100.0
        }

        return metrics

    except Exception as e:
        logger.error(f"âŒ SGLang ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return None


class SGLangOptimizer:
    """SGLang ì„±ëŠ¥ ìµœì í™” ë„êµ¬"""

    def __init__(self, performance_monitor: PerformanceMonitor):
        self.monitor = performance_monitor
        self.optimization_history = []

    def analyze_performance_bottlenecks(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„"""
        analysis = {
            "timestamp": time.time(),
            "bottlenecks": [],
            "recommendations": [],
            "severity": "none"
        }

        # ìµœê·¼ ë©”íŠ¸ë¦­ ë¶„ì„
        recent_summary = self.monitor.get_performance_summary(minutes=5)

        # CPU ë³‘ëª©
        if recent_summary["system"]["cpu"]["avg"] > 80:
            analysis["bottlenecks"].append({
                "type": "cpu",
                "severity": "high" if recent_summary["system"]["cpu"]["avg"] > 90 else "medium",
                "value": recent_summary["system"]["cpu"]["avg"],
                "description": "CPU ì‚¬ìš©ë¥ ì´ ë†’ì•„ ì²˜ë¦¬ ì†ë„ ì €í•˜"
            })

        # GPU ë©”ëª¨ë¦¬ ë³‘ëª©
        if recent_summary["gpu"]["available"]:
            for gpu_id, gpu_data in recent_summary["gpu"]["gpus"].items():
                if gpu_data["memory_percent"]["avg"] > 90:
                    analysis["bottlenecks"].append({
                        "type": "gpu_memory",
                        "severity": "high",
                        "value": gpu_data["memory_percent"]["avg"],
                        "description": f"GPU {gpu_id} ë©”ëª¨ë¦¬ ë¶€ì¡±"
                    })

        # SGLang ì„±ëŠ¥ ë³‘ëª©
        if recent_summary["sglang"].get("response_time", {}).get("avg", 0) > 3.0:
            analysis["bottlenecks"].append({
                "type": "response_time",
                "severity": "medium",
                "value": recent_summary["sglang"]["response_time"]["avg"],
                "description": "SGLang ì‘ë‹µ ì‹œê°„ ì§€ì—°"
            })

        # ìºì‹œ íš¨ìœ¨ì„± ë¬¸ì œ
        if recent_summary["sglang"].get("cache_hit_rate", {}).get("avg", 0) < 0.6:
            analysis["bottlenecks"].append({
                "type": "cache_efficiency",
                "severity": "medium",
                "value": recent_summary["sglang"]["cache_hit_rate"]["avg"],
                "description": "SGLang ìºì‹œ íš¨ìœ¨ì„± ë‚®ìŒ"
            })

        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        analysis["recommendations"] = self._generate_optimization_recommendations(analysis["bottlenecks"])

        # ì „ì²´ ì‹¬ê°ë„ ê²°ì •
        if any(b["severity"] == "high" for b in analysis["bottlenecks"]):
            analysis["severity"] = "high"
        elif any(b["severity"] == "medium" for b in analysis["bottlenecks"]):
            analysis["severity"] = "medium"
        else:
            analysis["severity"] = "low"

        return analysis

    def _generate_optimization_recommendations(self, bottlenecks: List[Dict]) -> List[Dict]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        for bottleneck in bottlenecks:
            if bottleneck["type"] == "cpu":
                recommendations.append({
                    "category": "SGLang Configuration",
                    "action": "Reduce max_running_requests",
                    "description": "ë™ì‹œ ì²˜ë¦¬ ìš”ì²­ ìˆ˜ë¥¼ ì¤„ì—¬ CPU ë¶€í•˜ ê°ì†Œ",
                    "config_change": "--max-running-requests 8",
                    "expected_impact": "CPU ì‚¬ìš©ë¥  20-30% ê°ì†Œ"
                })

            elif bottleneck["type"] == "gpu_memory":
                recommendations.append({
                    "category": "SGLang Memory",
                    "action": "Reduce memory allocation",
                    "description": "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°ì •",
                    "config_change": "--mem-fraction-static 0.6",
                    "expected_impact": "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  15-20% ê°ì†Œ"
                })

            elif bottleneck["type"] == "response_time":
                recommendations.append({
                    "category": "SGLang Performance",
                    "action": "Enable optimizations",
                    "description": "SGLang ì„±ëŠ¥ ìµœì í™” ê¸°ëŠ¥ í™œì„±í™”",
                    "config_change": "--enable-torch-compile --chunked-prefill-size 4096",
                    "expected_impact": "ì‘ë‹µ ì‹œê°„ 25-40% ê°œì„ "
                })

            elif bottleneck["type"] == "cache_efficiency":
                recommendations.append({
                    "category": "SGLang Caching",
                    "action": "Improve caching",
                    "description": "í”„ë¦¬í”½ìŠ¤ ìºì‹± ë° KV ìºì‹œ ìµœì í™”",
                    "config_change": "--enable-prefix-caching",
                    "expected_impact": "ìºì‹œ íˆíŠ¸ìœ¨ 30-50% í–¥ìƒ"
                })

        return recommendations

    def suggest_sglang_config_optimization(self, current_config: Dict) -> Dict[str, Any]:
        """SGLang ì„¤ì • ìµœì í™” ì œì•ˆ"""
        optimized_config = current_config.copy()
        changes = []

        # ìµœê·¼ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„
        recent_summary = self.monitor.get_performance_summary(minutes=10)

        # CPU ê¸°ë°˜ ìµœì í™”
        cpu_avg = recent_summary["system"]["cpu"]["avg"]
        if cpu_avg > 85:
            # CPU ë¶€í•˜ê°€ ë†’ìœ¼ë©´ ë™ì‹œ ìš”ì²­ ìˆ˜ ê°ì†Œ
            new_max_requests = max(4, current_config.get("max_running_requests", 16) - 4)
            optimized_config["max_running_requests"] = new_max_requests
            changes.append({
                "parameter": "max_running_requests",
                "old_value": current_config.get("max_running_requests", 16),
                "new_value": new_max_requests,
                "reason": f"CPU ì‚¬ìš©ë¥  ë†’ìŒ ({cpu_avg:.1f}%)"
            })
        elif cpu_avg < 50:
            # CPU ì—¬ìœ  ìˆìœ¼ë©´ ë™ì‹œ ìš”ì²­ ìˆ˜ ì¦ê°€
            new_max_requests = min(32, current_config.get("max_running_requests", 16) + 4)
            optimized_config["max_running_requests"] = new_max_requests
            changes.append({
                "parameter": "max_running_requests",
                "old_value": current_config.get("max_running_requests", 16),
                "new_value": new_max_requests,
                "reason": f"CPU ì—¬ìœ  ìˆìŒ ({cpu_avg:.1f}%)"
            })

        # GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì í™”
        if recent_summary["gpu"]["available"]:
            for gpu_id, gpu_data in recent_summary["gpu"]["gpus"].items():
                gpu_mem_avg = gpu_data["memory_percent"]["avg"]

                if gpu_mem_avg > 90:
                    # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê°ì†Œ
                    new_mem_fraction = max(0.5, current_config.get("mem_fraction_static", 0.75) - 0.1)
                    optimized_config["mem_fraction_static"] = new_mem_fraction
                    changes.append({
                        "parameter": "mem_fraction_static",
                        "old_value": current_config.get("mem_fraction_static", 0.75),
                        "new_value": new_mem_fraction,
                        "reason": f"GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ({gpu_mem_avg:.1f}%)"
                    })
                elif gpu_mem_avg < 60:
                    # GPU ë©”ëª¨ë¦¬ ì—¬ìœ  ì‹œ ì¦ê°€
                    new_mem_fraction = min(0.85, current_config.get("mem_fraction_static", 0.75) + 0.05)
                    optimized_config["mem_fraction_static"] = new_mem_fraction
                    changes.append({
                        "parameter": "mem_fraction_static",
                        "old_value": current_config.get("mem_fraction_static", 0.75),
                        "new_value": new_mem_fraction,
                        "reason": f"GPU ë©”ëª¨ë¦¬ ì—¬ìœ  ({gpu_mem_avg:.1f}%)"
                    })

        # ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ ìµœì í™”
        if recent_summary["sglang"].get("response_time", {}).get("avg", 0) > 3.0:
            # ì‘ë‹µ ì‹œê°„ì´ ëŠë¦¬ë©´ ì²­í¬ í¬ê¸° ì¡°ì •
            current_chunk_size = current_config.get("chunked_prefill_size", 4096)
            new_chunk_size = max(2048, current_chunk_size - 1024)
            optimized_config["chunked_prefill_size"] = new_chunk_size
            changes.append({
                "parameter": "chunked_prefill_size",
                "old_value": current_chunk_size,
                "new_value": new_chunk_size,
                "reason": "ì‘ë‹µ ì‹œê°„ ê°œì„ "
            })

            # Torch compile í™œì„±í™” ì œì•ˆ
            if not current_config.get("enable_torch_compile", False):
                optimized_config["enable_torch_compile"] = True
                changes.append({
                    "parameter": "enable_torch_compile",
                    "old_value": False,
                    "new_value": True,
                    "reason": "ì„±ëŠ¥ ìµœì í™”"
                })

        # ìºì‹œ íš¨ìœ¨ì„± ê¸°ë°˜ ìµœì í™”
        cache_hit_rate = recent_summary["sglang"].get("cache_hit_rate", {}).get("avg", 0)
        if cache_hit_rate < 0.6:
            if not current_config.get("enable_prefix_caching", False):
                optimized_config["enable_prefix_caching"] = True
                changes.append({
                    "parameter": "enable_prefix_caching",
                    "old_value": False,
                    "new_value": True,
                    "reason": f"ìºì‹œ íš¨ìœ¨ì„± ê°œì„  ({cache_hit_rate:.1%})"
                })

        return {
            "optimized_config": optimized_config,
            "changes": changes,
            "performance_analysis": recent_summary,
            "estimated_improvements": self._estimate_performance_improvements(changes)
        }

    def _estimate_performance_improvements(self, changes: List[Dict]) -> Dict[str, str]:
        """ì„±ëŠ¥ ê°œì„  ì˜ˆìƒì¹˜ ê³„ì‚°"""
        improvements = {}

        for change in changes:
            param = change["parameter"]

            if param == "max_running_requests":
                if change["new_value"] < change["old_value"]:
                    improvements["cpu_usage"] = "15-25% ê°ì†Œ"
                    improvements["response_stability"] = "í–¥ìƒ"
                else:
                    improvements["throughput"] = "20-30% ì¦ê°€"

            elif param == "mem_fraction_static":
                if change["new_value"] < change["old_value"]:
                    improvements["gpu_memory"] = "ì•ˆì •ì„± í–¥ìƒ"
                else:
                    improvements["model_capacity"] = "ì¦ê°€"

            elif param == "enable_torch_compile":
                improvements["inference_speed"] = "15-25% í–¥ìƒ"
                improvements["first_token_latency"] = "ê°ì†Œ"

            elif param == "enable_prefix_caching":
                improvements["cache_efficiency"] = "30-50% í–¥ìƒ"
                improvements["repeat_request_speed"] = "í¬ê²Œ í–¥ìƒ"

            elif param == "chunked_prefill_size":
                improvements["memory_efficiency"] = "í–¥ìƒ"
                improvements["large_context_handling"] = "ê°œì„ "

        return improvements


class KoreanTokenOptimizer:
    """í•œêµ­ì–´ í† í° ì²˜ë¦¬ ìµœì í™”"""

    def __init__(self):
        self.optimization_cache = {}

    def analyze_korean_text_characteristics(self, text: str) -> Dict[str, Any]:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ íŠ¹ì„± ë¶„ì„"""
        import re

        # ë¬¸ì ìœ í˜•ë³„ ë¶„ë¥˜
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        hanja_chars = len(re.findall(r'[ä¸€-é¾¯]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        number_chars = len(re.findall(r'[0-9]', text))
        punctuation_chars = len(re.findall(r'[^\w\sê°€-í£ä¸€-é¾¯]', text))
        space_chars = len(re.findall(r'\s', text))

        total_chars = len(text)

        # í•œêµ­ì–´ ë³µí•©ì–´ ë¶„ì„
        compound_words = len(re.findall(r'[ê°€-í£]{3,}', text))  # 3ê¸€ì ì´ìƒ í•œê¸€ ë‹¨ì–´

        # ë¬¸ì¥ êµ¬ì¡° ë¶„ì„
        sentences = len(re.findall(r'[.!?]', text))
        avg_sentence_length = total_chars / max(sentences, 1)

        return {
            "total_chars": total_chars,
            "korean_chars": korean_chars,
            "hanja_chars": hanja_chars,
            "english_chars": english_chars,
            "number_chars": number_chars,
            "punctuation_chars": punctuation_chars,
            "space_chars": space_chars,
            "korean_ratio": korean_chars / total_chars if total_chars > 0 else 0,
            "compound_words": compound_words,
            "sentences": sentences,
            "avg_sentence_length": avg_sentence_length,
            "complexity_score": self._calculate_complexity_score(korean_chars, compound_words, english_chars)
        }

    def _calculate_complexity_score(self, korean_chars: int, compound_words: int, english_chars: int) -> float:
        """í…ìŠ¤íŠ¸ ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°"""
        # í•œêµ­ì–´ ë³µí•©ì–´ê°€ ë§ê³ , ì˜ì–´ê°€ ì„ì´ë©´ ë³µì¡ë„ ì¦ê°€
        base_score = korean_chars * 0.8  # í•œê¸€ ê¸°ë³¸ ì ìˆ˜
        compound_penalty = compound_words * 0.3  # ë³µí•©ì–´ ê°€ì¤‘ì¹˜
        mixed_penalty = (english_chars > 0 and korean_chars > 0) * 0.5  # í˜¼ìš© ê°€ì¤‘ì¹˜

        return base_score + compound_penalty + mixed_penalty

    def optimize_korean_tokenization_factor(self, historical_data: List[Dict]) -> float:
        """í•œêµ­ì–´ í† í°í™” íŒ©í„° ìµœì í™”"""
        if not historical_data:
            return 1.15  # ê¸°ë³¸ê°’

        # ì‹¤ì œ í† í° ìˆ˜ì™€ ì˜ˆìƒ í† í° ìˆ˜ ë¹„êµ
        efficiency_scores = []
        for data in historical_data:
            if data.get("actual_tokens") and data.get("estimated_tokens"):
                efficiency = data["actual_tokens"] / data["estimated_tokens"]
                efficiency_scores.append(efficiency)

        if efficiency_scores:
            avg_efficiency = sum(efficiency_scores) / len(efficiency_scores)

            # íš¨ìœ¨ì„± ê¸°ë°˜ íŒ©í„° ì¡°ì •
            if avg_efficiency > 1.1:
                return 1.25  # ì‹¤ì œê°€ ì˜ˆìƒë³´ë‹¤ ë†’ìœ¼ë©´ íŒ©í„° ì¦ê°€
            elif avg_efficiency < 0.9:
                return 1.05  # ì‹¤ì œê°€ ì˜ˆìƒë³´ë‹¤ ë‚®ìœ¼ë©´ íŒ©í„° ê°ì†Œ
            else:
                return 1.15  # ì ì • ìˆ˜ì¤€

        return 1.15

    def suggest_korean_prompt_optimization(self, prompt: str) -> Dict[str, Any]:
        """í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì œì•ˆ"""
        analysis = self.analyze_korean_text_characteristics(prompt)
        suggestions = []

        # ë„ˆë¬´ ê¸´ ë¬¸ì¥ ì²´í¬
        if analysis["avg_sentence_length"] > 100:
            suggestions.append({
                "type": "sentence_length",
                "description": "ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ì–´ í† í° íš¨ìœ¨ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "suggestion": "ë¬¸ì¥ì„ ì§§ê²Œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”"
            })

        # ì˜ì–´/í•œêµ­ì–´ í˜¼ìš© ì²´í¬
        if 0.2 < analysis["korean_ratio"] < 0.8:
            suggestions.append({
                "type": "language_mixing",
                "description": "í•œêµ­ì–´ì™€ ì˜ì–´ê°€ í˜¼ì¬ë˜ì–´ í† í°í™” íš¨ìœ¨ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤",
                "suggestion": "ê°€ëŠ¥í•˜ë©´ í•œ ì–¸ì–´ë¡œ í†µì¼í•˜ê±°ë‚˜ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”"
            })

        # ë³µí•©ì–´ ê³¼ë‹¤ ì‚¬ìš© ì²´í¬
        complexity_ratio = analysis["compound_words"] / analysis["korean_chars"] if analysis["korean_chars"] > 0 else 0
        if complexity_ratio > 0.3:
            suggestions.append({
                "type": "complexity",
                "description": "ë³µì¡í•œ ë³µí•©ì–´ê°€ ë§ì•„ í† í° ìˆ˜ê°€ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "suggestion": "ê°„ë‹¨í•œ í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ê±°ë‚˜ ì„¤ëª…ì„ ì¶”ê°€í•˜ì„¸ìš”"
            })

        return {
            "analysis": analysis,
            "suggestions": suggestions,
            "optimized_prompt": self._optimize_prompt_structure(prompt, analysis),
            "expected_token_reduction": len(suggestions) * 5  # ì œì•ˆì‚¬í•­ë‹¹ ì•½ 5% í† í° ì ˆì•½
        }

    def _optimize_prompt_structure(self, prompt: str, analysis: Dict) -> str:
        """í”„ë¡¬í”„íŠ¸ êµ¬ì¡° ìµœì í™”"""
        import re

        optimized = prompt

        # ê¸´ ë¬¸ì¥ì„ ì§§ê²Œ ë¶„í• 
        if analysis["avg_sentence_length"] > 100:
            # ì ‘ì†ì‚¬ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¶„í• 
            optimized = re.sub(r'(\s+(ê·¸ë¦¬ê³ |ë˜í•œ|í•˜ì§€ë§Œ|ê·¸ëŸ¬ë‚˜|ë”°ë¼ì„œ)\s+)', r'.\n\1', optimized)

        # ë°˜ë³µë˜ëŠ” í‘œí˜„ ì••ì¶•
        optimized = re.sub(r'(\w+)\s+\1', r'\1', optimized)  # ì¤‘ë³µ ë‹¨ì–´ ì œê±°

        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        optimized = re.sub(r'\s+', ' ', optimized).strip()

        return optimized


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def benchmark_sglang_performance(sglang_client, test_prompts: List[str],
                                 iterations: int = 5) -> Dict[str, Any]:
    """SGLang ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    results = {
        "total_iterations": iterations,
        "test_prompts_count": len(test_prompts),
        "results": [],
        "summary": {}
    }

    for i in range(iterations):
        iteration_start = time.time()
        iteration_results = []

        for j, prompt in enumerate(test_prompts):
            start_time = time.time()

            # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
            try:
                result = asyncio.get_event_loop().run_until_complete(
                    sglang_client.chat_completion([{"role": "user", "content": prompt}])
                )

                response_time = time.time() - start_time
                success = "error" not in result

                iteration_results.append({
                    "prompt_index": j,
                    "response_time": response_time,
                    "success": success,
                    "prompt_length": len(prompt)
                })

            except Exception as e:
                iteration_results.append({
                    "prompt_index": j,
                    "response_time": time.time() - start_time,
                    "success": False,
                    "error": str(e),
                    "prompt_length": len(prompt)
                })

        iteration_time = time.time() - iteration_start
        results["results"].append({
            "iteration": i + 1,
            "total_time": iteration_time,
            "requests": iteration_results
        })

    # ê²°ê³¼ ìš”ì•½
    all_response_times = []
    success_count = 0
    total_requests = 0

    for iteration in results["results"]:
        for request in iteration["requests"]:
            all_response_times.append(request["response_time"])
            if request["success"]:
                success_count += 1
            total_requests += 1

    results["summary"] = {
        "avg_response_time": sum(all_response_times) / len(all_response_times),
        "min_response_time": min(all_response_times),
        "max_response_time": max(all_response_times),
        "success_rate": success_count / total_requests,
        "total_requests": total_requests,
        "requests_per_second": total_requests / sum(r["total_time"] for r in results["results"])
    }

    return results


def compare_sglang_vs_baseline(sglang_metrics: Dict, baseline_metrics: Dict) -> Dict[str, Any]:
    """SGLang vs ê¸°ì¤€ì„  ì„±ëŠ¥ ë¹„êµ"""
    comparison = {
        "framework_comparison": "SGLang vs Baseline",
        "metrics": {},
        "improvements": {},
        "timestamp": time.time()
    }

    metric_comparisons = [
        ("requests_per_second", "ì²˜ë¦¬ëŸ‰ (RPS)"),
        ("tokens_per_second", "í† í° ì²˜ë¦¬ìœ¨ (TPS)"),
        ("avg_response_time", "í‰ê·  ì‘ë‹µ ì‹œê°„"),
        ("cache_hit_rate", "ìºì‹œ íˆíŠ¸ìœ¨"),
        ("memory_usage_gb", "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"),
        ("error_rate", "ì—ëŸ¬ìœ¨")
    ]

    for metric_key, metric_name in metric_comparisons:
        sglang_value = sglang_metrics.get(metric_key, 0)
        baseline_value = baseline_metrics.get(metric_key, 0)

        if baseline_value > 0:
            if metric_key in ["avg_response_time", "memory_usage_gb", "error_rate"]:
                # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ë©”íŠ¸ë¦­
                improvement = ((baseline_value - sglang_value) / baseline_value) * 100
            else:
                # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ë©”íŠ¸ë¦­
                improvement = ((sglang_value - baseline_value) / baseline_value) * 100
        else:
            improvement = 0

        comparison["metrics"][metric_key] = {
            "name": metric_name,
            "sglang": sglang_value,
            "baseline": baseline_value,
            "improvement_percent": improvement
        }

        if abs(improvement) > 5:  # 5% ì´ìƒ ì°¨ì´ë‚˜ëŠ” ê²½ìš°ë§Œ
            comparison["improvements"][metric_key] = improvement

    return comparison