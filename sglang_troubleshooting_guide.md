# SGLang CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

## ğŸ” ë¬¸ì œ ë¶„ì„
```
RuntimeError: Cannot re-initialize CUDA in forked subprocess. 
To use CUDA with multiprocessing, you must use the 'spawn' start method
```

## ğŸ’¡ í•´ê²° ë°©ë²• (ìš°ì„ ìˆœìœ„ë³„)

### 1. CPU ëª¨ë“œ ì‹¤í–‰ (ê°€ì¥ ì•ˆì •ì )
```bash
python start_sglang_cpu_mode.py
```
**ì¥ì **: CUDA ë¬¸ì œ ì™„ì „ íšŒí”¼, ì•ˆì •ì 
**ë‹¨ì **: ì†ë„ ëŠë¦¼

### 2. Docker ì‹¤í–‰ (ê¶Œì¥)
```bash
bash start_sglang_docker.sh
```
**ì¥ì **: ì™„ì „ ê²©ë¦¬ëœ í™˜ê²½, CUDA ë¬¸ì œ í•´ê²°
**ë‹¨ì **: Docker ì„¤ì¹˜ í•„ìš”

### 3. í™˜ê²½ ë³€ìˆ˜ + ì¬ì‹œì‘
```bash
export TORCH_MULTIPROCESSING_START_METHOD=spawn
export CUDA_VISIBLE_DEVICES=0
python -m sglang.launch_server --model-path microsoft/DialoGPT-medium
```

### 4. ì™„ì „ ìƒˆë¡œìš´ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
```bash
# ìƒˆ í„°ë¯¸ë„ ì—´ê¸°
conda activate sglang_korean
export TORCH_MULTIPROCESSING_START_METHOD=spawn
python start_sglang_cpu_mode.py
```

## ğŸ¯ RTX 4060 íŠ¹í™” ê¶Œì¥ì‚¬í•­

1. **CPU ëª¨ë“œ ì‚¬ìš©** (ê°€ì¥ ì•ˆì •ì )
2. **ë©”ëª¨ë¦¬ ì œí•œ**: `--mem-fraction-static 0.6`
3. **ë™ì‹œ ìš”ì²­ ì œí•œ**: `--max-running-requests 2`
4. **í† í° ì œí•œ**: `--max-total-tokens 1024`

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| ëª¨ë“œ | ì†ë„ | ì•ˆì •ì„± | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|------|------|--------|---------------|
| GPU (ë¬¸ì œ ìˆìŒ) | â­â­â­â­â­ | â­â­ | ë†’ìŒ |
| CPU | â­â­ | â­â­â­â­â­ | ë‚®ìŒ |
| Docker | â­â­â­â­ | â­â­â­â­â­ | ì¤‘ê°„ |

## ğŸ”§ ë””ë²„ê¹… ëª…ë ¹ì–´

```bash
# ë©€í‹°í”„ë¡œì„¸ì‹± ë°©ë²• í™•ì¸
python -c "import multiprocessing; print(multiprocessing.get_start_method())"

# CUDA ìƒíƒœ í™•ì¸
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $TORCH_MULTIPROCESSING_START_METHOD
echo $CUDA_VISIBLE_DEVICES
```
